{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando Detectores x Descritores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FunÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.04):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "\n",
    "    # Applying the function \n",
    "    dst = cv2.cornerHarris(gray_image_f32, blockSize, ksize, k) \n",
    "  \n",
    "    # dilate to mark the corners \n",
    "    dst = cv2.dilate(dst, None)\n",
    "    \n",
    "    ret, dst = cv2.threshold(dst,threshold*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # draw keypoints\n",
    "    # image[dst > threshold * dst.max()] = [0, 255, 0]\n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(255, 0, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSIFTKeypoints(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None)\n",
    "    not_dup_kp = {pt.pt: pt for pt in kp}\n",
    "    kp_ = list(not_dup_kp.values())\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp_, None, color=(0, 255, 0), flags=0)\n",
    "\n",
    "    return kp_, kp_image \n",
    "\n",
    "def detectSIFTKeypointsFilter(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None)\n",
    "    not_dup_kp = {pt.pt: pt for pt in kp}\n",
    "    kp_ = list(not_dup_kp.values())\n",
    "    \n",
    "    altura, largura = image.shape[:2]\n",
    "    imagem_binaria = np.zeros((altura, largura), dtype=np.uint8)\n",
    "    for kp in kp_:\n",
    "        x, y = map(int, kp.pt)\n",
    "        cv2.circle(imagem_binaria, (x, y), 5, 255, -1)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(imagem_binaria)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "    \n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectStarKeypoints(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kp = star.detect(gray_image, None)\n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return kp, kp_image \n",
    "\n",
    "\n",
    "def detectStarKeypointsFilter(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kps = star.detect(gray_image, None)\n",
    "\n",
    "    altura, largura = image.shape[:2]\n",
    "    imagem_binaria = np.zeros((altura, largura), dtype=np.uint8)\n",
    "    for kp in kps:\n",
    "        x, y = map(int, kp.pt)\n",
    "        cv2.circle(imagem_binaria, (x, y), 5, 255, -1)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(imagem_binaria)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return keypoints, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "def computeDistacesKeypoints(pts1, pts2, threshold=1):\n",
    "    array_pts1 = np.asarray(pts1)\n",
    "    array_pts2 = np.asarray(pts2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)\n",
    "        matches_pts1 = [pts1[i] for i, (pt, dist) in enumerate(zip(dists[0], dists[1])) if dist <= threshold]\n",
    "        matches_pts2 = [pts2[pt] for pt, dist in zip(dists[0], dists[1]) if dist <= threshold]\n",
    "    else:\n",
    "        matches_pts1 = []\n",
    "        matches_pts2 = []\n",
    "        \n",
    "    return matches_pts1, matches_pts2\n",
    "\n",
    "\n",
    "def return_detector_func(algol):\n",
    "    if algol == 'harris':\n",
    "        func = detectHarrisKeypoints\n",
    "    elif algol == 'sift_filter':\n",
    "        func = detectSIFTKeypointsFilter\n",
    "    elif algol == 'sift':\n",
    "        func = detectSIFTKeypoints\n",
    "    elif algol == 'star_filter':\n",
    "        func = detectStarKeypointsFilter\n",
    "    else:\n",
    "        func = detectStarKeypoints\n",
    "    \n",
    "    return func\n",
    "\n",
    "\n",
    "def compare_detectors_keypoints(image, algol_1, algol_2, params_algol_1, params_algol_2, threshold):\n",
    "    detector_1 = return_detector_func(algol_1)\n",
    "    detector_2 = return_detector_func(algol_2)\n",
    "\n",
    "    kp1, _ = detector_1(image, **params_algol_1)\n",
    "    kp2, _ = detector_2(image, **params_algol_2)\n",
    "\n",
    "    kp1 = [(kp.pt[0], kp.pt[1]) for kp in kp1]\n",
    "    kp2 = [(kp.pt[0], kp.pt[1]) for kp in kp2]\n",
    "\n",
    "    matches_pts1, matches_pts2 = computeDistacesKeypoints(kp1, kp2, threshold=threshold)\n",
    "    mismatches_pts1 = [pt for pt in kp1 if pt not in matches_pts1]\n",
    "    mismatches_pts2 = [pt for pt in kp2 if pt not in matches_pts2]\n",
    "\n",
    "    matches_kp1 = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in matches_pts1]\n",
    "    matches_kp2 = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in matches_pts2]\n",
    "\n",
    "    mismatches_kp1 = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in mismatches_pts1]\n",
    "    mismatches_kp2 = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in mismatches_pts2]\n",
    "\n",
    "    kp_image = cv2.drawKeypoints(image, matches_kp1, None, color=(0, 255, 0), flags=0)\n",
    "    kp_image = cv2.drawKeypoints(kp_image, matches_kp2, None, color=(0, 255, 0), flags=0)\n",
    "    kp_image = cv2.drawKeypoints(kp_image, mismatches_kp1, None, color=(255, 0, 0), flags=0)\n",
    "    kp_image = cv2.drawKeypoints(kp_image, mismatches_kp2, None, color=(0, 0, 255), flags=0)\n",
    "\n",
    "    return kp_image, matches_kp1, matches_kp2, kp1, kp2 \n",
    "\n",
    "def return_params_combination(combination, params_harris, params_sift, params_star, pos):\n",
    "    if combination == 'harris':\n",
    "        params = {key: value[pos] for key, value in zip(params_harris.keys(), params_harris.values())}\n",
    "    elif combination == 'sift' or combination == 'sift_filter':\n",
    "        params = {key: value[pos] for key, value in zip(params_sift.keys(), params_sift.values())}\n",
    "    else:\n",
    "        params = {key: value[pos] for key, value in zip(params_star.keys(), params_star.values())}\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def run_all_tests(image, image_name, params_harris, params_sift, params_star, thresholds, filter=False, n_pontos=['25', '50', '100']):\n",
    "    if filter:\n",
    "        algol_combinations = [('harris', 'sift_filter'), ('harris', 'star_filter'), ('sift_filter', 'star_filter')]\n",
    "    else:    \n",
    "        algol_combinations = [('harris', 'sift'), ('harris', 'star'), ('sift', 'star')]\n",
    "\n",
    "    df = pd.DataFrame(columns=['combination', 'qtd_kp1', 'qtd_kp2', 'qtd_matches_kp1',\n",
    "                                'qtd_matches_kp2', 'precision_1', 'precision_2'])\n",
    "    \n",
    "    for comb in algol_combinations:\n",
    "        for i,n in enumerate(n_pontos):\n",
    "            image_ = image.copy()\n",
    "            params1 = return_params_combination(comb[0], params_harris, params_sift, params_star, i)\n",
    "            params2 = return_params_combination(comb[1], params_harris, params_sift, params_star, i)\n",
    "            \n",
    "            result = compare_detectors_keypoints(image_, comb[0], comb[1], params1, params2, thresholds[i])\n",
    "            \n",
    "            kp_image, matches_kp1, matches_kp2, kp1, kp2 = result\n",
    "\n",
    "\n",
    "            df.loc[len(df.index)] = [comb, len(kp1), len(kp2), len(matches_kp1), len(matches_kp2), len(matches_kp1) / len(kp1),\n",
    "                               len(matches_kp2) / len(kp2) ]\n",
    "\n",
    "            path_img = f'../results/first_part_detectors/{image_name}_matches_{comb[0]}_{comb[1]}_{n}_pontos.jpg'\n",
    "            cv2.imwrite(path_img, kp_image)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descritores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FunÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def draw_matches(train_img, query_img, trainKeypoints, queryKeypoints, matches, matchesMask):\n",
    "    kps_train = [[trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "    kps_query = [[queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "\n",
    "    # draw the tracks\n",
    "    mask = np.zeros_like(train_img, 'uint8') \n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "    frame = query_img.copy()\n",
    "    \n",
    "    for i, (m, query, train) in enumerate(zip(matchesMask, kps_query, kps_train)):\n",
    "        a, b = query[0], query[1]\n",
    "        c, d = train[0], train[1]\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "        \n",
    "        if m[0] > 0:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2) \n",
    "            frame = cv2.circle(frame, (a, b), 4, point_true, -1)\n",
    "        else:\n",
    "            frame = cv2.circle(frame, (a, b), 4, point_false, -1)\n",
    "    \n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "def return_idx_points_at_distance(pts1, pts2, threshold=1):\n",
    "    array_pts1 = np.asarray(pts1)\n",
    "    array_pts2 = np.asarray(pts2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)\n",
    "        matches = [(i, pos) for i, (pos, dist) in enumerate(zip(dists[0], dists[1])) if dist <= threshold]\n",
    "    else:\n",
    "        matches = []\n",
    "        \n",
    "    return matches\n",
    "\n",
    "\n",
    "def filter_matches(kpts1, kpts2, matches, threshold=1):\n",
    "    kp1 = [(kp.pt[0], kp.pt[1]) for kp in kpts1]\n",
    "    kp2 = [(kp.pt[0], kp.pt[1]) for kp in kpts2]\n",
    "    \n",
    "    matches_distance_idx = return_idx_points_at_distance(kp1, kp2, threshold)\n",
    "    matchesMask_ = [ [1,0] if (m[0].trainIdx, m[0].queryIdx) in matches_distance_idx else [0,0] for m in matches]\n",
    "\n",
    "    return matchesMask_\n",
    "\n",
    "\n",
    "def compare_descriptors(keypoints1, keypoints2, descriptors1,  descriptors2, window_size, threshold):\n",
    "\n",
    "    # Iterate through descriptors in the second image and compare with descriptors in the window\n",
    "    matches = []\n",
    "    for i, descriptor2 in enumerate(descriptors2):\n",
    "        x, y = keypoints2[i].pt\n",
    "        distances = []\n",
    "\n",
    "        # Define the window coordinates\n",
    "        window_x1 = int(x - window_size / 2)\n",
    "        window_y1 = int(y - window_size / 2)\n",
    "        window_x2 = int(x + window_size / 2)\n",
    "        window_y2 = int(y + window_size / 2)\n",
    "\n",
    "        # Ensure the window is within image bounds\n",
    "        for j, descriptor1 in enumerate(descriptors1):\n",
    "            x2, y2 = keypoints1[j].pt\n",
    "            if x2 > window_x1 and y2 > window_y1  and \\\n",
    "                x2 <= window_x2 and y2 <= window_y2 :\n",
    "\n",
    "                # Calculate Euclidean distance between descriptor1 and descriptors in the window\n",
    "                distance = np.linalg.norm(descriptor2 - descriptor1)\n",
    "                distances.append((j, distance))\n",
    "\n",
    "        # Check if any descriptor in the window is below the threshold\n",
    "        distances = sorted(distances, key=lambda x: x[1])\n",
    "        if len(distances) > 0 and distances[0][1] <= threshold:\n",
    "            duplicate = [m for m in matches if distances[0][0] == m[0].queryIdx]\n",
    "            if len(duplicate) > 0: continue\n",
    "            \n",
    "            match = cv2.DMatch(_queryIdx=distances[0][0], _trainIdx=i, _distance=np.min(distances))\n",
    "            matches.append((match, match))\n",
    "    \n",
    "    matches = tuple(tuple(m) for m in matches)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def matchDetectedKeypoints(train_img, query_img, threshold=5, window_size=30, detector='harris', descriptor='sift', dect_kargs={}, des_kargs={}):\n",
    "    query_img_bw = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if descriptor == 'brief':\n",
    "        des = cv2.xfeatures2d.BriefDescriptorExtractor_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    elif descriptor == 'brisk':\n",
    "        des = cv2.BRISK_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    else:\n",
    "        des = cv2.SIFT.create(**des_kargs)\n",
    "        norm_type = cv2.NORM_L2\n",
    "    \n",
    "    if detector == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    elif detector == 'sift_filter':\n",
    "        func_var = detectSIFTKeypointsFilter\n",
    "    elif detector == 'sift':\n",
    "        func_var = detectSIFTKeypoints\n",
    "    elif detector == 'star_filter':\n",
    "        func_var = detectStarKeypointsFilter\n",
    "    else:\n",
    "        func_var = detectStarKeypoints\n",
    "\n",
    "    queryKeypoints, _ = func_var(query_img, **dect_kargs)\n",
    "    trainKeypoints, _ = func_var(train_img, **dect_kargs)\n",
    "    \n",
    "    _,queryDescriptors = des.compute(query_img_bw, queryKeypoints) \n",
    "    _,trainDescriptors = des.compute(train_img_bw, trainKeypoints)\n",
    "\n",
    "    print(len(trainKeypoints))\n",
    "    # matcher = cv2.BFMatcher(normType=norm_type, crossCheck=False) \n",
    "    # matches = matcher.knnMatch(queryDescriptors, trainDescriptors, k=2)\n",
    "\n",
    "    matches = compare_descriptors(queryKeypoints, trainKeypoints, \n",
    "                                  queryDescriptors, trainDescriptors, window_size, threshold)\n",
    "    \n",
    "    # Need to draw only good matches, so create a mask\n",
    "    matchesMask = [[1,0] for i in range(len(matches))]\n",
    "\n",
    "    # for i,(m,n) in enumerate(matches):\n",
    "    #     if m.distance < ratio_test*n.distance:\n",
    "    #         matchesMask[i]=[1,0]\n",
    "\n",
    "    # matchesMask = filter_matches(trainKeypoints, queryKeypoints, matches, threshold=threshold)\n",
    "\n",
    "    draw_params = dict(\n",
    "                    matchColor = (0,255,0),\n",
    "                    singlePointColor = (255,0,0),\n",
    "                    matchesMask = matchesMask,\n",
    "                    flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "    \n",
    "    final_img = cv2.drawMatchesKnn(query_img, queryKeypoints, train_img, trainKeypoints, matches, None,**draw_params)\n",
    "    \n",
    "    qtd_kp_train = len(trainKeypoints)\n",
    "    qtd_kp_query = len(queryKeypoints)\n",
    "    qtd_matches = len(matches)\n",
    "\n",
    "    final_img = cv2.resize(final_img, (1280,480))\n",
    "\n",
    "    return final_img, qtd_kp_train, qtd_kp_query, qtd_matches\n",
    "\n",
    "\n",
    "def return_params_combination_descriptors(combination, params_harris, params_sift, params_star, params_brisk, pos):\n",
    "    if combination == 'harris':\n",
    "        params = {key: value[pos] for key, value in params_harris.items()}\n",
    "    elif combination == 'sift' or combination == 'sift_filter':\n",
    "        params = {key: value[pos] for key, value in params_sift.items()}\n",
    "    elif combination == 'star' or combination == 'star_filter':\n",
    "        params = {key: value[pos] for key, value in params_star.items()}\n",
    "    else:\n",
    "        params = {key: value[pos] for key, value in params_brisk.items()}\n",
    "    return params\n",
    "\n",
    "\n",
    "def run_all_tests_descriptors(train_img, query_img, image_name, params_harris, params_sift, params_star, params_brisk, thresholds={'sift': 100, 'brisk': 1000},\n",
    "                              window_size=50, pos=1, filter=False, n_pontos=['25', '50', '100']):\n",
    "    \n",
    "    if filter:\n",
    "        algol_combinations = [('harris', 'sift'), ('harris', 'brisk'), ('star_filter', 'sift'), ('star_filter', 'brisk'), ('sift_filter', 'sift'), ('sift_filter', 'brisk')]\n",
    "    else:\n",
    "        algol_combinations = [('harris', 'sift'), ('harris', 'brisk'), ('star', 'sift'), ('star', 'brisk'), ('sift', 'sift'), ('sift', 'brisk')]\n",
    "    df = pd.DataFrame(columns=['detector', 'descriptor', 'qtd_kp1', 'qtd_kp2', 'qtd_matches', 'precision_1', 'precision_2'])\n",
    "    \n",
    "    for comb in algol_combinations:\n",
    "        params_det = return_params_combination_descriptors(comb[0], params_harris, params_sift, params_star, params_brisk, pos)\n",
    "        params_des = return_params_combination_descriptors(comb[1], params_harris, params_sift, params_star, params_brisk, pos)\n",
    "        \n",
    "        result = matchDetectedKeypoints(train_img, query_img, thresholds[comb[1]], window_size, detector=comb[0], descriptor=comb[1],\n",
    "                                         dect_kargs=params_det, des_kargs=params_des)\n",
    "        \n",
    "        matches_image, qtd_kp_train, qtd_kp_query, qtd_matches = result\n",
    "\n",
    "\n",
    "        df.loc[len(df.index)] = [comb[0], comb[1], qtd_kp_train, qtd_kp_query, qtd_matches, qtd_matches / qtd_kp_train,\n",
    "                            qtd_matches / qtd_kp_query ]\n",
    "\n",
    "        path_img = f'../results/second_part_descriptors/{image_name}_matches_{comb[0]}_{comb[1]}_{n_pontos[pos]}_pontos.jpg'\n",
    "        cv2.imwrite(path_img, matches_image)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsc07631.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_harris = {\n",
    "    'threshold' : [0.27152, 0.078, 0.053],\n",
    "    'blockSize' : [2, 5, 3],\n",
    "    'ksize' : [3, 5, 9],\n",
    "    'k' : [0.04, 0.04, 0.06]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'nfeatures': [34, 69, 143],\n",
    "    'nOctaveLayers' : [3, 10, 10],\n",
    "    'contrastThreshold' : [0.15, 0.05, 0.01],\n",
    "    'edgeThreshold' : [2, 10, 3],\n",
    "    'sigma' : [1.6, 3.2, 3.2],\n",
    "    'enable_precise_upscale': [True, True, True]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [10, 16, 10],\n",
    "    'response_threshold': [70, 55, 30],\n",
    "    'line_threshold_projected': [10, 5, 5],\n",
    "    'line_threshold_binarized': [10, 5, 5],\n",
    "    'suppress_nonmax_size': [10, 16, 10]\n",
    "}\n",
    "\n",
    "params_brisk = {\n",
    "    # 'patternScale': 0.5\n",
    "    # 'thresh': 30,\n",
    "    # 'octaves': 3,\n",
    "    # 'radiusList': [3, 6, 9, 12],\n",
    "    # 'numberList': [12, 24, 36, 48],\n",
    "    # 'dMax': 30,\n",
    "    # 'dMin': 5\n",
    "    'patternScale': [0.5, 0.5, 0.5]\n",
    "}\n",
    "\n",
    "thresholds = {'sift': 120, 'brisk': 1200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "# train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "# query_img_1_ = cv2.resize(query_img_1, (480,640))\n",
    "# train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "\n",
    "\n",
    "query_img_2 = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img_2 = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "query_img_2_ = cv2.resize(query_img_2, (640,480))\n",
    "train_img_2_ = cv2.resize(train_img_2, (640,480))\n",
    "\n",
    "# query_img_3 = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "# train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "# query_img_3_ = cv2.resize(query_img_3, (480,640))\n",
    "# train_img_3_ = cv2.resize(train_img_3, (480,640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "51\n",
      "51\n",
      "50\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>qtd_kp1</th>\n",
       "      <th>qtd_kp2</th>\n",
       "      <th>qtd_matches</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harris</td>\n",
       "      <td>sift</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harris</td>\n",
       "      <td>brisk</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>34</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star</td>\n",
       "      <td>sift</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.607843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>star</td>\n",
       "      <td>brisk</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>33</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sift</td>\n",
       "      <td>sift</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.531915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sift</td>\n",
       "      <td>brisk</td>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>37</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  detector descriptor  qtd_kp1  qtd_kp2  qtd_matches  precision_1  precision_2\n",
       "0   harris       sift       50       50           40     0.800000     0.800000\n",
       "1   harris      brisk       50       50           34     0.680000     0.680000\n",
       "2     star       sift       51       51           31     0.607843     0.607843\n",
       "3     star      brisk       51       51           33     0.647059     0.647059\n",
       "4     sift       sift       50       47           25     0.500000     0.531915\n",
       "5     sift      brisk       50       47           37     0.740000     0.787234"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_all_tests_descriptors(train_img_2_, query_img_2_,'dsc07631', params_harris, params_sift, params_star, params_brisk, thresholds=thresholds, window_size=50, pos=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dect_kargs = {k: v[1] for k, v in params_harris.items()}\n",
    "des_kargs = {k: v[1] for k, v in params_sift.items()}\n",
    "final_image,_,_,_ = matchDetectedKeypoints(train_img_2, query_img_2, window_size=50, threshold=1000, detector='harris', descriptor='sift', dect_kargs=dect_kargs, des_kargs=des_kargs)\n",
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsc02651.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_harris = {\n",
    "    'threshold' : [0.43, 0.33, 0.14],\n",
    "    'blockSize' : [3, 6, 6],\n",
    "    'ksize' : [3, 5, 5],\n",
    "    'k' : [0.04, 0.04, 0.04]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'nfeatures': [37, 60, 125],\n",
    "    'nOctaveLayers' : [3, 10, 10],\n",
    "    'contrastThreshold' : [0.15, 0.05, 0.01],\n",
    "    'edgeThreshold' : [2, 10, 3],\n",
    "    'sigma' : [1.6, 3.2, 3.2],\n",
    "    'enable_precise_upscale': [True, True, True]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [11, 16, 16],\n",
    "    'response_threshold': [71, 64, 48],\n",
    "    'line_threshold_projected': [10, 6, 5],\n",
    "    'line_threshold_binarized': [5, 6, 5],\n",
    "    'suppress_nonmax_size': [8, 16, 8]\n",
    "}\n",
    "\n",
    "params_brisk = {\n",
    "    # 'patternScale': 0.5\n",
    "    # 'thresh': 30,\n",
    "    # 'octaves': 3,\n",
    "    # 'radiusList': [3, 6, 9, 12],\n",
    "    # 'numberList': [12, 24, 36, 48],\n",
    "    # 'dMax': 30,\n",
    "    # 'dMin': 5\n",
    "    'patternScale': [0.5, 0.5, 0.5]\n",
    "}\n",
    "\n",
    "thresholds = {'sift': 400, 'brisk': 1200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "# train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "# query_img_1_ = cv2.resize(query_img_1, (480,640))\n",
    "# train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "\n",
    "\n",
    "query_img_2 = cv2.imread('../data/imgs/dsc02652.jpg') \n",
    "train_img_2 = cv2.imread('../data/imgs/dsc02651.jpg')\n",
    "query_img_2_ = cv2.resize(query_img_2, (640,480))\n",
    "train_img_2_ = cv2.resize(train_img_2, (640,480))\n",
    "\n",
    "# query_img_3 = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "# train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "# query_img_3_ = cv2.resize(query_img_3, (480,640))\n",
    "# train_img_3_ = cv2.resize(train_img_3, (480,640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>qtd_kp1</th>\n",
       "      <th>qtd_kp2</th>\n",
       "      <th>qtd_matches</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harris</td>\n",
       "      <td>sift</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.788462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harris</td>\n",
       "      <td>brisk</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star</td>\n",
       "      <td>sift</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>star</td>\n",
       "      <td>brisk</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sift</td>\n",
       "      <td>sift</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.568182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sift</td>\n",
       "      <td>brisk</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  detector descriptor  qtd_kp1  qtd_kp2  qtd_matches  precision_1  precision_2\n",
       "0   harris       sift       50       52           41         0.82     0.788462\n",
       "1   harris      brisk       50       52           28         0.56     0.538462\n",
       "2     star       sift       50       49           37         0.74     0.755102\n",
       "3     star      brisk       50       49           31         0.62     0.632653\n",
       "4     sift       sift       50       44           25         0.50     0.568182\n",
       "5     sift      brisk       50       44           31         0.62     0.704545"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_all_tests_descriptors(train_img_2_, query_img_2_, 'dsc02651', params_harris, params_sift, params_star, params_brisk, thresholds=thresholds, window_size=30, pos=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dect_kargs = {k: v[1] for k, v in params_harris.items()}\n",
    "des_kargs = {k: v[1] for k, v in params_brisk.items()}\n",
    "final_image,_,_,_ = matchDetectedKeypoints(train_img_2_, query_img_2_, window_size=30, threshold=1200, detector='harris', descriptor='brisk', dect_kargs=dect_kargs, des_kargs=des_kargs)\n",
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMG-20240114-WA0043.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_harris = {\n",
    "    'threshold' : [0.005],\n",
    "    'blockSize' : [6],\n",
    "    'ksize' : [3],\n",
    "    'k' : [0.04]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'nfeatures': [55],\n",
    "    'nOctaveLayers' : [1],\n",
    "    'contrastThreshold' : [0.02],\n",
    "    'edgeThreshold' : [5],\n",
    "    'sigma' : [1.6],\n",
    "    'enable_precise_upscale': [True]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [10],\n",
    "    'response_threshold': [10],\n",
    "    'line_threshold_projected': [5],\n",
    "    'line_threshold_binarized': [5],\n",
    "    'suppress_nonmax_size': [1]\n",
    "}\n",
    "\n",
    "\n",
    "params_brisk = {\n",
    "    # 'patternScale': 0.5\n",
    "    # 'thresh': 30,\n",
    "    # 'octaves': 3,\n",
    "    # 'radiusList': [3, 6, 9, 12],\n",
    "    # 'numberList': [12, 24, 36, 48],\n",
    "    # 'dMax': 30,\n",
    "    # 'dMin': 5\n",
    "    'patternScale': [0.5]\n",
    "}\n",
    "\n",
    "thresholds = {'sift': 400, 'brisk': 1200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "# train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "# query_img_1_ = cv2.resize(query_img_1, (480,640))\n",
    "# train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "\n",
    "\n",
    "query_img_2 = cv2.imread('../data/imgs_teste_3/IMG-20240114-WA0044.jpg')\n",
    "train_img_2 = cv2.imread('../data/imgs_teste_3/IMG-20240114-WA0043.jpg')\n",
    "query_img_2_ = cv2.resize(query_img_2, (640,480))\n",
    "train_img_2_ = cv2.resize(train_img_2, (640,480))\n",
    "\n",
    "# query_img_3 = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "# train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "# query_img_3_ = cv2.resize(query_img_3, (480,640))\n",
    "# train_img_3_ = cv2.resize(train_img_3, (480,640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "22\n",
      "21\n",
      "21\n",
      "25\n",
      "25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>qtd_kp1</th>\n",
       "      <th>qtd_kp2</th>\n",
       "      <th>qtd_matches</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>precision_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harris</td>\n",
       "      <td>sift</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harris</td>\n",
       "      <td>brisk</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star_filter</td>\n",
       "      <td>sift</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>star_filter</td>\n",
       "      <td>brisk</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sift_filter</td>\n",
       "      <td>sift</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sift_filter</td>\n",
       "      <td>brisk</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      detector descriptor  qtd_kp1  qtd_kp2  qtd_matches  precision_1  \\\n",
       "0       harris       sift       22       22           22     1.000000   \n",
       "1       harris      brisk       22       22           20     0.909091   \n",
       "2  star_filter       sift       21       21           21     1.000000   \n",
       "3  star_filter      brisk       21       21           18     0.857143   \n",
       "4  sift_filter       sift       25       25           23     0.920000   \n",
       "5  sift_filter      brisk       25       25           17     0.680000   \n",
       "\n",
       "   precision_2  \n",
       "0     1.000000  \n",
       "1     0.909091  \n",
       "2     1.000000  \n",
       "3     0.857143  \n",
       "4     0.920000  \n",
       "5     0.680000  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_all_tests_descriptors(train_img_2_, query_img_2_, 'IMG-20240114-WA0043', params_harris, params_sift, params_star, params_brisk, thresholds=thresholds, window_size=50, pos=0,\n",
    "                          filter=True, n_pontos=['20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dect_kargs = {k: v[0] for k, v in params_sift.items()}\n",
    "des_kargs = {k: v[0] for k, v in params_sift.items()}\n",
    "final_image,_,_,_ = matchDetectedKeypoints(train_img_2_, query_img_2_, window_size=50, threshold=1200, detector='sift_filter', descriptor='sift', dect_kargs=dect_kargs, des_kargs=des_kargs)\n",
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
