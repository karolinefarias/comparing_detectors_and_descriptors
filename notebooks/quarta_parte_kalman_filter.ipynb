{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando Kalman-Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.04):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "\n",
    "    # Applying the function \n",
    "    dst = cv2.cornerHarris(gray_image_f32, blockSize, ksize, k) \n",
    "  \n",
    "    # dilate to mark the corners \n",
    "    dst = cv2.dilate(dst, None)\n",
    "    \n",
    "    ret, dst = cv2.threshold(dst,threshold*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # draw keypoints\n",
    "    # image[dst > threshold * dst.max()] = [0, 255, 0]\n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(255, 0, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSIFTKeypoints(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None)\n",
    "    not_dup_kp = {pt.pt: pt for pt in kp}\n",
    "    kp_ = list(not_dup_kp.values())\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp_, None, color=(0, 255, 0), flags=0)\n",
    "\n",
    "    return kp_, kp_image \n",
    "\n",
    "def detectSIFTKeypointsFilter(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None)\n",
    "    not_dup_kp = {pt.pt: pt for pt in kp}\n",
    "    kp_ = list(not_dup_kp.values())\n",
    "    \n",
    "    altura, largura = image.shape[:2]\n",
    "    imagem_binaria = np.zeros((altura, largura), dtype=np.uint8)\n",
    "    for kp in kp_:\n",
    "        x, y = map(int, kp.pt)\n",
    "        cv2.circle(imagem_binaria, (x, y), 5, 255, -1)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(imagem_binaria)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "    \n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectStarKeypoints(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kp = star.detect(gray_image, None)\n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return kp, kp_image \n",
    "\n",
    "\n",
    "def detectStarKeypointsFilter(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kps = star.detect(gray_image, None)\n",
    "\n",
    "    altura, largura = image.shape[:2]\n",
    "    imagem_binaria = np.zeros((altura, largura), dtype=np.uint8)\n",
    "    for kp in kps:\n",
    "        x, y = map(int, kp.pt)\n",
    "        cv2.circle(imagem_binaria, (x, y), 5, 255, -1)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(imagem_binaria)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return keypoints, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "def computeDistacesKeypoints(pts1, pts2, threshold=1):\n",
    "    array_pts1 = np.asarray(pts1)\n",
    "    array_pts2 = np.asarray(pts2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)\n",
    "        matches_pts1 = [pts1[i] for i, (pt, dist) in enumerate(zip(dists[0], dists[1])) if dist <= threshold]\n",
    "        matches_pts2 = [pts2[pt] for pt, dist in zip(dists[0], dists[1]) if dist <= threshold]\n",
    "    else:\n",
    "        matches_pts1 = []\n",
    "        matches_pts2 = []\n",
    "        \n",
    "    return matches_pts1, matches_pts2\n",
    "\n",
    "\n",
    "def return_detector_func(algol):\n",
    "    if algol == 'harris':\n",
    "        func = detectHarrisKeypoints\n",
    "    elif algol == 'sift_filter':\n",
    "        func = detectSIFTKeypointsFilter\n",
    "    elif algol == 'sift':\n",
    "        func = detectSIFTKeypoints\n",
    "    elif algol == 'star_filter':\n",
    "        func = detectStarKeypointsFilter\n",
    "    else:\n",
    "        func = detectStarKeypoints\n",
    "    \n",
    "    return func\n",
    "\n",
    "\n",
    "def compare_detectors_keypoints(image, algol_1, algol_2, params_algol_1, params_algol_2, threshold):\n",
    "    detector_1 = return_detector_func(algol_1)\n",
    "    detector_2 = return_detector_func(algol_2)\n",
    "\n",
    "    kp1, _ = detector_1(image, **params_algol_1)\n",
    "    kp2, _ = detector_2(image, **params_algol_2)\n",
    "\n",
    "    kp1 = [(kp.pt[0], kp.pt[1]) for kp in kp1]\n",
    "    kp2 = [(kp.pt[0], kp.pt[1]) for kp in kp2]\n",
    "\n",
    "    matches_pts1, matches_pts2 = computeDistacesKeypoints(kp1, kp2, threshold=threshold)\n",
    "    mismatches_pts1 = [pt for pt in kp1 if pt not in matches_pts1]\n",
    "    mismatches_pts2 = [pt for pt in kp2 if pt not in matches_pts2]\n",
    "\n",
    "    matches_kp1 = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in matches_pts1]\n",
    "    matches_kp2 = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in matches_pts2]\n",
    "\n",
    "    mismatches_kp1 = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in mismatches_pts1]\n",
    "    mismatches_kp2 = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in mismatches_pts2]\n",
    "\n",
    "    kp_image = cv2.drawKeypoints(image, matches_kp1, None, color=(0, 255, 0), flags=0)\n",
    "    kp_image = cv2.drawKeypoints(kp_image, matches_kp2, None, color=(0, 255, 0), flags=0)\n",
    "    kp_image = cv2.drawKeypoints(kp_image, mismatches_kp1, None, color=(255, 0, 0), flags=0)\n",
    "    kp_image = cv2.drawKeypoints(kp_image, mismatches_kp2, None, color=(0, 0, 255), flags=0)\n",
    "\n",
    "    return kp_image, matches_kp1, matches_kp2, kp1, kp2 \n",
    "\n",
    "def return_params_combination(combination, params_harris, params_sift, params_star, pos):\n",
    "    if combination == 'harris':\n",
    "        params = {key: value[pos] for key, value in zip(params_harris.keys(), params_harris.values())}\n",
    "    elif combination == 'sift' or combination == 'sift_filter':\n",
    "        params = {key: value[pos] for key, value in zip(params_sift.keys(), params_sift.values())}\n",
    "    else:\n",
    "        params = {key: value[pos] for key, value in zip(params_star.keys(), params_star.values())}\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def run_all_tests(image, image_name, params_harris, params_sift, params_star, thresholds, filter=False, n_pontos=['25', '50', '100']):\n",
    "    if filter:\n",
    "        algol_combinations = [('harris', 'sift_filter'), ('harris', 'star_filter'), ('sift_filter', 'star_filter')]\n",
    "    else:    \n",
    "        algol_combinations = [('harris', 'sift'), ('harris', 'star'), ('sift', 'star')]\n",
    "\n",
    "    df = pd.DataFrame(columns=['combination', 'qtd_kp1', 'qtd_kp2', 'qtd_matches_kp1',\n",
    "                                'qtd_matches_kp2', 'precision_1', 'precision_2'])\n",
    "    \n",
    "    for comb in algol_combinations:\n",
    "        for i,n in enumerate(n_pontos):\n",
    "            image_ = image.copy()\n",
    "            params1 = return_params_combination(comb[0], params_harris, params_sift, params_star, i)\n",
    "            params2 = return_params_combination(comb[1], params_harris, params_sift, params_star, i)\n",
    "            \n",
    "            result = compare_detectors_keypoints(image_, comb[0], comb[1], params1, params2, thresholds[i])\n",
    "            \n",
    "            kp_image, matches_kp1, matches_kp2, kp1, kp2 = result\n",
    "\n",
    "\n",
    "            df.loc[len(df.index)] = [comb, len(kp1), len(kp2), len(matches_kp1), len(matches_kp2), len(matches_kp1) / len(kp1),\n",
    "                               len(matches_kp2) / len(kp2) ]\n",
    "\n",
    "            path_img = f'../results/first_part_detectors/{image_name}_matches_{comb[0]}_{comb[1]}_{n}_pontos.jpg'\n",
    "            cv2.imwrite(path_img, kp_image)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def draw_matches(train_img, query_img, trainKeypoints, queryKeypoints, matches, matchesMask):\n",
    "    kps_train = [[trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "    kps_query = [[queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "\n",
    "    # draw the tracks\n",
    "    mask = np.zeros_like(train_img, 'uint8') \n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "    frame = query_img.copy()\n",
    "    \n",
    "    for i, (m, query, train) in enumerate(zip(matchesMask, kps_query, kps_train)):\n",
    "        a, b = query[0], query[1]\n",
    "        c, d = train[0], train[1]\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "        \n",
    "        if m[0] > 0:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2) \n",
    "            frame = cv2.circle(frame, (a, b), 4, point_true, -1)\n",
    "        else:\n",
    "            frame = cv2.circle(frame, (a, b), 4, point_false, -1)\n",
    "    \n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "def return_idx_points_at_distance(pts1, pts2, threshold=1):\n",
    "    array_pts1 = np.asarray(pts1)\n",
    "    array_pts2 = np.asarray(pts2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)\n",
    "        matches = [(i, pos) for i, (pos, dist) in enumerate(zip(dists[0], dists[1])) if dist <= threshold]\n",
    "    else:\n",
    "        matches = []\n",
    "        \n",
    "    return matches\n",
    "\n",
    "\n",
    "def filter_matches(kpts1, kpts2, matches, threshold=1):\n",
    "    kp1 = [(kp.pt[0], kp.pt[1]) for kp in kpts1]\n",
    "    kp2 = [(kp.pt[0], kp.pt[1]) for kp in kpts2]\n",
    "    \n",
    "    matches_distance_idx = return_idx_points_at_distance(kp1, kp2, threshold)\n",
    "    matchesMask_ = [ [1,0] if (m[0].trainIdx, m[0].queryIdx) in matches_distance_idx else [0,0] for m in matches]\n",
    "\n",
    "    return matchesMask_\n",
    "\n",
    "\n",
    "def compare_descriptors(keypoints1, keypoints2, descriptors1,  descriptors2, window_size, threshold):\n",
    "\n",
    "    # Iterate through descriptors in the second image and compare with descriptors in the window\n",
    "    matches = []\n",
    "    for i, descriptor2 in enumerate(descriptors2):\n",
    "        x, y = keypoints2[i].pt\n",
    "        distances = []\n",
    "\n",
    "        # Define the window coordinates\n",
    "        window_x1 = int(x - window_size / 2)\n",
    "        window_y1 = int(y - window_size / 2)\n",
    "        window_x2 = int(x + window_size / 2)\n",
    "        window_y2 = int(y + window_size / 2)\n",
    "\n",
    "        # Ensure the window is within image bounds\n",
    "        for j, descriptor1 in enumerate(descriptors1):\n",
    "            x2, y2 = keypoints1[j].pt\n",
    "            if x2 > window_x1 and y2 > window_y1  and \\\n",
    "                x2 <= window_x2 and y2 <= window_y2 :\n",
    "\n",
    "                # Calculate Euclidean distance between descriptor1 and descriptors in the window\n",
    "                distance = np.linalg.norm(descriptor2 - descriptor1)\n",
    "                distances.append((j, distance))\n",
    "\n",
    "        # Check if any descriptor in the window is below the threshold\n",
    "        distances = sorted(distances, key=lambda x: x[1])\n",
    "        if len(distances) > 0 and distances[0][1] <= threshold:\n",
    "            duplicate = [m for m in matches if distances[0][0] == m[0].queryIdx]\n",
    "            if len(duplicate) > 0: continue\n",
    "            \n",
    "            match = cv2.DMatch(_queryIdx=distances[0][0], _trainIdx=i, _distance=np.min(distances))\n",
    "            matches.append((match, match))\n",
    "    \n",
    "    matches = tuple(tuple(m) for m in matches)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def matchDetectedKeypoints(train_img, query_img, threshold=5, window_size=30, detector='harris', descriptor='sift', dect_kargs={}, des_kargs={}):\n",
    "    query_img_bw = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if descriptor == 'brief':\n",
    "        des = cv2.xfeatures2d.BriefDescriptorExtractor_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    elif descriptor == 'brisk':\n",
    "        des = cv2.BRISK_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    else:\n",
    "        des = cv2.SIFT.create(**des_kargs)\n",
    "        norm_type = cv2.NORM_L2\n",
    "    \n",
    "    if detector == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    elif detector == 'sift_filter':\n",
    "        func_var = detectSIFTKeypointsFilter\n",
    "    elif detector == 'sift':\n",
    "        func_var = detectSIFTKeypoints\n",
    "    elif detector == 'star_filter':\n",
    "        func_var = detectStarKeypointsFilter\n",
    "    else:\n",
    "        func_var = detectStarKeypoints\n",
    "\n",
    "    queryKeypoints, _ = func_var(query_img, **dect_kargs)\n",
    "    trainKeypoints, _ = func_var(train_img, **dect_kargs)\n",
    "    \n",
    "    _,queryDescriptors = des.compute(query_img_bw, queryKeypoints) \n",
    "    _,trainDescriptors = des.compute(train_img_bw, trainKeypoints)\n",
    "\n",
    "    print(len(trainKeypoints))\n",
    "    # matcher = cv2.BFMatcher(normType=norm_type, crossCheck=False) \n",
    "    # matches = matcher.knnMatch(queryDescriptors, trainDescriptors, k=2)\n",
    "\n",
    "    matches = compare_descriptors(queryKeypoints, trainKeypoints, \n",
    "                                  queryDescriptors, trainDescriptors, window_size, threshold)\n",
    "    \n",
    "    # Need to draw only good matches, so create a mask\n",
    "    matchesMask = [[1,0] for i in range(len(matches))]\n",
    "\n",
    "    # for i,(m,n) in enumerate(matches):\n",
    "    #     if m.distance < ratio_test*n.distance:\n",
    "    #         matchesMask[i]=[1,0]\n",
    "\n",
    "    # matchesMask = filter_matches(trainKeypoints, queryKeypoints, matches, threshold=threshold)\n",
    "\n",
    "    draw_params = dict(\n",
    "                    matchColor = (0,255,0),\n",
    "                    singlePointColor = (255,0,0),\n",
    "                    matchesMask = matchesMask,\n",
    "                    flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "    \n",
    "    final_img = cv2.drawMatchesKnn(query_img, queryKeypoints, train_img, trainKeypoints, matches, None,**draw_params)\n",
    "    \n",
    "    qtd_kp_train = len(trainKeypoints)\n",
    "    qtd_kp_query = len(queryKeypoints)\n",
    "    qtd_matches = len(matches)\n",
    "\n",
    "    final_img = cv2.resize(final_img, (1280,480))\n",
    "\n",
    "    return final_img, qtd_kp_train, qtd_kp_query, qtd_matches\n",
    "\n",
    "\n",
    "def return_params_combination_descriptors(combination, params_harris, params_sift, params_star, params_brisk, pos):\n",
    "    if combination == 'harris':\n",
    "        params = {key: value[pos] for key, value in params_harris.items()}\n",
    "    elif combination == 'sift' or combination == 'sift_filter':\n",
    "        params = {key: value[pos] for key, value in params_sift.items()}\n",
    "    elif combination == 'star' or combination == 'star_filter':\n",
    "        params = {key: value[pos] for key, value in params_star.items()}\n",
    "    else:\n",
    "        params = {key: value[pos] for key, value in params_brisk.items()}\n",
    "    return params\n",
    "\n",
    "\n",
    "def run_all_tests_descriptors(train_img, query_img, image_name, params_harris, params_sift, params_star, params_brisk, thresholds={'sift': 100, 'brisk': 1000},\n",
    "                              window_size=50, pos=1, filter=False, n_pontos=['25', '50', '100']):\n",
    "    \n",
    "    if filter:\n",
    "        algol_combinations = [('harris', 'sift'), ('harris', 'brisk'), ('star_filter', 'sift'), ('star_filter', 'brisk'), ('sift_filter', 'sift'), ('sift_filter', 'brisk')]\n",
    "    else:\n",
    "        algol_combinations = [('harris', 'sift'), ('harris', 'brisk'), ('star', 'sift'), ('star', 'brisk'), ('sift', 'sift'), ('sift', 'brisk')]\n",
    "    df = pd.DataFrame(columns=['detector', 'descriptor', 'qtd_kp1', 'qtd_kp2', 'qtd_matches', 'precision_1', 'precision_2'])\n",
    "    \n",
    "    for comb in algol_combinations:\n",
    "        params_det = return_params_combination_descriptors(comb[0], params_harris, params_sift, params_star, params_brisk, pos)\n",
    "        params_des = return_params_combination_descriptors(comb[1], params_harris, params_sift, params_star, params_brisk, pos)\n",
    "        \n",
    "        result = matchDetectedKeypoints(train_img, query_img, thresholds[comb[1]], window_size, detector=comb[0], descriptor=comb[1],\n",
    "                                         dect_kargs=params_det, des_kargs=params_des)\n",
    "        \n",
    "        matches_image, qtd_kp_train, qtd_kp_query, qtd_matches = result\n",
    "\n",
    "\n",
    "        df.loc[len(df.index)] = [comb[0], comb[1], qtd_kp_train, qtd_kp_query, qtd_matches, qtd_matches / qtd_kp_train,\n",
    "                            qtd_matches / qtd_kp_query ]\n",
    "\n",
    "        path_img = f'../results/second_part_descriptors/{image_name}_matches_{comb[0]}_{comb[1]}_{n_pontos[pos]}_pontos.jpg'\n",
    "        cv2.imwrite(path_img, matches_image)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def return_params_combination_optflow(combination, params_harris, params_sift, params_star, pos):\n",
    "    if combination == 'harris':\n",
    "        params = {key: value[pos] for key, value in params_harris.items()}\n",
    "    elif combination == 'sift' or combination == 'sift_filter':\n",
    "        params = {key: value[pos] for key, value in params_sift.items()}\n",
    "    else:\n",
    "        params = {key: value[pos] for key, value in params_star.items()}\n",
    "    return params\n",
    "\n",
    "\n",
    "def lucas_kanade_opflow(train_img, query_img, func_detector, feature_params, lk_params):\n",
    "    \n",
    "    # Take first frame and find corners in it \n",
    "    old_frame = train_img.copy() \n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "    kps,_ = func_detector(old_frame, **feature_params)\n",
    "    p0 = np.array([[[int(kp.pt[0]), int(kp.pt[1])]] for kp in kps])\n",
    "    p0 = p0.astype(np.float32)\n",
    "\n",
    "    # Create a mask image for drawing purposes \n",
    "\n",
    "    mask = np.zeros_like(old_frame, 'uint8') \n",
    "    \n",
    "    frame = query_img.copy()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # calculate optical flow \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params) \n",
    "\n",
    "    # Select good points \n",
    "    good_new = p1[st == 1] \n",
    "    good_old = p0[st == 1]\n",
    "    \n",
    "    print(p1)\n",
    "\n",
    "    # good_old_, good_new_ = filter_by_variance(good_old, good_new, var_dist, var_slope)\n",
    "    # dists = calculate_distance_points(good_old_, good_new_)\n",
    "    # slopes = calculate_slope_points(good_old_, good_new_)\n",
    "    \n",
    "    # var_dist_ = np.var(dists)\n",
    "    # var_slope_ = np.var(slopes)\n",
    "    \n",
    "    qtd_matches = len(p1)\n",
    "    qtd_matches_filtered = len(good_new)\n",
    "    qtd_fp = qtd_matches - qtd_matches_filtered\n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (old, new) in enumerate(zip(good_old, good_new)):\n",
    "        a, b = old.ravel() \n",
    "        c, d = new.ravel()\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "\n",
    "        mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "        old_frame = cv2.circle(old_frame, (a, b), 3, point_true, 2)\n",
    "        frame = cv2.circle(frame, (c, d), 3, point_true, 2)\n",
    "        \n",
    "        # if new in good_new_:\n",
    "        #     mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "        #     frame = cv2.circle(frame, (a, b), 5, point_true, -1) \n",
    "        # else:\n",
    "        #     mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "        #     frame = cv2.circle(frame, (a, b), 5, point_false, -1)\n",
    "            \n",
    "    img = cv2.add(old_frame, mask)\n",
    "\n",
    "    return img, frame, qtd_matches, qtd_matches_filtered, qtd_fp\n",
    "\n",
    "\n",
    "def run_all_tests_lk(train_img, query_img, image_name, params_harris, params_sift, params_star, lk_params, pos):\n",
    "    n_pontos = [25, 50, 100]\n",
    "    algol_combinations = [('harris', 'lucas-kanade'), ('sift', 'lucas-kanade'), ('star', 'lucas-kanade')]\n",
    "    df = pd.DataFrame(columns=['detector', 'optical_flow', 'qtd_matches', 'qtd_good_matches', 'precision'])\n",
    "\n",
    "    for comb in algol_combinations:\n",
    "        if comb[0] == 'star':\n",
    "            func_var = detectStarKeypoints\n",
    "        elif comb[0] == 'harris':\n",
    "            func_var = detectHarrisKeypoints\n",
    "        else:\n",
    "            func_var = detectSIFTKeypoints\n",
    "        \n",
    "        params_det = return_params_combination_optflow(comb[0], params_harris, params_sift, params_star, pos)\n",
    "        \n",
    "        result = lucas_kanade_opflow(train_img, query_img, func_var, params_det, lk_params)\n",
    "        \n",
    "        imge_flow, new_points, qtd_matches, qtd_good_matches, _ = result\n",
    "\n",
    "        df.loc[len(df.index)] = [comb[0], comb[1], qtd_matches, qtd_good_matches, qtd_good_matches / qtd_matches ]\n",
    "\n",
    "        path_img = f'../results/third_part_optical_flow/{image_name}_matches_{comb[0]}_{comb[1]}_{n_pontos[pos]}_pontos.jpg'\n",
    "        cv2.imwrite(path_img, imge_flow)\n",
    "\n",
    "        path_img = f'../results/third_part_optical_flow/{image_name}_detected_{comb[0]}_{comb[1]}_{n_pontos[pos]}_pontos.jpg'\n",
    "        cv2.imwrite(path_img, new_points)\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsc07631.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lk_params = dict( winSize = (32, 32), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "\n",
    "params_harris = {\n",
    "    'threshold' : [0.27152, 0.078, 0.053],\n",
    "    'blockSize' : [2, 5, 3],\n",
    "    'ksize' : [3, 5, 9],\n",
    "    'k' : [0.04, 0.04, 0.06]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'nfeatures': [34, 69, 143],\n",
    "    'nOctaveLayers' : [3, 10, 10],\n",
    "    'contrastThreshold' : [0.15, 0.05, 0.01],\n",
    "    'edgeThreshold' : [2, 10, 3],\n",
    "    'sigma' : [1.6, 3.2, 3.2],\n",
    "    'enable_precise_upscale': [True, True, True]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [10, 16, 10],\n",
    "    'response_threshold': [70, 55, 30],\n",
    "    'line_threshold_projected': [10, 5, 5],\n",
    "    'line_threshold_binarized': [10, 5, 5],\n",
    "    'suppress_nonmax_size': [10, 16, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "# query_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "# train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "\n",
    "# query_img_1_ = cv2.resize(query_img_1, (480,640))\n",
    "# train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "\n",
    "query_img_2 = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img_2 = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "\n",
    "query_img_2_ = cv2.resize(query_img_2, (640,480))\n",
    "train_img_2_ = cv2.resize(train_img_2, (640,480))\n",
    "\n",
    "# query_img_3 = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "# train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "\n",
    "# query_img_3_ = cv2.resize(query_img_3, (480,640))\n",
    "# train_img_3_ = cv2.resize(train_img_3, (480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>optical_flow</th>\n",
       "      <th>qtd_matches</th>\n",
       "      <th>qtd_good_matches</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harris</td>\n",
       "      <td>lucas-kanade</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sift</td>\n",
       "      <td>lucas-kanade</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star</td>\n",
       "      <td>lucas-kanade</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  detector  optical_flow  qtd_matches  qtd_good_matches  precision\n",
       "0   harris  lucas-kanade           50                49       0.98\n",
       "1     sift  lucas-kanade           50                50       1.00\n",
       "2     star  lucas-kanade           51                51       1.00"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run_all_tests_lk(train_img_2, query_img_2, 'dsc07631', params_harris, params_sift, params_star, lk_params, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[296.184    247.10135 ]]\n",
      "\n",
      " [[111.65102   34.86127 ]]\n",
      "\n",
      " [[125.621124  45.99446 ]]\n",
      "\n",
      " [[383.78256   50.795044]]\n",
      "\n",
      " [[372.7966    55.70113 ]]\n",
      "\n",
      " [[507.5251    63.799477]]\n",
      "\n",
      " [[290.69403   83.29393 ]]\n",
      "\n",
      " [[442.00928   82.399895]]\n",
      "\n",
      " [[276.6931    83.22663 ]]\n",
      "\n",
      " [[177.48549   84.86171 ]]\n",
      "\n",
      " [[412.2274    92.10363 ]]\n",
      "\n",
      " [[293.69623   96.26154 ]]\n",
      "\n",
      " [[193.43788   97.01095 ]]\n",
      "\n",
      " [[375.24423  102.31924 ]]\n",
      "\n",
      " [[208.41582  108.22109 ]]\n",
      "\n",
      " [[347.29407  111.0738  ]]\n",
      "\n",
      " [[222.21272  130.40633 ]]\n",
      "\n",
      " [[286.16376  129.09924 ]]\n",
      "\n",
      " [[609.20197  135.65182 ]]\n",
      "\n",
      " [[262.0456   136.94724 ]]\n",
      "\n",
      " [[285.0687   140.07455 ]]\n",
      "\n",
      " [[558.0479   146.53944 ]]\n",
      "\n",
      " [[521.67847  155.19608 ]]\n",
      "\n",
      " [[452.0867   170.98648 ]]\n",
      "\n",
      " [[420.2771   178.78575 ]]\n",
      "\n",
      " [[380.35706  188.1092  ]]\n",
      "\n",
      " [[147.07332  191.75186 ]]\n",
      "\n",
      " [[351.4615   195.95439 ]]\n",
      "\n",
      " [[287.38287  210.03508 ]]\n",
      "\n",
      " [[262.24817  216.98712 ]]\n",
      "\n",
      " [[576.9174   261.8092  ]]\n",
      "\n",
      " [[538.41876  268.50897 ]]\n",
      "\n",
      " [[464.09357  280.6247  ]]\n",
      "\n",
      " [[430.27032  286.43134 ]]\n",
      "\n",
      " [[114.870415 283.77933 ]]\n",
      "\n",
      " [[387.45245  292.92676 ]]\n",
      "\n",
      " [[357.52194  298.83786 ]]\n",
      "\n",
      " [[-29.52919  324.7728  ]]\n",
      "\n",
      " [[289.39877  309.16223 ]]\n",
      "\n",
      " [[263.366    314.1117  ]]\n",
      "\n",
      " [[474.17538  390.32425 ]]\n",
      "\n",
      " [[438.3642   393.22708 ]]\n",
      "\n",
      " [[394.62112  396.93927 ]]\n",
      "\n",
      " [[361.70535  399.85114 ]]\n",
      "\n",
      " [[ 43.653988 401.62262 ]]\n",
      "\n",
      " [[291.615    404.40115 ]]\n",
      "\n",
      " [[264.58832  407.35904 ]]\n",
      "\n",
      " [[ 51.641727 406.6293  ]]\n",
      "\n",
      " [[573.7579   422.67365 ]]\n",
      "\n",
      " [[102.15545  439.05563 ]]]\n",
      "---- Resultado ---- \n",
      "Quantidade de matches: 50\n",
      "Quantidade de matches filtro outliers: 49\n",
      "Quantidade de falso positivo: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params for corner detection \n",
    "feature_params = dict( maxCorners = 53, \n",
    "                       qualityLevel = 0.02, \n",
    "                       minDistance = 3, \n",
    "                       blockSize = 3,\n",
    "                       useHarrisDetector = False)\n",
    "\n",
    "dect_kargs = {k: v[1] for k, v in params_harris.items()}\n",
    "func_var = detectHarrisKeypoints\n",
    "\n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = dict( winSize = (32, 32), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "  \n",
    "\n",
    "lk_result = lucas_kanade_opflow(train_img_2, query_img_2, func_var, dect_kargs, lk_params)\n",
    "\n",
    "img, img2, qtd_matches, qtd_matches_filtered, qtd_fp = lk_result\n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de matches filtro outliers: {qtd_matches_filtered}')\n",
    "print(f'Quantidade de falso positivo: {qtd_fp}')\n",
    "\n",
    "cv2.imshow('frame', img)\n",
    "cv2.imshow('frame2', img2)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsc02651.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_params = {\n",
    "    'maxCorners' : [25, 50, 100], \n",
    "    'qualityLevel' : [0.02, 0.05, 0.1],\n",
    "    'minDistance' : [3, 7, 9], \n",
    "    'blockSize' : [3, 7, 9],\n",
    "    'useHarrisDetector' : [False]\n",
    "} \n",
    "  \n",
    "# Parameters for lucas kanade optical flow \n",
    "# lk_params = {\n",
    "#     'winSize' : [(8, 8), (16, 16), (24, 24)], \n",
    "#     'maxLevel': [2, 4, 8], \n",
    "#     'criteria': [(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "#                               10, 0.03)]\n",
    "# }\n",
    "lk_params = dict( winSize = (24, 24), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "\n",
    "params_harris = {\n",
    "    'threshold' : [0.43, 0.33, 0.14],\n",
    "    'blockSize' : [3, 6, 6],\n",
    "    'ksize' : [3, 5, 5],\n",
    "    'k' : [0.04, 0.04, 0.04]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'nfeatures': [37, 60, 125],\n",
    "    'nOctaveLayers' : [3, 10, 10],\n",
    "    'contrastThreshold' : [0.15, 0.05, 0.01],\n",
    "    'edgeThreshold' : [2, 10, 3],\n",
    "    'sigma' : [1.6, 3.2, 3.2],\n",
    "    'enable_precise_upscale': [True, True, True]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [11, 16, 16],\n",
    "    'response_threshold': [71, 64, 48],\n",
    "    'line_threshold_projected': [10, 6, 5],\n",
    "    'line_threshold_binarized': [5, 6, 5],\n",
    "    'suppress_nonmax_size': [8, 16, 8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "# query_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "# train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "\n",
    "# query_img_1_ = cv2.resize(query_img_1, (480,640))\n",
    "# train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "\n",
    "query_img_2 = cv2.imread('../data/imgs/dsc02652.jpg') \n",
    "train_img_2 = cv2.imread('../data/imgs/dsc02651.jpg')\n",
    "\n",
    "query_img_2_ = cv2.resize(query_img_2, (640,480))\n",
    "train_img_2_ = cv2.resize(train_img_2, (640,480))\n",
    "\n",
    "# query_img_3 = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "# train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "\n",
    "# query_img_3_ = cv2.resize(query_img_3, (480,640))\n",
    "# train_img_3_ = cv2.resize(train_img_3, (480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>optical_flow</th>\n",
       "      <th>qtd_matches</th>\n",
       "      <th>qtd_good_matches</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harris</td>\n",
       "      <td>lucas-kanade</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sift</td>\n",
       "      <td>lucas-kanade</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star</td>\n",
       "      <td>lucas-kanade</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  detector  optical_flow  qtd_matches  qtd_good_matches  precision\n",
       "0   harris  lucas-kanade           50                50        1.0\n",
       "1     sift  lucas-kanade           50                50        1.0\n",
       "2     star  lucas-kanade           50                50        1.0"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run_all_tests_lk(train_img_2, query_img_2, 'dsc02651', params_harris, params_sift, params_star, lk_params, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 50\n",
      "Quantidade de matches filtro outliers: 49\n",
      "Quantidade de falso positivo: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params for corner detection \n",
    "feature_params = dict( maxCorners = 53, \n",
    "                       qualityLevel = 0.02, \n",
    "                       minDistance = 3, \n",
    "                       blockSize = 3,\n",
    "                       useHarrisDetector = False)\n",
    "\n",
    "dect_kargs = {k: v[1] for k, v in params_harris.items()}\n",
    "func_var = detectHarrisKeypoints\n",
    "\n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = dict( winSize = (16, 16), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "  \n",
    "\n",
    "lk_result = lucas_kanade_opflow(train_img_2, query_img_2, func_var, dect_kargs, lk_params)\n",
    "\n",
    "img, img2, qtd_matches, qtd_matches_filtered, qtd_fp = lk_result\n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de matches filtro outliers: {qtd_matches_filtered}')\n",
    "print(f'Quantidade de falso positivo: {qtd_fp}')\n",
    "\n",
    "cv2.imshow('frame', img)\n",
    "cv2.imshow('frame2', img2)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horn-Schunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_points(old_points, new_points):\n",
    "    array_pts_train = np.asarray(old_points)\n",
    "    array_pts_query = np.asarray(new_points)\n",
    "    \n",
    "    dists = [ np.linalg.norm(p1 - p2) for p1, p2 in zip(array_pts_train, array_pts_query)]\n",
    "\n",
    "    return dists\n",
    "\n",
    "\n",
    "def draw_flow(img, next_img, flow, x, y, new_points):\n",
    "    # h, w = img.shape[:2]\n",
    "    # y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines)\n",
    "    mapped_img = img.copy()#cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    new_mapped_img = next_img.copy()\n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "    # cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    \n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        if np.asarray([x2, y2]) in new_points:\n",
    "            cv2.circle(mapped_img, (x1, y1), 3, point_true, 2)\n",
    "            cv2.line(mapped_img, (x1, y1), (x2, y2), line, 2)\n",
    "            cv2.circle(new_mapped_img, (x2, y2), 3, point_true, 2)\n",
    "        else:\n",
    "            cv2.circle(mapped_img, (x1, y1), 3, point_false, 2)\n",
    "            cv2.line(mapped_img, (x1, y1), (x2, y2), line, 2)\n",
    "            cv2.circle(new_mapped_img, (x2, y2), 3, point_false, 2)\n",
    "\n",
    "    return mapped_img, new_mapped_img\n",
    "\n",
    "\n",
    "def return_points_hs(img, flow, x, y):\n",
    "    # h, w = img.shape[:2]\n",
    "    # y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines)\n",
    "\n",
    "    old_points = np.asarray([[x1, y1] for (x1, y1), (x2, y2) in lines if calculate_distance_points([[x1, y1]], [[x2, y2]])[0] > 0.5])\n",
    "    new_points = np.asarray([[x2, y2] for (x1, y1), (x2, y2) in lines if calculate_distance_points([[x1, y1]], [[x2, y2]])[0] > 0.5])\n",
    "\n",
    "    return old_points, new_points\n",
    "\n",
    "\n",
    "def horn_schunck_opflow(train_img, query_img, func_detector, feature_params, params_horn_schunck):\n",
    "    # Convert to gray scale\n",
    "    prvs = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Capture another frame and convert to gray scale\n",
    "    next = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Optical flow is now calculated\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=prvs, next=next,flow=None, flags=0, **params_horn_schunck)\n",
    "\n",
    "    # Calculated fp points\n",
    "    kps,_ = func_detector(train_img, **feature_params)\n",
    "    x = np.array([int(kp.pt[0]) for kp in kps])\n",
    "    y = np.array([int(kp.pt[1]) for kp in kps])\n",
    "    old_points, new_points = return_points_hs(next, flow, x, y)\n",
    "\n",
    "    qtd_matches = len(new_points)\n",
    "    qtd_matches_filtered = len(new_points)\n",
    "    qtd_fp = qtd_matches - qtd_matches_filtered\n",
    "\n",
    "    mapped_img, new_mapped_img = draw_flow(train_img, query_img, flow, x, y, new_points)\n",
    "\n",
    "    return mapped_img, new_mapped_img, qtd_matches, qtd_matches_filtered, qtd_fp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_tests_hs(train_img, query_img, image_name, params_harris, params_sift, params_star, params_horn_schunck, pos):\n",
    "    n_pontos = [25, 50, 100]\n",
    "    algol_combinations = [('harris', 'horn-schunck'), ('sift', 'horn-schunck'), ('star', 'horn-schunck')]\n",
    "    df = pd.DataFrame(columns=['detector', 'optical_flow', 'qtd_matches', 'qtd_good_matches', 'precision'])\n",
    "\n",
    "    for comb in algol_combinations:\n",
    "        if comb[0] == 'star':\n",
    "            func_var = detectStarKeypoints\n",
    "        elif comb[0] == 'harris':\n",
    "            func_var = detectHarrisKeypoints\n",
    "        else:\n",
    "            func_var = detectSIFTKeypoints\n",
    "        \n",
    "        params_det = return_params_combination_optflow(comb[0], params_harris, params_sift, params_star, pos)\n",
    "        \n",
    "        result = horn_schunck_opflow(train_img, query_img, func_var, params_det, params_horn_schunck)\n",
    "        \n",
    "        imge_flow, new_points, qtd_matches, qtd_good_matches, _ = result\n",
    "\n",
    "        df.loc[len(df.index)] = [comb[0], comb[1], qtd_matches, qtd_good_matches, qtd_good_matches / qtd_matches ]\n",
    "\n",
    "        path_img = f'../results/third_part_optical_flow/{image_name}_matches_{comb[0]}_{comb[1]}_{n_pontos[pos]}_pontos.jpg'\n",
    "        cv2.imwrite(path_img, imge_flow)\n",
    "\n",
    "        path_img = f'../results/third_part_optical_flow/{image_name}_detected_{comb[0]}_{comb[1]}_{n_pontos[pos]}_pontos.jpg'\n",
    "        cv2.imwrite(path_img, new_points)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsc07631.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_horn_schunck = {\n",
    "#     'pyr_scale': [0.1, 0.5, 0.8],\n",
    "#     'levels': [3, 6, 9], \n",
    "#     'winsize': [15, 30, 45],\n",
    "#     'iterations': [3, 15, 30], \n",
    "#     'poly_n': [3, 6, 9], \n",
    "#     'poly_sigma': [1.2, 1.6, 2.4]\n",
    "#     }\n",
    "\n",
    "params_horn_schunck = dict(pyr_scale=0.5, levels=3, winsize=15,\n",
    "                           iterations=3, poly_n=5, poly_sigma=1.2)\n",
    "\n",
    "params_harris = {\n",
    "    'threshold' : [0.27152, 0.078, 0.053],\n",
    "    'blockSize' : [2, 5, 3],\n",
    "    'ksize' : [3, 5, 9],\n",
    "    'k' : [0.04, 0.04, 0.06]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'nfeatures': [34, 69, 143],\n",
    "    'nOctaveLayers' : [3, 10, 10],\n",
    "    'contrastThreshold' : [0.15, 0.05, 0.01],\n",
    "    'edgeThreshold' : [2, 10, 3],\n",
    "    'sigma' : [1.6, 3.2, 3.2],\n",
    "    'enable_precise_upscale': [True, True, True]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [10, 16, 10],\n",
    "    'response_threshold': [70, 55, 30],\n",
    "    'line_threshold_projected': [10, 5, 5],\n",
    "    'line_threshold_binarized': [10, 5, 5],\n",
    "    'suppress_nonmax_size': [10, 16, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (640,480))\n",
    "query_img_ = cv2.resize(query_img, (640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detector</th>\n",
       "      <th>optical_flow</th>\n",
       "      <th>qtd_matches</th>\n",
       "      <th>qtd_good_matches</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harris</td>\n",
       "      <td>horn-schunck</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sift</td>\n",
       "      <td>horn-schunck</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star</td>\n",
       "      <td>horn-schunck</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  detector  optical_flow  qtd_matches  qtd_good_matches  precision\n",
       "0   harris  horn-schunck           50                50        1.0\n",
       "1     sift  horn-schunck           50                50        1.0\n",
       "2     star  horn-schunck           51                51        1.0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_all_tests_hs(train_img, query_img, 'dsc07631', params_harris, params_sift, params_star, params_horn_schunck, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 50\n",
      "Quantidade de matches filtro outliers: 50\n",
      "Quantidade de falso positivo: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dect_kargs = {k: v[1] for k, v in params_harris.items()}\n",
    "func_var = detectHarrisKeypoints\n",
    "\n",
    "hs_optical = horn_schunck_opflow(train_img_, query_img_, func_var, dect_kargs, params_horn_schunck)\n",
    "mapped_img, new_mapped_img, qtd_matches, qtd_matches_filtered, qtd_fp = hs_optical\n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de matches filtro outliers: {qtd_matches_filtered}')\n",
    "print(f'Quantidade de falso positivo: {qtd_fp}')\n",
    "\n",
    "cv2.imshow('frame', mapped_img)\n",
    "cv2.imshow('frame2', new_mapped_img)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dsc02651.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_horn_schunck = {\n",
    "#     'pyr_scale': [0.1, 0.5, 0.8],\n",
    "#     'levels': [3, 6, 9], \n",
    "#     'winsize': [15, 30, 45],\n",
    "#     'iterations': [3, 15, 30], \n",
    "#     'poly_n': [3, 6, 9], \n",
    "#     'poly_sigma': [1.2, 1.6, 2.4]\n",
    "#     }\n",
    "\n",
    "params_horn_schunck = dict(pyr_scale=0.5, levels=3, winsize=5,\n",
    "                           iterations=3, poly_n=5, poly_sigma=1.2)\n",
    "\n",
    "params_harris = {\n",
    "    'threshold' : [0.43, 0.33, 0.14],\n",
    "    'blockSize' : [3, 6, 6],\n",
    "    'ksize' : [3, 5, 5],\n",
    "    'k' : [0.04, 0.04, 0.04]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'nfeatures': [37, 60, 125],\n",
    "    'nOctaveLayers' : [3, 10, 10],\n",
    "    'contrastThreshold' : [0.15, 0.05, 0.01],\n",
    "    'edgeThreshold' : [2, 10, 3],\n",
    "    'sigma' : [1.6, 3.2, 3.2],\n",
    "    'enable_precise_upscale': [True, True, True]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [11, 16, 16],\n",
    "    'response_threshold': [71, 64, 48],\n",
    "    'line_threshold_projected': [10, 6, 5],\n",
    "    'line_threshold_binarized': [5, 6, 5],\n",
    "    'suppress_nonmax_size': [8, 16, 8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc02652.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc02651.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (640,480))\n",
    "query_img_ = cv2.resize(query_img, (640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_all_tests_hs(train_img, query_img, 'dsc02651', params_harris, params_sift, params_star, params_horn_schunck, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 50\n",
      "Quantidade de matches filtro outliers: 50\n",
      "Quantidade de falso positivo: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "params_horn_schunck = dict(pyr_scale=0.5, levels=3, winsize=5,\n",
    "                           iterations=3, poly_n=5, poly_sigma=1.2)\n",
    "\n",
    "dect_kargs = {k: v[1] for k, v in params_harris.items()}\n",
    "func_var = detectHarrisKeypoints\n",
    "\n",
    "hs_optical = horn_schunck_opflow(train_img_, query_img_, func_var, dect_kargs, params_horn_schunck)\n",
    "mapped_img, new_mapped_img, qtd_matches, qtd_matches_filtered, qtd_fp = hs_optical\n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de matches filtro outliers: {qtd_matches_filtered}')\n",
    "print(f'Quantidade de falso positivo: {qtd_fp}')\n",
    "\n",
    "cv2.imshow('frame', mapped_img)\n",
    "cv2.imshow('frame2', new_mapped_img)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter:\n",
    "\n",
    "    def __init__(self, coordX, coordY, coordX_, coordY_):\n",
    "        self.kf = cv2.KalmanFilter(4, 2)\n",
    "        self.kf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "        self.kf.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "        self.kf.processNoiseCov = np.array(\n",
    "                [[1, 0, 0, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1]], np.float32) * 10\n",
    "        self.kf.statePre = np.array([[coordX], [coordY], [0], [0]], np.float32)\n",
    "        self.kf.statePost = np.array([[coordX_], [coordY_], [0], [0]], np.float32)\n",
    "\n",
    "\n",
    "    def predict(self, coordX, coordY):\n",
    "        ''' This function estimates the position of the object'''\n",
    "        measured = np.array([[coordX], [coordY]], np.float32)\n",
    "        self.kf.correct(measured)\n",
    "        predicted = self.kf.predict()\n",
    "        x, y = int(predicted[0]), int(predicted[1])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ## My image\n",
    "# lk_params = dict( winSize = (24, 24), \n",
    "#                   maxLevel = 2, \n",
    "#                   criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "#                               10, 0.03)) \n",
    "\n",
    "\n",
    "# params_horn_schunck = dict(pyr_scale=0.5, levels=3, winsize=10,\n",
    "#                            iterations=3, poly_n=5, poly_sigma=1.2)\n",
    "\n",
    "# params_harris = {\n",
    "#     'threshold' : [0.005],\n",
    "#     'blockSize' : [6],\n",
    "#     'ksize' : [3],\n",
    "#     'k' : [0.04]\n",
    "# }\n",
    "\n",
    "# params_sift = {\n",
    "#     'nfeatures': [55],\n",
    "#     'nOctaveLayers' : [1],\n",
    "#     'contrastThreshold' : [0.02],\n",
    "#     'edgeThreshold' : [5],\n",
    "#     'sigma' : [1.6],\n",
    "#     'enable_precise_upscale': [True]\n",
    "# }\n",
    "\n",
    "# params_star = {\n",
    "#     'max_size': [10],\n",
    "#     'response_threshold': [10],\n",
    "#     'line_threshold_projected': [5],\n",
    "#     'line_threshold_binarized': [5],\n",
    "#     'suppress_nonmax_size': [1]\n",
    "# }\n",
    "\n",
    "# dect_kargs = {k: v[0] for k, v in params_harris.items()}\n",
    "# func_var = detectHarrisKeypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Params img teste\n",
    "\n",
    "lk_params = dict( winSize = (32, 32), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "\n",
    "params_harris = {\n",
    "    'threshold' : [0.27152, 0.078, 0.053],\n",
    "    'blockSize' : [2, 5, 3],\n",
    "    'ksize' : [3, 5, 9],\n",
    "    'k' : [0.04, 0.04, 0.06]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'nfeatures': [34, 69, 143],\n",
    "    'nOctaveLayers' : [3, 10, 10],\n",
    "    'contrastThreshold' : [0.15, 0.05, 0.01],\n",
    "    'edgeThreshold' : [2, 10, 3],\n",
    "    'sigma' : [1.6, 3.2, 3.2],\n",
    "    'enable_precise_upscale': [True, True, True]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [10, 16, 10],\n",
    "    'response_threshold': [70, 55, 30],\n",
    "    'line_threshold_projected': [10, 5, 5],\n",
    "    'line_threshold_binarized': [10, 5, 5],\n",
    "    'suppress_nonmax_size': [10, 16, 10]\n",
    "}\n",
    "\n",
    "dect_kargs = {k: v[1] for k, v in params_harris.items()}\n",
    "func_var = detectHarrisKeypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_points_hs(img, flow, x, y):\n",
    "    # h, w = img.shape[:2]\n",
    "    # y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines)\n",
    "\n",
    "    old_points = np.asarray([[x1, y1] for (x1, y1), (x2, y2) in lines])\n",
    "    new_points = np.asarray([[x2, y2] for (x1, y1), (x2, y2) in lines])\n",
    "\n",
    "    return old_points, new_points\n",
    "\n",
    "def horn_schunck_opflow(train_img, query_img, func_detector, feature_params, params_horn_schunck):\n",
    "    # Convert to gray scale\n",
    "    prvs = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Capture another frame and convert to gray scale\n",
    "    next = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Optical flow is now calculated\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=prvs, next=next,flow=None, flags=0, **params_horn_schunck)\n",
    "\n",
    "    # Calculated fp points\n",
    "    kps,_ = func_detector(train_img, **feature_params)\n",
    "    x = np.array([int(kp.pt[0]) for kp in kps])\n",
    "    y = np.array([int(kp.pt[1]) for kp in kps])\n",
    "    old_points, new_points = return_points_hs(next, flow, x, y)\n",
    "    \n",
    "    mapped_img, new_mapped_img = draw_flow(train_img, query_img, flow, x, y, new_points)\n",
    "\n",
    "    old_points = np.array([[[int(kp[0]), int(kp[1])]] for kp in old_points])\n",
    "    new_points = np.array([[[int(kp[0]), int(kp[1])]] for kp in new_points])\n",
    "\n",
    "    return mapped_img, new_mapped_img, old_points, new_points\n",
    "\n",
    "\n",
    "def horn_schunck_opflow_KF(train_img, query_img, points, params_horn_schunck):\n",
    "    # Convert to gray scale\n",
    "    prvs = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Capture another frame and convert to gray scale\n",
    "    next = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Optical flow is now calculated\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=prvs, next=next,flow=None, flags=0, **params_horn_schunck)\n",
    "\n",
    "    # Calculated fp points\n",
    "    x = np.array([int(kp[0][0]) for kp in points])\n",
    "    y = np.array([int(kp[0][1]) for kp in points])\n",
    "    old_points, new_points = return_points_hs(next, flow, x, y)\n",
    "\n",
    "    mapped_img, new_mapped_img = draw_flow(train_img, query_img, flow, x, y, new_points)\n",
    "    \n",
    "    old_points = np.array([[[int(kp[0]), int(kp[1])]] for kp in old_points])\n",
    "    new_points = np.array([[[int(kp[0]), int(kp[1])]] for kp in new_points])\n",
    "\n",
    "    return mapped_img, new_mapped_img, old_points, new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_opflow(train_img, query_img, func_detector, feature_params, lk_params):\n",
    "    \n",
    "    # Take first frame and find corners in it \n",
    "    old_frame = train_img.copy() \n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "    kps,_ = func_detector(old_frame, **feature_params)\n",
    "    p0 = np.array([[[int(kp.pt[0]), int(kp.pt[1])]] for kp in kps])\n",
    "    p0 = p0.astype(np.float32)\n",
    "\n",
    "    # Create a mask image for drawing purposes \n",
    "\n",
    "    mask = np.zeros_like(old_frame, 'uint8') \n",
    "    \n",
    "    frame = query_img.copy()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # calculate optical flow \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params) \n",
    "\n",
    "    # Select good points \n",
    "    good_new = p1\n",
    "    good_old = p0\n",
    "        \n",
    "    qtd_matches = len(p1)\n",
    "    qtd_matches_filtered = len(good_new)\n",
    "    qtd_fp = qtd_matches - qtd_matches_filtered\n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (old, new) in enumerate(zip(good_old, good_new)):\n",
    "        a, b = old.ravel() \n",
    "        c, d = new.ravel()\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "\n",
    "        mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "        old_frame = cv2.circle(old_frame, (a, b), 3, point_true, 2)\n",
    "        frame = cv2.circle(frame, (c, d), 3, point_true, 2)\n",
    "                   \n",
    "    img = cv2.add(old_frame, mask)\n",
    "\n",
    "    return img, frame, good_old, good_new\n",
    "\n",
    "\n",
    "def lucas_kanade_opflow_KF(train_img, query_img, points, lk_params):\n",
    "    \n",
    "    # Take first frame and find corners in it \n",
    "    old_frame = train_img.copy()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    p0 = np.array([[[int(kp[0][0]), int(kp[0][1])]] for kp in points])\n",
    "    p0 = p0.astype(np.float32)\n",
    "\n",
    "    # Create a mask image for drawing purposes \n",
    "\n",
    "    mask = np.zeros_like(old_frame, 'uint8') \n",
    "    \n",
    "    frame = query_img.copy()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # calculate optical flow \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params) \n",
    "\n",
    "    # Select good points \n",
    "    good_new = p1\n",
    "    good_old = p0\n",
    "        \n",
    "    qtd_matches = len(p1)\n",
    "    qtd_matches_filtered = len(good_new)\n",
    "    qtd_fp = qtd_matches - qtd_matches_filtered\n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (old, new) in enumerate(zip(good_old, good_new)):\n",
    "        a, b = old.ravel() \n",
    "        c, d = new.ravel()\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "\n",
    "        mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "        old_frame = cv2.circle(old_frame, (a, b), 3, point_true, 2)\n",
    "        frame = cv2.circle(frame, (c, d), 3, point_true, 2)\n",
    "            \n",
    "    img = cv2.add(old_frame, mask)\n",
    "\n",
    "    return img, frame, good_old, good_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[319 239]]\n",
      "\n",
      " [[133  29]]\n",
      "\n",
      " [[147  40]]\n",
      "\n",
      " [[405  41]]\n",
      "\n",
      " [[394  46]]\n",
      "\n",
      " [[530  52]]\n",
      "\n",
      " [[312  75]]\n",
      "\n",
      " [[464  72]]\n",
      "\n",
      " [[298  75]]\n",
      "\n",
      " [[199  78]]\n",
      "\n",
      " [[434  82]]\n",
      "\n",
      " [[315  88]]\n",
      "\n",
      " [[215  90]]\n",
      "\n",
      " [[397  93]]\n",
      "\n",
      " [[230 101]]\n",
      "\n",
      " [[369 102]]\n",
      "\n",
      " [[244 123]]\n",
      "\n",
      " [[308 121]]\n",
      "\n",
      " [[634 123]]\n",
      "\n",
      " [[284 129]]\n",
      "\n",
      " [[307 132]]\n",
      "\n",
      " [[582 135]]\n",
      "\n",
      " [[545 144]]\n",
      "\n",
      " [[475 161]]\n",
      "\n",
      " [[443 169]]\n",
      "\n",
      " [[403 179]]\n",
      "\n",
      " [[170 185]]\n",
      "\n",
      " [[374 187]]\n",
      "\n",
      " [[310 202]]\n",
      "\n",
      " [[285 209]]\n",
      "\n",
      " [[602 251]]\n",
      "\n",
      " [[563 258]]\n",
      "\n",
      " [[488 271]]\n",
      "\n",
      " [[454 277]]\n",
      "\n",
      " [[139 277]]\n",
      "\n",
      " [[411 284]]\n",
      "\n",
      " [[381 290]]\n",
      "\n",
      " [[  5 300]]\n",
      "\n",
      " [[313 301]]\n",
      "\n",
      " [[287 306]]\n",
      "\n",
      " [[499 381]]\n",
      "\n",
      " [[463 384]]\n",
      "\n",
      " [[419 388]]\n",
      "\n",
      " [[386 391]]\n",
      "\n",
      " [[ 70 394]]\n",
      "\n",
      " [[316 396]]\n",
      "\n",
      " [[289 399]]\n",
      "\n",
      " [[ 78 399]]\n",
      "\n",
      " [[600 413]]\n",
      "\n",
      " [[128 431]]]\n",
      "(319, 239)\n",
      "[[319 239]]\n",
      "[[296 246]]\n",
      "(319, 239)\n",
      "\n",
      "(133, 29)\n",
      "[[133  29]]\n",
      "[[111  34]]\n",
      "(133, 29)\n",
      "\n",
      "(147, 40)\n",
      "[[147  40]]\n",
      "[[125  45]]\n",
      "(147, 40)\n",
      "\n",
      "(405, 41)\n",
      "[[405  41]]\n",
      "[[383  50]]\n",
      "(405, 41)\n",
      "\n",
      "(394, 46)\n",
      "[[394  46]]\n",
      "[[372  55]]\n",
      "(394, 46)\n",
      "\n",
      "(530, 52)\n",
      "[[530  52]]\n",
      "[[507  63]]\n",
      "(530, 52)\n",
      "\n",
      "(312, 75)\n",
      "[[312  75]]\n",
      "[[290  83]]\n",
      "(312, 75)\n",
      "\n",
      "(464, 72)\n",
      "[[464  72]]\n",
      "[[442  82]]\n",
      "(464, 72)\n",
      "\n",
      "(298, 75)\n",
      "[[298  75]]\n",
      "[[276  83]]\n",
      "(298, 75)\n",
      "\n",
      "(199, 78)\n",
      "[[199  78]]\n",
      "[[177  84]]\n",
      "(199, 78)\n",
      "\n",
      "(434, 82)\n",
      "[[434  82]]\n",
      "[[412  92]]\n",
      "(434, 82)\n",
      "\n",
      "(315, 88)\n",
      "[[315  88]]\n",
      "[[293  96]]\n",
      "(315, 88)\n",
      "\n",
      "(215, 90)\n",
      "[[215  90]]\n",
      "[[193  96]]\n",
      "(215, 90)\n",
      "\n",
      "(397, 93)\n",
      "[[397  93]]\n",
      "[[375 102]]\n",
      "(397, 93)\n",
      "\n",
      "(230, 101)\n",
      "[[230 101]]\n",
      "[[208 108]]\n",
      "(230, 101)\n",
      "\n",
      "(369, 102)\n",
      "[[369 102]]\n",
      "[[347 111]]\n",
      "(369, 102)\n",
      "\n",
      "(244, 123)\n",
      "[[244 123]]\n",
      "[[222 130]]\n",
      "(244, 123)\n",
      "\n",
      "(308, 121)\n",
      "[[308 121]]\n",
      "[[286 129]]\n",
      "(308, 121)\n",
      "\n",
      "(634, 123)\n",
      "[[634 123]]\n",
      "[[609 135]]\n",
      "(634, 123)\n",
      "\n",
      "(284, 129)\n",
      "[[284 129]]\n",
      "[[262 136]]\n",
      "(284, 129)\n",
      "\n",
      "(307, 132)\n",
      "[[307 132]]\n",
      "[[285 140]]\n",
      "(307, 132)\n",
      "\n",
      "(582, 135)\n",
      "[[582 135]]\n",
      "[[558 146]]\n",
      "(582, 135)\n",
      "\n",
      "(545, 144)\n",
      "[[545 144]]\n",
      "[[521 155]]\n",
      "(545, 144)\n",
      "\n",
      "(475, 161)\n",
      "[[475 161]]\n",
      "[[452 171]]\n",
      "(475, 161)\n",
      "\n",
      "(443, 169)\n",
      "[[443 169]]\n",
      "[[420 178]]\n",
      "(443, 169)\n",
      "\n",
      "(403, 179)\n",
      "[[403 179]]\n",
      "[[380 188]]\n",
      "(403, 179)\n",
      "\n",
      "(170, 185)\n",
      "[[170 185]]\n",
      "[[147 191]]\n",
      "(170, 185)\n",
      "\n",
      "(374, 187)\n",
      "[[374 187]]\n",
      "[[351 195]]\n",
      "(374, 187)\n",
      "\n",
      "(310, 202)\n",
      "[[310 202]]\n",
      "[[287 210]]\n",
      "(310, 202)\n",
      "\n",
      "(285, 209)\n",
      "[[285 209]]\n",
      "[[262 216]]\n",
      "(285, 209)\n",
      "\n",
      "(602, 251)\n",
      "[[602 251]]\n",
      "[[576 261]]\n",
      "(602, 251)\n",
      "\n",
      "(563, 258)\n",
      "[[563 258]]\n",
      "[[538 268]]\n",
      "(563, 258)\n",
      "\n",
      "(488, 271)\n",
      "[[488 271]]\n",
      "[[464 280]]\n",
      "(488, 271)\n",
      "\n",
      "(454, 277)\n",
      "[[454 277]]\n",
      "[[430 286]]\n",
      "(454, 277)\n",
      "\n",
      "(139, 277)\n",
      "[[139 277]]\n",
      "[[114 283]]\n",
      "(139, 277)\n",
      "\n",
      "(411, 284)\n",
      "[[411 284]]\n",
      "[[387 292]]\n",
      "(411, 284)\n",
      "\n",
      "(381, 290)\n",
      "[[381 290]]\n",
      "[[357 298]]\n",
      "(381, 290)\n",
      "\n",
      "(5, 300)\n",
      "[[  5 300]]\n",
      "[[-27 312]]\n",
      "(5, 300)\n",
      "\n",
      "(313, 301)\n",
      "[[313 301]]\n",
      "[[289 309]]\n",
      "(313, 301)\n",
      "\n",
      "(287, 306)\n",
      "[[287 306]]\n",
      "[[263 314]]\n",
      "(287, 306)\n",
      "\n",
      "(499, 381)\n",
      "[[499 381]]\n",
      "[[474 390]]\n",
      "(499, 381)\n",
      "\n",
      "(463, 384)\n",
      "[[463 384]]\n",
      "[[438 393]]\n",
      "(463, 384)\n",
      "\n",
      "(419, 388)\n",
      "[[419 388]]\n",
      "[[394 396]]\n",
      "(419, 388)\n",
      "\n",
      "(386, 391)\n",
      "[[386 391]]\n",
      "[[361 399]]\n",
      "(386, 391)\n",
      "\n",
      "(70, 394)\n",
      "[[ 70 394]]\n",
      "[[ 43 401]]\n",
      "(70, 394)\n",
      "\n",
      "(316, 396)\n",
      "[[316 396]]\n",
      "[[291 404]]\n",
      "(316, 396)\n",
      "\n",
      "(289, 399)\n",
      "[[289 399]]\n",
      "[[264 407]]\n",
      "(289, 399)\n",
      "\n",
      "(78, 399)\n",
      "[[ 78 399]]\n",
      "[[ 51 406]]\n",
      "(78, 399)\n",
      "\n",
      "(600, 413)\n",
      "[[600 413]]\n",
      "[[573 422]]\n",
      "(600, 413)\n",
      "\n",
      "(128, 431)\n",
      "[[128 431]]\n",
      "[[102 439]]\n",
      "(128, 431)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdemo\\AppData\\Local\\Temp\\ipykernel_9040\\518723252.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  x, y = int(predicted[0]), int(predicted[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 239)\n",
      "[[296 246]]\n",
      "[[277 249]]\n",
      "(298, 245)\n",
      "\n",
      "(133, 29)\n",
      "[[111  34]]\n",
      "[[93 34]]\n",
      "(113, 33)\n",
      "\n",
      "(147, 40)\n",
      "[[125  45]]\n",
      "[[107  45]]\n",
      "(127, 44)\n",
      "\n",
      "(405, 41)\n",
      "[[383  50]]\n",
      "[[366  54]]\n",
      "(385, 49)\n",
      "\n",
      "(394, 46)\n",
      "[[372  55]]\n",
      "[[355  59]]\n",
      "(374, 54)\n",
      "\n",
      "(530, 52)\n",
      "[[507  63]]\n",
      "[[489  68]]\n",
      "(509, 62)\n",
      "\n",
      "(312, 75)\n",
      "[[290  83]]\n",
      "[[273  86]]\n",
      "(292, 82)\n",
      "\n",
      "(464, 72)\n",
      "[[442  82]]\n",
      "[[424  86]]\n",
      "(444, 81)\n",
      "\n",
      "(298, 75)\n",
      "[[276  83]]\n",
      "[[259  86]]\n",
      "(278, 82)\n",
      "\n",
      "(199, 78)\n",
      "[[177  84]]\n",
      "[[159  85]]\n",
      "(179, 83)\n",
      "\n",
      "(434, 82)\n",
      "[[412  92]]\n",
      "[[394  96]]\n",
      "(414, 91)\n",
      "\n",
      "(315, 88)\n",
      "[[293  96]]\n",
      "[[276  99]]\n",
      "(295, 95)\n",
      "\n",
      "(215, 90)\n",
      "[[193  96]]\n",
      "[[175  98]]\n",
      "(195, 95)\n",
      "\n",
      "(397, 93)\n",
      "[[375 102]]\n",
      "[[357 106]]\n",
      "(377, 101)\n",
      "\n",
      "(230, 101)\n",
      "[[208 108]]\n",
      "[[190 110]]\n",
      "(210, 107)\n",
      "\n",
      "(369, 102)\n",
      "[[347 111]]\n",
      "[[329 114]]\n",
      "(349, 110)\n",
      "\n",
      "(244, 123)\n",
      "[[222 130]]\n",
      "[[204 132]]\n",
      "(224, 129)\n",
      "\n",
      "(308, 121)\n",
      "[[286 129]]\n",
      "[[268 132]]\n",
      "(288, 128)\n",
      "\n",
      "(634, 123)\n",
      "[[609 135]]\n",
      "[[589 141]]\n",
      "(611, 133)\n",
      "\n",
      "(284, 129)\n",
      "[[262 136]]\n",
      "[[244 138]]\n",
      "(264, 135)\n",
      "\n",
      "(307, 132)\n",
      "[[285 140]]\n",
      "[[267 143]]\n",
      "(287, 139)\n",
      "\n",
      "(582, 135)\n",
      "[[558 146]]\n",
      "[[539 151]]\n",
      "(560, 145)\n",
      "\n",
      "(545, 144)\n",
      "[[521 155]]\n",
      "[[502 160]]\n",
      "(523, 154)\n",
      "\n",
      "(475, 161)\n",
      "[[452 171]]\n",
      "[[433 175]]\n",
      "(454, 170)\n",
      "\n",
      "(443, 169)\n",
      "[[420 178]]\n",
      "[[402 182]]\n",
      "(422, 177)\n",
      "\n",
      "(403, 179)\n",
      "[[380 188]]\n",
      "[[362 191]]\n",
      "(382, 187)\n",
      "\n",
      "(170, 185)\n",
      "[[147 191]]\n",
      "[[128 192]]\n",
      "(149, 190)\n",
      "\n",
      "(374, 187)\n",
      "[[351 195]]\n",
      "[[333 198]]\n",
      "(353, 194)\n",
      "\n",
      "(310, 202)\n",
      "[[287 210]]\n",
      "[[268 213]]\n",
      "(289, 209)\n",
      "\n",
      "(285, 209)\n",
      "[[262 216]]\n",
      "[[243 218]]\n",
      "(264, 215)\n",
      "\n",
      "(602, 251)\n",
      "[[576 261]]\n",
      "[[556 266]]\n",
      "(578, 260)\n",
      "\n",
      "(563, 258)\n",
      "[[538 268]]\n",
      "[[518 272]]\n",
      "(540, 267)\n",
      "\n",
      "(488, 271)\n",
      "[[464 280]]\n",
      "[[445 284]]\n",
      "(466, 279)\n",
      "\n",
      "(454, 277)\n",
      "[[430 286]]\n",
      "[[411 290]]\n",
      "(432, 285)\n",
      "\n",
      "(139, 277)\n",
      "[[114 283]]\n",
      "[[ 94 285]]\n",
      "(116, 282)\n",
      "\n",
      "(411, 284)\n",
      "[[387 292]]\n",
      "[[368 295]]\n",
      "(389, 291)\n",
      "\n",
      "(381, 290)\n",
      "[[357 298]]\n",
      "[[338 301]]\n",
      "(359, 297)\n",
      "\n",
      "(5, 300)\n",
      "[[-27 312]]\n",
      "[[-29 311]]\n",
      "(-24, 310)\n",
      "\n",
      "(313, 301)\n",
      "[[289 309]]\n",
      "[[270 312]]\n",
      "(291, 308)\n",
      "\n",
      "(287, 306)\n",
      "[[263 314]]\n",
      "[[244 317]]\n",
      "(265, 313)\n",
      "\n",
      "(499, 381)\n",
      "[[474 390]]\n",
      "[[454 393]]\n",
      "(476, 389)\n",
      "\n",
      "(463, 384)\n",
      "[[438 393]]\n",
      "[[418 396]]\n",
      "(440, 392)\n",
      "\n",
      "(419, 388)\n",
      "[[394 396]]\n",
      "[[374 399]]\n",
      "(396, 395)\n",
      "\n",
      "(386, 391)\n",
      "[[361 399]]\n",
      "[[341 402]]\n",
      "(363, 398)\n",
      "\n",
      "(70, 394)\n",
      "[[ 43 401]]\n",
      "[[ 21 403]]\n",
      "(45, 400)\n",
      "\n",
      "(316, 396)\n",
      "[[291 404]]\n",
      "[[271 407]]\n",
      "(293, 403)\n",
      "\n",
      "(289, 399)\n",
      "[[264 407]]\n",
      "[[244 410]]\n",
      "(266, 406)\n",
      "\n",
      "(78, 399)\n",
      "[[ 51 406]]\n",
      "[[ 29 408]]\n",
      "(53, 405)\n",
      "\n",
      "(600, 413)\n",
      "[[573 422]]\n",
      "[[552 426]]\n",
      "(575, 421)\n",
      "\n",
      "(128, 431)\n",
      "[[102 439]]\n",
      "[[ 81 442]]\n",
      "(104, 438)\n",
      "\n",
      "(298, 245)\n",
      "[[277 249]]\n",
      "[[259 242]]\n",
      "(268, 250)\n",
      "\n",
      "(113, 33)\n",
      "[[93 34]]\n",
      "[[75 25]]\n",
      "(84, 34)\n",
      "\n",
      "(127, 44)\n",
      "[[107  45]]\n",
      "[[89 36]]\n",
      "(98, 45)\n",
      "\n",
      "(385, 49)\n",
      "[[366  54]]\n",
      "[[350  48]]\n",
      "(358, 55)\n",
      "\n",
      "(374, 54)\n",
      "[[355  59]]\n",
      "[[339  53]]\n",
      "(347, 60)\n",
      "\n",
      "(509, 62)\n",
      "[[489  68]]\n",
      "[[472  63]]\n",
      "(480, 70)\n",
      "\n",
      "(292, 82)\n",
      "[[273  86]]\n",
      "[[256  79]]\n",
      "(265, 87)\n",
      "\n",
      "(444, 81)\n",
      "[[424  86]]\n",
      "[[407  80]]\n",
      "(415, 88)\n",
      "\n",
      "(278, 82)\n",
      "[[259  86]]\n",
      "[[242  79]]\n",
      "(251, 87)\n",
      "\n",
      "(179, 83)\n",
      "[[159  85]]\n",
      "[[142  77]]\n",
      "(150, 85)\n",
      "\n",
      "(414, 91)\n",
      "[[394  96]]\n",
      "[[377  90]]\n",
      "(385, 98)\n",
      "\n",
      "(295, 95)\n",
      "[[276  99]]\n",
      "[[259  92]]\n",
      "(268, 100)\n",
      "\n",
      "(195, 95)\n",
      "[[175  98]]\n",
      "[[158  90]]\n",
      "(166, 99)\n",
      "\n",
      "(377, 101)\n",
      "[[357 106]]\n",
      "[[340 100]]\n",
      "(348, 107)\n",
      "\n",
      "(210, 107)\n",
      "[[190 110]]\n",
      "[[173 103]]\n",
      "(181, 111)\n",
      "\n",
      "(349, 110)\n",
      "[[329 114]]\n",
      "[[312 108]]\n",
      "(320, 115)\n",
      "\n",
      "(224, 129)\n",
      "[[204 132]]\n",
      "[[187 125]]\n",
      "(195, 133)\n",
      "\n",
      "(288, 128)\n",
      "[[268 132]]\n",
      "[[251 125]]\n",
      "(259, 133)\n",
      "\n",
      "(611, 133)\n",
      "[[589 141]]\n",
      "[[571 137]]\n",
      "(579, 143)\n",
      "\n",
      "(264, 135)\n",
      "[[244 138]]\n",
      "[[227 131]]\n",
      "(235, 139)\n",
      "\n",
      "(287, 139)\n",
      "[[267 143]]\n",
      "[[250 136]]\n",
      "(258, 144)\n",
      "\n",
      "(560, 145)\n",
      "[[539 151]]\n",
      "[[521 146]]\n",
      "(530, 153)\n",
      "\n",
      "(523, 154)\n",
      "[[502 160]]\n",
      "[[484 155]]\n",
      "(493, 162)\n",
      "\n",
      "(454, 170)\n",
      "[[433 175]]\n",
      "[[416 169]]\n",
      "(424, 177)\n",
      "\n",
      "(422, 177)\n",
      "[[402 182]]\n",
      "[[385 176]]\n",
      "(393, 183)\n",
      "\n",
      "(382, 187)\n",
      "[[362 191]]\n",
      "[[345 185]]\n",
      "(353, 192)\n",
      "\n",
      "(149, 190)\n",
      "[[128 192]]\n",
      "[[110 185]]\n",
      "(119, 192)\n",
      "\n",
      "(353, 194)\n",
      "[[333 198]]\n",
      "[[316 192]]\n",
      "(324, 199)\n",
      "\n",
      "(289, 209)\n",
      "[[268 213]]\n",
      "[[250 206]]\n",
      "(259, 214)\n",
      "\n",
      "(264, 215)\n",
      "[[243 218]]\n",
      "[[225 211]]\n",
      "(234, 219)\n",
      "\n",
      "(578, 260)\n",
      "[[556 266]]\n",
      "[[537 261]]\n",
      "(546, 268)\n",
      "\n",
      "(540, 267)\n",
      "[[518 272]]\n",
      "[[499 267]]\n",
      "(508, 274)\n",
      "\n",
      "(466, 279)\n",
      "[[445 284]]\n",
      "[[427 278]]\n",
      "(436, 285)\n",
      "\n",
      "(432, 285)\n",
      "[[411 290]]\n",
      "[[393 284]]\n",
      "(402, 291)\n",
      "\n",
      "(116, 282)\n",
      "[[ 94 285]]\n",
      "[[ 75 278]]\n",
      "(84, 286)\n",
      "\n",
      "(389, 291)\n",
      "[[368 295]]\n",
      "[[350 289]]\n",
      "(359, 296)\n",
      "\n",
      "(359, 297)\n",
      "[[338 301]]\n",
      "[[320 295]]\n",
      "(329, 302)\n",
      "\n",
      "(-24, 310)\n",
      "[[-29 311]]\n",
      "[[-45 306]]\n",
      "(-31, 311)\n",
      "\n",
      "(291, 308)\n",
      "[[270 312]]\n",
      "[[252 306]]\n",
      "(261, 313)\n",
      "\n",
      "(265, 313)\n",
      "[[244 317]]\n",
      "[[226 310]]\n",
      "(235, 318)\n",
      "\n",
      "(476, 389)\n",
      "[[454 393]]\n",
      "[[435 387]]\n",
      "(444, 394)\n",
      "\n",
      "(440, 392)\n",
      "[[418 396]]\n",
      "[[400 390]]\n",
      "(408, 397)\n",
      "\n",
      "(396, 395)\n",
      "[[374 399]]\n",
      "[[356 393]]\n",
      "(364, 400)\n",
      "\n",
      "(363, 398)\n",
      "[[341 402]]\n",
      "[[323 396]]\n",
      "(331, 403)\n",
      "\n",
      "(45, 400)\n",
      "[[ 21 403]]\n",
      "[[  2 397]]\n",
      "(10, 404)\n",
      "\n",
      "(293, 403)\n",
      "[[271 407]]\n",
      "[[253 400]]\n",
      "(261, 408)\n",
      "\n",
      "(266, 406)\n",
      "[[244 410]]\n",
      "[[226 404]]\n",
      "(234, 411)\n",
      "\n",
      "(53, 405)\n",
      "[[ 29 408]]\n",
      "[[  9 402]]\n",
      "(18, 409)\n",
      "\n",
      "(575, 421)\n",
      "[[552 426]]\n",
      "[[532 420]]\n",
      "(542, 427)\n",
      "\n",
      "(104, 438)\n",
      "[[ 81 442]]\n",
      "[[ 62 436]]\n",
      "(71, 443)\n",
      "\n",
      "(268, 250)\n",
      "[[259 242]]\n",
      "[[241 232]]\n",
      "(244, 239)\n",
      "\n",
      "(84, 34)\n",
      "[[75 25]]\n",
      "[[56 12]]\n",
      "(60, 20)\n",
      "\n",
      "(98, 45)\n",
      "[[89 36]]\n",
      "[[70 23]]\n",
      "(74, 31)\n",
      "\n",
      "(358, 55)\n",
      "[[350  48]]\n",
      "[[333  38]]\n",
      "(337, 46)\n",
      "\n",
      "(347, 60)\n",
      "[[339  53]]\n",
      "[[322  43]]\n",
      "(326, 51)\n",
      "\n",
      "(480, 70)\n",
      "[[472  63]]\n",
      "[[454  54]]\n",
      "(458, 61)\n",
      "\n",
      "(265, 87)\n",
      "[[256  79]]\n",
      "[[238  68]]\n",
      "(242, 76)\n",
      "\n",
      "(415, 88)\n",
      "[[407  80]]\n",
      "[[389  70]]\n",
      "(393, 78)\n",
      "\n",
      "(251, 87)\n",
      "[[242  79]]\n",
      "[[225  69]]\n",
      "(228, 76)\n",
      "\n",
      "(150, 85)\n",
      "[[142  77]]\n",
      "[[124  65]]\n",
      "(128, 73)\n",
      "\n",
      "(385, 98)\n",
      "[[377  90]]\n",
      "[[359  80]]\n",
      "(363, 88)\n",
      "\n",
      "(268, 100)\n",
      "[[259  92]]\n",
      "[[241  81]]\n",
      "(245, 89)\n",
      "\n",
      "(166, 99)\n",
      "[[158  90]]\n",
      "[[140  78]]\n",
      "(144, 86)\n",
      "\n",
      "(348, 107)\n",
      "[[340 100]]\n",
      "[[322  90]]\n",
      "(326, 98)\n",
      "\n",
      "(181, 111)\n",
      "[[173 103]]\n",
      "[[155  92]]\n",
      "(159, 99)\n",
      "\n",
      "(320, 115)\n",
      "[[312 108]]\n",
      "[[294  98]]\n",
      "(298, 105)\n",
      "\n",
      "(195, 133)\n",
      "[[187 125]]\n",
      "[[169 114]]\n",
      "(173, 121)\n",
      "\n",
      "(259, 133)\n",
      "[[251 125]]\n",
      "[[233 114]]\n",
      "(237, 122)\n",
      "\n",
      "(579, 143)\n",
      "[[571 137]]\n",
      "[[552 128]]\n",
      "(556, 136)\n",
      "\n",
      "(235, 139)\n",
      "[[227 131]]\n",
      "[[209 120]]\n",
      "(213, 127)\n",
      "\n",
      "(258, 144)\n",
      "[[250 136]]\n",
      "[[232 125]]\n",
      "(236, 133)\n",
      "\n",
      "(530, 153)\n",
      "[[521 146]]\n",
      "[[502 137]]\n",
      "(506, 144)\n",
      "\n",
      "(493, 162)\n",
      "[[484 155]]\n",
      "[[466 146]]\n",
      "(469, 153)\n",
      "\n",
      "(424, 177)\n",
      "[[416 169]]\n",
      "[[398 159]]\n",
      "(401, 167)\n",
      "\n",
      "(393, 183)\n",
      "[[385 176]]\n",
      "[[367 166]]\n",
      "(371, 174)\n",
      "\n",
      "(353, 192)\n",
      "[[345 185]]\n",
      "[[327 175]]\n",
      "(331, 182)\n",
      "\n",
      "(119, 192)\n",
      "[[110 185]]\n",
      "[[ 91 174]]\n",
      "(95, 181)\n",
      "\n",
      "(324, 199)\n",
      "[[316 192]]\n",
      "[[298 182]]\n",
      "(302, 189)\n",
      "\n",
      "(259, 214)\n",
      "[[250 206]]\n",
      "[[232 196]]\n",
      "(235, 203)\n",
      "\n",
      "(234, 219)\n",
      "[[225 211]]\n",
      "[[207 201]]\n",
      "(210, 207)\n",
      "\n",
      "(546, 268)\n",
      "[[537 261]]\n",
      "[[517 251]]\n",
      "(521, 259)\n",
      "\n",
      "(508, 274)\n",
      "[[499 267]]\n",
      "[[480 257]]\n",
      "(483, 265)\n",
      "\n",
      "(436, 285)\n",
      "[[427 278]]\n",
      "[[408 268]]\n",
      "(412, 276)\n",
      "\n",
      "(402, 291)\n",
      "[[393 284]]\n",
      "[[374 274]]\n",
      "(378, 282)\n",
      "\n",
      "(84, 286)\n",
      "[[ 75 278]]\n",
      "[[ 55 267]]\n",
      "(59, 274)\n",
      "\n",
      "(359, 296)\n",
      "[[350 289]]\n",
      "[[331 279]]\n",
      "(335, 286)\n",
      "\n",
      "(329, 302)\n",
      "[[320 295]]\n",
      "[[301 285]]\n",
      "(305, 292)\n",
      "\n",
      "(-31, 311)\n",
      "[[-45 306]]\n",
      "[[-64 297]]\n",
      "(-54, 303)\n",
      "\n",
      "(261, 313)\n",
      "[[252 306]]\n",
      "[[233 296]]\n",
      "(237, 303)\n",
      "\n",
      "(235, 318)\n",
      "[[226 310]]\n",
      "[[207 300]]\n",
      "(211, 307)\n",
      "\n",
      "(444, 394)\n",
      "[[435 387]]\n",
      "[[416 377]]\n",
      "(419, 384)\n",
      "\n",
      "(408, 397)\n",
      "[[400 390]]\n",
      "[[381 380]]\n",
      "(385, 387)\n",
      "\n",
      "(364, 400)\n",
      "[[356 393]]\n",
      "[[337 383]]\n",
      "(341, 390)\n",
      "\n",
      "(331, 403)\n",
      "[[323 396]]\n",
      "[[305 386]]\n",
      "(308, 393)\n",
      "\n",
      "(10, 404)\n",
      "[[  2 397]]\n",
      "[[-23 388]]\n",
      "(-13, 394)\n",
      "\n",
      "(261, 408)\n",
      "[[253 400]]\n",
      "[[234 390]]\n",
      "(238, 397)\n",
      "\n",
      "(234, 411)\n",
      "[[226 404]]\n",
      "[[207 394]]\n",
      "(211, 401)\n",
      "\n",
      "(18, 409)\n",
      "[[  9 402]]\n",
      "[[-12 393]]\n",
      "(-7, 399)\n",
      "\n",
      "(542, 427)\n",
      "[[532 420]]\n",
      "[[512 409]]\n",
      "(515, 418)\n",
      "\n",
      "(71, 443)\n",
      "[[ 62 436]]\n",
      "[[ 42 426]]\n",
      "(46, 433)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregar as imagens da sequência\n",
    "image_folders = ['../data/imgs/dsc07631.jpg',\n",
    "                  '../data/imgs/dsc07632.jpg',\n",
    "                  '../data/imgs/dsc07633.jpg',\n",
    "                  '../data/imgs/dsc07634.jpg',\n",
    "                  '../data/imgs/dsc07635.jpg',\n",
    "        ]\n",
    "\n",
    "# image_folders = ['../data/imgs_teste_3/IMG-20240114-WA0043.jpg',\n",
    "#                   '../data/imgs_teste_3/IMG-20240114-WA0044.jpg',\n",
    "#                   '../data/imgs_teste_3/IMG-20240114-WA0045.jpg',\n",
    "#                   '../data/imgs_teste_3/IMG-20240114-WA0046.jpg',\n",
    "#                   '../data/imgs_teste_3/IMG-20240114-WA0047.jpg',\n",
    "#                   '../data/imgs_teste_3/IMG-20240114-WA0048.jpg',\n",
    "#         ]\n",
    "\n",
    "\n",
    "images = [cv2.resize(cv2.imread(image_folder), (640,480)) for image_folder in image_folders]\n",
    "\n",
    "# Detector de Harris\n",
    "# corners, kp_image = detectSIFTKeypoints(images[0], **dect_kargs)\n",
    "# _, _, p0, p1 = lucas_kanade_opflow(images[0], images[1], func_var, dect_kargs, lk_params)\n",
    "_, _, p0, p1 = horn_schunck_opflow(images[0], images[1], func_var, dect_kargs, params_horn_schunck)\n",
    "\n",
    "print(p0)\n",
    "# Inicialização do Kalman para cada ponto\n",
    "# kf = KalmanFilter()\n",
    "kalman_filters = [KalmanFilter(p1[0][0], p1[0][1], p2[0][0], p2[0][1]) for p1, p2 in zip(p0, p1)]\n",
    "kf_points = []\n",
    "\n",
    "for i, p in enumerate(p0):\n",
    "    kf_points.append((p[0][0], p[0][1]))\n",
    "\n",
    "# Atualizar cada filtro de Kalman com as novas medições\n",
    "for i in range(1, len(images)):\n",
    "    image_train = images[i-1].copy()\n",
    "    image_query = images[i].copy()\n",
    "    \n",
    "    # _, _, p0, p1 = lucas_kanade_opflow_KF(image_train, image_query, p0, lk_params)\n",
    "    _, _, p0, p1 = horn_schunck_opflow_KF(image_train, image_query, p0, params_horn_schunck)\n",
    "\n",
    "    for j, (pt_1, pt_2) in enumerate(zip(p0, p1)):\n",
    "        if j < 100: \n",
    "            x, y = pt_1[0][0], pt_1[0][1]\n",
    "            print(kf_points[j])\n",
    "            print(pt_1)\n",
    "            print(pt_2)\n",
    "            kf_points[j] = kalman_filters[j].predict(x, y)\n",
    "\n",
    "            # Atualizar a posição estimada\n",
    "            predicted_position = kf_points[j]\n",
    "\n",
    "            print(predicted_position)\n",
    "            print(\"\")\n",
    "\n",
    "            # Desenhar a posição estimada\n",
    "            cv2.circle(image_query, (int(predicted_position[0]), int(predicted_position[1])), 5, (0, 255, 0), -1)\n",
    "\n",
    "            # Desenhar a posição real do detector de Harris\n",
    "            cv2.circle(image_query, (int(pt_2[0][0]), int(pt_2[0][1])), 5, (0, 0, 255), -1)\n",
    "        else : continue\n",
    "    p0 = p1\n",
    "    # Exibir a imagem com as posições estimadas e reais\n",
    "    cv2.imshow('Kalman Filter - Harris Corners', image_query)\n",
    "    \n",
    "    # Aguardar um pouco entre as imagens (ajuste conforme necessário)\n",
    "    cv2.waitKey(1000)\n",
    "\n",
    "# Aguardar até que uma tecla seja pressionada para fechar a janela\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2148, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
