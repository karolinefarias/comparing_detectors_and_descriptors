{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### tarefas para fazer\n",
    "## Algoritmos de detecção\n",
    "# -- harris - OK\n",
    "# -- sift - OK\n",
    "# -- star/brisk OK\n",
    "# -- entender parâmetros harris, sift, star e brisk (pendente)\n",
    "# -- criar experimento para 25, 50, 100, 500, 1000 features\n",
    "########################\n",
    "## Algoritmos de descrição\n",
    "# -- restringir área de checagem de pontos\n",
    "# -- criar algoritmo para contar falsos positivos\n",
    "## Imagem de teste\n",
    "# -- preciso escolher qual o terceiro par de imagens para testar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento com detectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Códigos detectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.04):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "\n",
    "    # Applying the function \n",
    "    dst = cv2.cornerHarris(gray_image_f32, blockSize, ksize, k) \n",
    "  \n",
    "    # dilate to mark the corners \n",
    "    dst = cv2.dilate(dst, None)\n",
    "    \n",
    "    ret, dst = cv2.threshold(dst,threshold*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # draw keypoints\n",
    "    # image[dst > threshold * dst.max()] = [0, 255, 0]\n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(255, 0, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSIFTKeypoints(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None) \n",
    "    \n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectStarKeypoints(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kp = star.detect(gray_image, None)    \n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "# kp, kp_image = detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.02)\n",
    "# print(len(kp))\n",
    "# cv2.imshow('Star', kp_image) \n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detectORBKeypoints(image, nfeatures=500, scaleFactor = 1.2, nlevels=8, edgeThreshold=31, WTA_K=2, patchSize=31):\n",
    "#     # Reading the image and converting the image to B/W \n",
    "#     gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "#     # Applying the function \n",
    "#     orb = cv2.ORB_create(\n",
    "#         nfeatures=nfeatures,\n",
    "#         scaleFactor=scaleFactor,\n",
    "#         nlevels=nlevels, \n",
    "#         edgeThreshold=edgeThreshold, \n",
    "#         WTA_K=WTA_K, \n",
    "#         patchSize=patchSize, \n",
    "#     ) \n",
    "#     kp, des = orb.detectAndCompute(gray_image, None)    \n",
    "\n",
    "#     # Applying the function \n",
    "#     kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "#     return kp, kp_image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código comparando pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def computeDistacesKeypoints(pts1, pts2, threshold=1):\n",
    "    array_pts1 = np.asarray(pts1)\n",
    "    array_pts2 = np.asarray(pts2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)  \n",
    "        matches = [pts2[pt] for pt, dist in zip(dists[0], dists[1]) if dist <= threshold]\n",
    "    else:\n",
    "        matches = []\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features_csv(params, algol, path):\n",
    "    if algol == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif algol == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "    \n",
    "    cols_name = [algol + '_' + param for param in list(params.keys())[1:]]\n",
    "    cols_result = [algol + '_' + 'qtd_keypoints', algol + '_' + 'keypoints']\n",
    "    df = pd.DataFrame(columns=cols_name+cols_result)\n",
    "    \n",
    "    keys = list(params)\n",
    "    for values in itertools.product(*map(params.get, keys)):\n",
    "        kps, kp_image = func_var(**dict(zip(keys, values)))\n",
    "        kps_ = [(kp.pt[0], kp.pt[1]) for kp in kps] #kp.angle, kp.response, kp.octave, kp.class_id) for kp in kps]\n",
    "\n",
    "        df.loc[len(df)] = list(values[1:]) + [len(kps_), kps_]\n",
    "\n",
    "    df.to_csv(path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_to_kp(string_points):\n",
    "    string_converted = list(eval(string_points))\n",
    "    # kps = [cv2.KeyPoint(x[0], x[1], 13) for x in string_converted]\n",
    "    # for p in string_converted:\n",
    "    #     kp = cv2.KeyPoint(x=float(p[0]), y=float(p[1]), size=float(p[2]), angle=float(p[3]),\n",
    "    #                 response=float(p[4]), octave=int(p[5]), class_id=int(p[6]))\n",
    "    #     kps.append(kp)\n",
    "    \n",
    "    return string_converted\n",
    "\n",
    "def comparing_keypoints_parallel(df, df1, df2, idx1, kp1_col, kp2_col, cols1, cols2, extra_cols):\n",
    "    kp1 = df1.loc[idx1][kp1_col]\n",
    "    df = pd.DataFrame(columns=cols1+cols2+extra_cols)\n",
    "    for idx2 in df2.index:\n",
    "        kp2 = df2.loc[idx2][kp2_col]\n",
    "        matches = computeDistacesKeypoints(kp1, kp2, threshold=2)\n",
    "\n",
    "        df.loc[len(df)] = df1.loc[idx1][cols1].tolist() + df2.loc[idx2][cols2].tolist() + [len(matches), matches]\n",
    "    return df\n",
    "\n",
    "def compare_and_save_match_points(df1, df2, kp1_col, kp2_col, path):\n",
    "    cols1 = list(df1.columns[:-1])\n",
    "    cols2 = list(df2.columns[:-1])\n",
    "    extra_cols = ['qtd_matches', 'match_keypoints']\n",
    "\n",
    "    df1_ = df1.copy()\n",
    "    df2_ = df2.copy()\n",
    "\n",
    "    df = pd.DataFrame(columns=cols1+cols2+extra_cols)\n",
    "    dfs = []\n",
    "    dfs = Parallel(n_jobs=-1)(delayed(comparing_keypoints_parallel)(df, df1_, df2_, idx1, kp1_col, kp2_col, cols1, cols2, extra_cols) for idx1 in df1_.index)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    # for idx1 in df1_.index:\n",
    "    #     kp1 = df1_.loc[idx1][kp1_col]\n",
    "    #     print(f'passou {idx1}')\n",
    "    #     for idx2 in df2_.index:\n",
    "    #         kp2 = df2_.loc[idx2][kp2_col]\n",
    "    #         matches = computeDistacesKeypoints(kp1, kp2, threshold=2)\n",
    "\n",
    "    #         df.loc[len(df)] = df1_.loc[idx1][cols1].tolist() + df2_.loc[idx2][cols2].tolist() + [len(matches), matches]\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando combinações de parâmetros dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "\n",
    "params_harris = {\n",
    "    'image': [image],\n",
    "    'threshold' : [0.005, 0.05, 0.1, 0.2],\n",
    "    'blockSize' : [2, 4, 6, 8],\n",
    "    'ksize' : [3, 5, 7, 9],\n",
    "    'k' : [0.02, 0.04, 0.08, 0.16]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'image': [image],\n",
    "    # 'nfeatures': [50, 100, 500, 1000],\n",
    "    'nOctaveLayers' : [3, 5, 7, 9],\n",
    "    'contrastThreshold' : [0.02, 0.04, 0.08, 0.1],\n",
    "    'edgeThreshold' : [5, 10, 20, 40],\n",
    "    'sigma' : [0.8, 1.6, 3.2, 6.4]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'image': [image],\n",
    "    'max_size': [11, 21, 41, 81],\n",
    "    'response_threshold': [5, 10, 20, 30],\n",
    "    'line_threshold_projected': [5, 10, 20, 30],\n",
    "    'line_threshold_binarized': [4, 8, 16, 32],\n",
    "    'suppress_nonmax_size': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "# df_harris = extract_and_save_features_csv(params_harris, 'harris', '../data/results/dsc07631/harris_keypoints_1.csv')\n",
    "# df_sift = extract_and_save_features_csv(params_sift, 'sift', '../data/results/dsc07631/sift_keypoints_1.csv')\n",
    "# df_orb = extract_and_save_features_csv(params_star, 'star', '../data/results/dsc07631/star_keypoints_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_harris = pd.read_csv('../data/results/dsc07631/harris_keypoints_1.csv')\n",
    "df_sift = pd.read_csv('../data/results/dsc07631/sift_keypoints_1.csv')\n",
    "df_star = pd.read_csv('../data/results/dsc07631/star_keypoints_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps1 = []\n",
    "for idx in df_harris.index.tolist():\n",
    "    kps1.append(convert_to_kp(df_harris['harris_keypoints'].loc[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps2 = []\n",
    "for idx in df_sift.index.tolist():\n",
    "    kps2.append(convert_to_kp(df_sift['sift_keypoints'].loc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps3 = []\n",
    "for idx in df_star.index.tolist():\n",
    "    kps3.append(convert_to_kp(df_star['star_keypoints'].loc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_harris['harris_keypoints'] = kps1\n",
    "df_sift['sift_keypoints'] = kps2\n",
    "df_star['star_keypoints'] = kps3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs = compare_and_save_match_points(df_harris, df_sift, 'harris_keypoints', 'sift_keypoints', '../data/results/dsc07631/harris_sift_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hst = compare_and_save_match_points(df_harris, df_star, 'harris_keypoints', 'star_keypoints', '../data/results/dsc07631/harris_star_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss = compare_and_save_match_points(df_sift, df_star, 'sift_keypoints', 'star_keypoints', '../data/results/dsc07631/sift_star_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harris_threshold</th>\n",
       "      <th>harris_blockSize</th>\n",
       "      <th>harris_ksize</th>\n",
       "      <th>harris_k</th>\n",
       "      <th>harris_qtd_keypoints</th>\n",
       "      <th>harris_keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10493</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9288</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5947</td>\n",
       "      <td>[(98.0, 2.0), (99.0, 2.0), (100.0, 2.0), (98.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8844</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7534</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   harris_threshold  harris_blockSize  harris_ksize  harris_k  \\\n",
       "0              0.01                 2             3      0.02   \n",
       "1              0.01                 2             3      0.04   \n",
       "2              0.01                 2             3      0.16   \n",
       "3              0.01                 2             5      0.02   \n",
       "4              0.01                 2             5      0.04   \n",
       "\n",
       "   harris_qtd_keypoints                                   harris_keypoints  \n",
       "0                 10493  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "1                  9288  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "2                  5947  [(98.0, 2.0), (99.0, 2.0), (100.0, 2.0), (98.0...  \n",
       "3                  8844  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "4                  7534  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_harris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=2)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro experimento\n",
    "- Rodando com os parâmetros default dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "h_kp, harris_image = detectHarrisKeypoints(image)\n",
    "s_kp, sift_image = detectSIFTKeypoints(image)\n",
    "o_kp, orb_image = detectStarKeypoints(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=1)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=1)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   9288\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD ORB Keypoints:   500\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   645\n",
      "Matches Keypoints Harris/ORB:   666\n",
      "Matches Keypoints SIFT/ORB:   80\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD ORB Keypoints:   {len(o_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/ORB:   {len(matches_ho)}')\n",
    "print(f'Matches Keypoints SIFT/ORB:   {len(matches_so)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_matches_hs = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_hs]\n",
    "kp_matches_ho = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_ho]\n",
    "kp_matches_so = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_so]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, kp_matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, kp_matches_ho, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, kp_matches_so, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('ORB', kp_matches_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=2)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   9288\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD ORB Keypoints:   500\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   2342\n",
      "Matches Keypoints Harris/ORB:   1430\n",
      "Matches Keypoints SIFT/ORB:   125\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD ORB Keypoints:   {len(o_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/ORB:   {len(matches_ho)}')\n",
    "print(f'Matches Keypoints SIFT/ORB:   {len(matches_so)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_matches_hs = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_hs]\n",
    "kp_matches_ho = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_ho]\n",
    "kp_matches_so = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_so]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, kp_matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, kp_matches_ho, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, kp_matches_so, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('Harris/SIFT', kp1_image)\n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Descritores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def calculate_slope(pt1, pt2):\n",
    "    slope = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0])\n",
    "    return slope\n",
    "\n",
    "\n",
    "def verify_slope(match, trainKeypoints, queryKeypoints, slope1, slope2):\n",
    "    slope = calculate_slope(trainKeypoints[match.trainIdx].pt, queryKeypoints[match.queryIdx].pt) \n",
    "    if slope <= slope2 and slope >= slope1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def verify_dist(match, trainKeypoints, queryKeypoints, dist1, dist2):\n",
    "    point1 = np.asarray(trainKeypoints[match.trainIdx].pt)\n",
    "    point2 = np.asarray(queryKeypoints[match.queryIdx].pt)\n",
    "\n",
    "    dist = np.linalg.norm(point1 - point2)\n",
    "\n",
    "    if dist <= dist2 and dist >= dist1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints):\n",
    "    slope_list = [calculate_slope(trainKeypoints[matches[i][0].trainIdx].pt, queryKeypoints[matches[i][0].queryIdx].pt) for i, m in enumerate(matchesMask)]\n",
    "    slope_list_mask = [calculate_slope(trainKeypoints[matches[i][0].trainIdx].pt, queryKeypoints[matches[i][0].queryIdx].pt) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "\n",
    "    return slope_list, slope_list_mask\n",
    "\n",
    "\n",
    "def calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints):\n",
    "    kps_train = [(trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]) for i, m in enumerate(matchesMask)]\n",
    "    kps_query = [(queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]) for i, m in enumerate(matchesMask)]\n",
    "\n",
    "    kps_train_ = [(trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "    kps_query_ = [(queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "    \n",
    "    array_pts_train = np.asarray(kps_train)\n",
    "    array_pts_query = np.asarray(kps_query)\n",
    "\n",
    "    array_pts_train_ = np.asarray(kps_train_)\n",
    "    array_pts_query_ = np.asarray(kps_query_)\n",
    "\n",
    "    dists = [np.linalg.norm(point1 - point2) for point1, point2 in zip(array_pts_train, array_pts_query)]\n",
    "    dists_mask = [np.linalg.norm(point1 - point2) for point1, point2 in zip(array_pts_train_, array_pts_query_)]\n",
    "\n",
    "    return dists, dists_mask\n",
    "\n",
    "\n",
    "def filter_matches_by_percentile(matches, matchesMask, trainKeypoints, queryKeypoints, q1, q2):\n",
    "    slope_list, slope_list_ = calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "    dists, dists_ = calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "\n",
    "    s1_, s2_ = np.percentile(slope_list_, [q1 ,q2])\n",
    "    d1_, d2_ = np.percentile(dists_, [q1 ,q2])\n",
    "    \n",
    "    matchesMask_ = [ [1,0] if m[0] > 0 and verify_slope(matches[i][0], trainKeypoints, queryKeypoints, s1_, s2_) else [0,0] for i, m in enumerate(matchesMask)]\n",
    "    matchesMask_ = [ [1,0] if m[0] > 0 and verify_dist(matches[i][0], trainKeypoints, queryKeypoints, d1_, d2_) else [0,0] for i, m in enumerate(matchesMask_)]\n",
    "\n",
    "    qtd_matches = len(matches)\n",
    "    qtd_matches_dlowe = len([m[0] for m in matchesMask if m[0] > 0 ])\n",
    "    qtd_matches_filter = len([m[0] for m in matchesMask_ if m[0] > 0 ])\n",
    "\n",
    "    qtd_fp_dlowe = qtd_matches - qtd_matches_dlowe\n",
    "    qtd_fp_filter = qtd_matches_dlowe - qtd_matches_filter\n",
    "    \n",
    "    # norm = np.linalg.norm(data)  # Calculate the L2 norm of the data\n",
    "    # normalized_data = data / norm\n",
    "\n",
    "    var_dist = np.var([d for m, d in zip(matchesMask, dists) if m[0] > 0 ])\n",
    "    var_slope = np.var([sl for m, sl in zip(matchesMask, slope_list) if m[0] > 0 ])\n",
    "\n",
    "    # mismatch_train_keypoints = len(trainKeypoints) - qtd_matches\n",
    "    # mismatch_query_keypoints = len(queryKeypoints) - qtd_matches\n",
    "\n",
    "    return matchesMask_, qtd_matches, qtd_matches_dlowe, qtd_matches_filter, qtd_fp_dlowe, qtd_fp_filter, var_dist, var_slope\n",
    "\n",
    "\n",
    "def filter_matches_by_variance(matches, trainKeypoints, queryKeypoints, var_dist, var_slope):\n",
    "    matchesMask_ = [[0,0] for i in range(len(matches))]\n",
    "    var_dist_ = -1\n",
    "    var_slope_ = -1\n",
    "    ratio_test_ = -1\n",
    "    \n",
    "    for ratio_test in np.arange(0.1, 1., 0.01):\n",
    "        matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "        for i,(m,n) in enumerate(matches):\n",
    "            if m.distance < ratio_test*n.distance:\n",
    "                matchesMask[i]=[1,0]\n",
    "\n",
    "        slope_list, slope_list_ = calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "        dists, dists_ = calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "\n",
    "        var_d = np.var(dists_)\n",
    "        var_s = np.var(slope_list_)\n",
    "\n",
    "        if var_d <= var_dist and var_s <= var_slope:\n",
    "            ratio_test_ = round(copy.copy(ratio_test), 2)\n",
    "            var_dist_ = var_d\n",
    "            var_slope_ = var_s\n",
    "            matchesMask_ = [m for m in matchesMask]\n",
    "        \n",
    "    \n",
    "    qtd_matches = len(matches)\n",
    "    qtd_matches_dlowe = len([m[0] for m in matchesMask_ if m[0] > 0 ])\n",
    "\n",
    "    qtd_fp_dlowe = qtd_matches - qtd_matches_dlowe\n",
    "\n",
    "    return matchesMask_, ratio_test_, qtd_matches, qtd_matches_dlowe, qtd_fp_dlowe, var_dist_, var_slope_\n",
    "\n",
    "\n",
    "\n",
    "def draw_matches(train_img, query_img, trainKeypoints, queryKeypoints, matches, matchesMask):\n",
    "    kps_train = [[trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "    kps_query = [[queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "\n",
    "    # draw the tracks\n",
    "    mask = np.zeros_like(train_img, 'uint8') \n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "    frame = query_img.copy()\n",
    "    \n",
    "    for i, (m, query, train) in enumerate(zip(matchesMask, kps_query, kps_train)):\n",
    "        a, b = query[0], query[1]\n",
    "        c, d = train[0], train[1]\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "        \n",
    "        if m[0] > 0:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2) \n",
    "            frame = cv2.circle(frame, (a, b), 4, point_true, -1)\n",
    "        else:\n",
    "            frame = cv2.circle(frame, (a, b), 4, point_false, -1)\n",
    "    \n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchDetectedKeypoints(train_img, query_img, var_dist, var_slope, detector='harris', descriptor='orb', dect_kargs={}, des_kargs={}):\n",
    "    query_img_bw = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if descriptor == 'brief':\n",
    "        des = cv2.xfeatures2d.BriefDescriptorExtractor_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    elif descriptor == 'brisk':\n",
    "        des = cv2.BRISK_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    else:\n",
    "        des = cv2.SIFT.create(**des_kargs)\n",
    "        norm_type = cv2.NORM_L2\n",
    "    \n",
    "    if detector == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif detector == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "\n",
    "    queryKeypoints, _ = func_var(query_img, **dect_kargs)\n",
    "    trainKeypoints, _ = func_var(train_img, **dect_kargs)\n",
    "    \n",
    "    _,queryDescriptors = des.compute(query_img_bw, queryKeypoints) \n",
    "    _,trainDescriptors = des.compute(train_img_bw, trainKeypoints)\n",
    "\n",
    "\n",
    "    matcher = cv2.BFMatcher(normType=norm_type, crossCheck=False) \n",
    "    matches = matcher.knnMatch(queryDescriptors,trainDescriptors, k=2) \n",
    "\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    # matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "    # for i,(m,n) in enumerate(matches):\n",
    "    #     if m.distance < ratio_test*n.distance:\n",
    "    #         matchesMask[i]=[1,0]\n",
    "\n",
    "    # m = filter_matches_by_percentile(matches, matchesMask, trainKeypoints, queryKeypoints, filter_slope[0], filter_slope[1])\n",
    "    \n",
    "    m = filter_matches_by_variance(matches, trainKeypoints, queryKeypoints, var_dist, var_slope)\n",
    "    matchesMask_, ratio_test_, qtd_matches, qtd_matches_dlowe, qtd_fp_dlowe, var_dist_, var_slope_ = m \n",
    "\n",
    "    print('---- Resultado ---- ')\n",
    "    print(f'Quantidade de keypoints train image: {len(trainKeypoints)}')\n",
    "    print(f'Quantidade de keypoints query image: {len(queryKeypoints)}')\n",
    "    print(f'Quantidade de matches: {qtd_matches}')\n",
    "    print(f'Valor ratio test D.Lowe: {ratio_test_}')\n",
    "    print(f'Quantidade de matches filtro D.Lowe: {qtd_matches_dlowe}')\n",
    "    print(f'Quantidade de falso D.Lowe: {qtd_fp_dlowe}')\n",
    "    print(f'Variância da distância: {var_dist_}')\n",
    "    print(f'Variância da inclinação da linha: {var_slope_}')\n",
    "\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                    singlePointColor = (255,0,0),\n",
    "                    matchesMask = matchesMask_,\n",
    "                    flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "    \n",
    "    # final_img = cv2.drawMatchesKnn(query_img,queryKeypoints,train_img,trainKeypoints,matches,None,**draw_params)\n",
    "\n",
    "    final_img = draw_matches(train_img, query_img, trainKeypoints, queryKeypoints, matches, matchesMask_)\n",
    "\n",
    "    \n",
    "    final_img = cv2.resize(final_img, (480,640))\n",
    "\n",
    "    return final_img \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sift = {\n",
    "    'nfeatures': 100,\n",
    "    'nOctaveLayers' : 1,\n",
    "    'contrastThreshold' : 0.04,\n",
    "    'edgeThreshold' : 20,\n",
    "    'sigma' : 1.6\n",
    "}\n",
    "\n",
    "params_harris = {\n",
    "    # 'image': [image],\n",
    "    'threshold' : 0.2,# [0.005, 0.01, 0.05, 0.1, 0.2],\n",
    "    'blockSize' : 6,#[2, 4, 6, 8],\n",
    "    'ksize' : 7,#[3, 5, 7, 9],\n",
    "    'k' : 0.16,#[0.02, 0.04, 0.08, 0.16]\n",
    "}\n",
    "\n",
    "params_brisk = {    \n",
    "    # 'thresh': 100,\t#AGAST detection threshold score.\n",
    "    # 'octaves':200,\t#detection octaves. Use 0 to do single scale.\n",
    "    'radiusList': [8, 9, 10],\t#defines the radii (in pixels) where the samples around a keypoint are taken (for keypoint scale 1).\n",
    "    'numberList': [12, 16, 20],\t#defines the number of sampling points on the sampling circle. Must be the same size as radiusList..\n",
    "    'dMax': 2,\t#threshold for the short pairings used for descriptor formation (in pixels for keypoint scale 1).\n",
    "    'dMin': 1,\t#threshold for the long pairings used for orientation determination (in pixels for keypoint scale 1).\n",
    "    # 'indexChange': 1,\t#index remapping of the bits.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg') \n",
    "train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg')\n",
    "# query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "# train_img = cv2.imread('../data/imgs/dsc07631.jpg') \n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "train_img_ = cv2.resize(train_img, (480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_img = matchDetectedKeypoints(train_img_, query_img_, 0.75, filter_slope=(0,100), detector='harris', descriptor='sift', dect_kargs=params_harris, des_kargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de keypoints train image: 316\n",
      "Quantidade de keypoints query image: 350\n",
      "Quantidade de matches: 350\n",
      "Valor ratio test D.Lowe: 0.55\n",
      "Quantidade de matches filtro D.Lowe: 148\n",
      "Quantidade de falso D.Lowe: 202\n",
      "Variância da distância: 9.628911904936926\n",
      "Variância da inclinação da linha: 0.0031546559590156244\n"
     ]
    }
   ],
   "source": [
    "final_img = matchDetectedKeypoints(train_img_, query_img_, 10, 1, detector='sift', descriptor='sift', dect_kargs={}, des_kargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_img) \n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Fluxo Óptico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[229  41 190]\n",
      " [202 214 159]\n",
      " [ 86 208 177]\n",
      " [165 216 246]\n",
      " [ 85   3 206]\n",
      " [240 193 161]\n",
      " [ 36 214 124]\n",
      " [ 79 202 122]\n",
      " [200 220 170]\n",
      " [254  80  22]\n",
      " [ 19 210 170]\n",
      " [186 179 248]\n",
      " [ 29 226   8]\n",
      " [ 88 240 106]\n",
      " [ 63  87 137]\n",
      " [ 66 144  46]\n",
      " [ 40 202   0]\n",
      " [132 128 104]\n",
      " [132  64 246]\n",
      " [ 68 111 150]\n",
      " [ 88 150 137]\n",
      " [ 83  98 127]\n",
      " [  7 161 139]\n",
      " [  9  54 238]\n",
      " [ 93  97 235]\n",
      " [ 52 243 174]\n",
      " [112  80  76]\n",
      " [ 11  11 249]\n",
      " [218 252  89]\n",
      " [207  30  57]\n",
      " [ 65   1  92]\n",
      " [207  20  41]\n",
      " [221   0 164]\n",
      " [192  94 136]\n",
      " [181 168 178]\n",
      " [ 42 230  95]\n",
      " [114  58  92]\n",
      " [214 128 254]\n",
      " [183 218 136]\n",
      " [110 165 109]\n",
      " [  7  74   3]\n",
      " [248  59  31]\n",
      " [144  61 200]\n",
      " [ 20 143  60]\n",
      " [ 88 248 129]\n",
      " [187 111   7]\n",
      " [ 20 138 208]\n",
      " [100 243  36]\n",
      " [ 28  65 232]\n",
      " [ 17  52  38]\n",
      " [227 172  94]\n",
      " [ 23  38   7]\n",
      " [ 64  81 183]\n",
      " [227 241   6]\n",
      " [ 34  57  63]\n",
      " [162 239 242]\n",
      " [ 58 176   3]\n",
      " [132 125 182]\n",
      " [ 28 237  61]\n",
      " [250 125   9]\n",
      " [235  92 132]\n",
      " [144  78 209]\n",
      " [181  90 204]\n",
      " [118  84 211]\n",
      " [ 48 122 157]\n",
      " [102 114 122]\n",
      " [ 56   3 174]\n",
      " [236 106 220]\n",
      " [ 87 155 229]\n",
      " [175  34 139]\n",
      " [200  89 120]\n",
      " [ 60 246 109]\n",
      " [ 11 137  94]\n",
      " [  7 190 174]\n",
      " [ 76 141 109]\n",
      " [ 15  59 170]\n",
      " [148 100 127]\n",
      " [ 33 222 144]\n",
      " [241  12 155]\n",
      " [ 16  44 126]\n",
      " [ 86 100 190]\n",
      " [211 239 220]\n",
      " [107 212  47]\n",
      " [ 99   7 136]\n",
      " [216  92  54]\n",
      " [ 93  56 118]\n",
      " [251  49 207]\n",
      " [253 191   6]\n",
      " [139  84  49]\n",
      " [225 133 142]\n",
      " [234 195  86]\n",
      " [ 55 134 216]\n",
      " [219  27 191]\n",
      " [151 151  72]\n",
      " [239 173 142]\n",
      " [190  85 182]\n",
      " [110 122 159]\n",
      " [148 126 228]\n",
      " [173 113  69]\n",
      " [191 118  31]]\n",
      "[[[191.23915  198.21149 ]]\n",
      "\n",
      " [[222.17218  177.48637 ]]\n",
      "\n",
      " [[227.13261  116.91931 ]]\n",
      "\n",
      " [[247.71074  127.79355 ]]\n",
      "\n",
      " [[247.34879  173.01222 ]]\n",
      "\n",
      " [[205.1057   110.37857 ]]\n",
      "\n",
      " [[147.26517  249.92639 ]]\n",
      "\n",
      " [[247.04094  140.79538 ]]\n",
      "\n",
      " [[206.35423  109.0392  ]]\n",
      "\n",
      " [[246.66109  301.53674 ]]\n",
      "\n",
      " [[245.70485  134.6861  ]]\n",
      "\n",
      " [[148.75833  114.70395 ]]\n",
      "\n",
      " [[148.75833  114.70395 ]]\n",
      "\n",
      " [[149.71797  332.51575 ]]\n",
      "\n",
      " [[149.71797  332.51575 ]]\n",
      "\n",
      " [[150.07066  332.355   ]]\n",
      "\n",
      " [[150.07066  332.355   ]]\n",
      "\n",
      " [[244.58022  109.97391 ]]\n",
      "\n",
      " [[153.56662  134.18045 ]]\n",
      "\n",
      " [[153.56662  134.18045 ]]\n",
      "\n",
      " [[243.92555  165.7214  ]]\n",
      "\n",
      " [[243.787    170.17772 ]]\n",
      "\n",
      " [[207.97775  146.79297 ]]\n",
      "\n",
      " [[207.97775  146.79297 ]]\n",
      "\n",
      " [[165.7798   228.0872  ]]\n",
      "\n",
      " [[169.89597  135.21222 ]]\n",
      "\n",
      " [[243.50015  139.19585 ]]\n",
      "\n",
      " [[174.34988  252.12978 ]]\n",
      "\n",
      " [[239.5376   133.48578 ]]\n",
      "\n",
      " [[235.40398  138.70346 ]]\n",
      "\n",
      " [[235.1636   324.02563 ]]\n",
      "\n",
      " [[222.4356   292.2376  ]]\n",
      "\n",
      " [[228.3875   117.58281 ]]\n",
      "\n",
      " [[231.48868  141.14197 ]]\n",
      "\n",
      " [[181.4298   112.58518 ]]\n",
      "\n",
      " [[229.38339  207.97061 ]]\n",
      "\n",
      " [[209.70573  122.45809 ]]\n",
      "\n",
      " [[183.36365  111.29308 ]]\n",
      "\n",
      " [[183.69435  245.72949 ]]\n",
      "\n",
      " [[229.15685  242.84006 ]]\n",
      "\n",
      " [[209.7704   122.06516 ]]\n",
      "\n",
      " [[228.91911  137.27417 ]]\n",
      "\n",
      " [[221.43452  260.45297 ]]\n",
      "\n",
      " [[184.81142  110.18304 ]]\n",
      "\n",
      " [[211.55101  145.2324  ]]\n",
      "\n",
      " [[221.43452  260.45297 ]]\n",
      "\n",
      " [[186.17221  109.033035]]\n",
      "\n",
      " [[186.1814   267.6211  ]]\n",
      "\n",
      " [[186.1814   267.6211  ]]\n",
      "\n",
      " [[217.43588  144.96013 ]]\n",
      "\n",
      " [[217.43588  144.96013 ]]\n",
      "\n",
      " [[216.26653  307.21402 ]]\n",
      "\n",
      " [[216.17328  325.61426 ]]\n",
      "\n",
      " [[214.63377  248.62407 ]]\n",
      "\n",
      " [[222.17218  177.48637 ]]\n",
      "\n",
      " [[319.87576  367.62033 ]]\n",
      "\n",
      " [[319.56662  369.95804 ]]\n",
      "\n",
      " [[319.27368  372.83093 ]]\n",
      "\n",
      " [[319.27368  372.83093 ]]\n",
      "\n",
      " [[317.30243  237.85075 ]]\n",
      "\n",
      " [[317.30243  237.85075 ]]\n",
      "\n",
      " [[316.20895  374.29327 ]]\n",
      "\n",
      " [[315.12976  361.01135 ]]\n",
      "\n",
      " [[191.23915  198.21149 ]]\n",
      "\n",
      " [[315.12976  361.01135 ]]\n",
      "\n",
      " [[315.12976  361.01135 ]]\n",
      "\n",
      " [[314.55502  370.4546  ]]\n",
      "\n",
      " [[314.55502  370.4546  ]]\n",
      "\n",
      " [[301.4451   144.6884  ]]\n",
      "\n",
      " [[301.4451   144.6884  ]]\n",
      "\n",
      " [[194.4404   195.95274 ]]\n",
      "\n",
      " [[194.50815  230.14415 ]]\n",
      "\n",
      " [[297.48022  334.2087  ]]\n",
      "\n",
      " [[195.11133  137.4855  ]]\n",
      "\n",
      " [[195.11133  137.4855  ]]\n",
      "\n",
      " [[285.9642   242.78772 ]]\n",
      "\n",
      " [[283.82278  221.91026 ]]\n",
      "\n",
      " [[281.5615   139.1197  ]]\n",
      "\n",
      " [[281.5615   139.1197  ]]\n",
      "\n",
      " [[196.84291  328.12866 ]]\n",
      "\n",
      " [[270.76764  114.38365 ]]\n",
      "\n",
      " [[267.7747   112.354454]]\n",
      "\n",
      " [[222.98058  190.73566 ]]\n",
      "\n",
      " [[266.4171   111.466484]]\n",
      "\n",
      " [[266.26593  243.6681  ]]\n",
      "\n",
      " [[200.78195  175.35925 ]]\n",
      "\n",
      " [[200.95396  175.30505 ]]\n",
      "\n",
      " [[201.05434  130.09906 ]]\n",
      "\n",
      " [[255.20084  111.026306]]\n",
      "\n",
      " [[250.89296  243.85304 ]]\n",
      "\n",
      " [[201.59026  124.87909 ]]\n",
      "\n",
      " [[201.59026  124.87909 ]]\n",
      "\n",
      " [[202.10086  113.321846]]\n",
      "\n",
      " [[202.70071  281.4235  ]]\n",
      "\n",
      " [[202.70071  281.4235  ]]\n",
      "\n",
      " [[250.88275  172.95752 ]]\n",
      "\n",
      " [[250.01248  114.483086]]\n",
      "\n",
      " [[203.76466  135.67902 ]]\n",
      "\n",
      " [[247.71074  127.79355 ]]\n",
      "\n",
      " [[225.62256  127.11348 ]]\n",
      "\n",
      " [[225.62256  127.11348 ]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg') \n",
    "query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg')\n",
    "# query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "# train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "# params for corner detection \n",
    "feature_params = dict( maxCorners = 100, \n",
    "                       qualityLevel = 0.2, \n",
    "                       minDistance = 7, \n",
    "                       blockSize = 7,\n",
    "                       useHarrisDetector = False) \n",
    "  \n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = dict( winSize = (16, 16), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "  \n",
    "# Create some random colors \n",
    "color = np.random.randint(0, 255, (100, 3)) \n",
    "print(color)\n",
    "# Take first frame and find corners in it \n",
    "old_frame = train_img_ \n",
    "old_gray = cv2.cvtColor(old_frame, \n",
    "                        cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv2.SIFT_create(nfeatures=100)\n",
    "\n",
    "p0 = sift.detect(old_gray)\n",
    "p0 = np.asarray([[[np.float32(kp.pt[0]), np.float32(kp.pt[1])]] for kp in p0])\n",
    "\n",
    "# p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params) \n",
    "\n",
    "print(p0)\n",
    "\n",
    "# Create a mask image for drawing purposes \n",
    "mask = np.zeros_like(old_frame, 'uint8') \n",
    "  \n",
    "\n",
    "frame = query_img_ \n",
    "frame_gray = cv2.cvtColor(frame, \n",
    "                            cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# calculate optical flow \n",
    "p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, \n",
    "                                        frame_gray, \n",
    "                                        p0, None, \n",
    "                                        **lk_params) \n",
    "\n",
    "# Select good points \n",
    "good_new = p1[st == 1] \n",
    "good_old = p0[st == 1] \n",
    "\n",
    "# draw the tracks\n",
    "for i, (new, old) in enumerate(zip(good_new,  \n",
    "                                    good_old)):\n",
    "    a, b = new.ravel() \n",
    "    c, d = old.ravel()\n",
    "    \n",
    "    a, b = int(a), int(b)\n",
    "    c, d = int(c), int(d)\n",
    "\n",
    "\n",
    "    mask = cv2.line(mask, (a, b), (c, d), \n",
    "                    color[0].tolist(), 2) \n",
    "        \n",
    "    frame = cv2.circle(frame, (a, b), 5, \n",
    "                        color[0].tolist(), -1) \n",
    "        \n",
    "img = cv2.add(frame, mask) \n",
    "\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey()\n",
    "\n",
    "# # Updating Previous frame and points  \n",
    "# old_gray = frame_gray.copy() \n",
    "# p0 = good_new.reshape(-1, 1, 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horn-Schunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow(img, flow, step=16):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "# Convert to gray scale\n",
    "prvs = cv2.cvtColor(train_img_, cv2.COLOR_BGR2GRAY)\n",
    "# Create mask\n",
    "hsv_mask = np.zeros_like(train_img_)\n",
    "# Make image saturation to a maximum value\n",
    "hsv_mask[..., 1] = 255\n",
    " \n",
    "# Capture another frame and convert to gray scale\n",
    "next = cv2.cvtColor(query_img_, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Optical flow is now calculated\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "mapped_img = draw_flow(next, flow, step=16)\n",
    "\n",
    "cv2.imshow('frame2', mapped_img)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
