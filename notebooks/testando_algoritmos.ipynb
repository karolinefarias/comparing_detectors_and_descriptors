{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### tarefas para fazer\n",
    "## Algoritmos de detecção\n",
    "# -- harris - OK\n",
    "# -- sift - OK\n",
    "# -- star/brisk OK\n",
    "# -- entender parâmetros harris, sift, star e brisk (pendente)\n",
    "# -- criar experimento para 25, 50, 100, 500, 1000 features (abandonado)\n",
    "########################\n",
    "## Algoritmos de descrição\n",
    "# -- restringir área de checagem de pontos \n",
    "# -- criar algoritmo para contar falsos positivos - OK\n",
    "## Imagem de teste\n",
    "# -- preciso escolher qual o terceiro par de imagens para testar -OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento com detectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Códigos detectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.04):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "\n",
    "    # Applying the function \n",
    "    dst = cv2.cornerHarris(gray_image_f32, blockSize, ksize, k) \n",
    "  \n",
    "    # dilate to mark the corners \n",
    "    dst = cv2.dilate(dst, None)\n",
    "    \n",
    "    ret, dst = cv2.threshold(dst,threshold*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # draw keypoints\n",
    "    # image[dst > threshold * dst.max()] = [0, 255, 0]\n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(255, 0, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSIFTKeypoints(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None) \n",
    "    \n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectStarKeypoints(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kp = star.detect(gray_image, None)    \n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "# kp, kp_image = detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.02)\n",
    "# print(len(kp))\n",
    "# cv2.imshow('Star', kp_image) \n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código comparando pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def computeDistacesKeypoints(pts1, pts2, threshold=1):\n",
    "    array_pts1 = np.asarray(pts1)\n",
    "    array_pts2 = np.asarray(pts2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)  \n",
    "        matches = [pts2[pt] for pt, dist in zip(dists[0], dists[1]) if dist <= threshold]\n",
    "    else:\n",
    "        matches = []\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features_csv(image, params, algol, path):\n",
    "    if algol == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif algol == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "    \n",
    "    cols_name = [algol + '_' + param for param in list(params.keys())[1:]]\n",
    "    cols_result = [algol + '_' + 'qtd_keypoints', algol + '_' + 'keypoints']\n",
    "    df = pd.DataFrame(columns=cols_name+cols_result)\n",
    "    \n",
    "    keys = list(params)\n",
    "    for values in itertools.product(*map(params.get, keys)):\n",
    "        kps, kp_image = func_var(image, **dict(zip(keys, values)))\n",
    "        kps_ = [(kp.pt[0], kp.pt[1]) for kp in kps] #kp.angle, kp.response, kp.octave, kp.class_id) for kp in kps]\n",
    "\n",
    "        df.loc[len(df)] = list(values[1:]) + [len(kps_), kps_]\n",
    "\n",
    "    df.to_csv(path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_to_kp(string_points):\n",
    "    string_converted = list(eval(string_points))\n",
    "    # kps = [cv2.KeyPoint(x[0], x[1], 13) for x in string_converted]\n",
    "    # for p in string_converted:\n",
    "    #     kp = cv2.KeyPoint(x=float(p[0]), y=float(p[1]), size=float(p[2]), angle=float(p[3]),\n",
    "    #                 response=float(p[4]), octave=int(p[5]), class_id=int(p[6]))\n",
    "    #     kps.append(kp)\n",
    "    \n",
    "    return string_converted\n",
    "\n",
    "\n",
    "def save_image_with_matches(image, kp1, kp2, kp_matches, path, name_img):\n",
    "    kp_image = image.copy()\n",
    "    path_img = f'{path}{name_img}.jpg' \n",
    "\n",
    "    kp1_ = [kp for kp in np.asarray(kp1) if kp not in np.asarray(kp_matches)]\n",
    "    kp2_ = [kp for kp in np.asarray(kp2) if kp not in np.asarray(kp_matches)]\n",
    "\n",
    "    kp1_ = [cv2.KeyPoint(x[0], x[1], 13) for x in kp1_]\n",
    "    kp2_ = [cv2.KeyPoint(x[0], x[1], 13) for x in kp2_]\n",
    "    kp_matches = [cv2.KeyPoint(x[0], x[1], 13) for x in kp_matches]\n",
    "\n",
    "    kp_image = cv2.drawKeypoints(kp_image, kp1_, None, color=(0, 0, 255), flags=0)\n",
    "    kp_image = cv2.drawKeypoints(kp_image, kp2_, None, color=(255, 0, 0), flags=0)\n",
    "    kp_image = cv2.drawKeypoints(kp_image, kp_matches, None, color=(0, 255, 0), flags=0)\n",
    "    \n",
    "    cv2.imwrite(path_img, kp_image)\n",
    "\n",
    "def comparing_keypoints_parallel(image, df, df1, df2, idx1, kp1_name, kp2_name, cols1, cols2, extra_cols, path):\n",
    "    kp1_col = f'{kp1_name}_keypoints'\n",
    "    kp2_col = f'{kp2_name}_keypoints'\n",
    "\n",
    "    kp1 = df1.loc[idx1][kp1_col]\n",
    "    df = pd.DataFrame(columns=cols1+cols2+extra_cols)\n",
    "    for idx2 in df2.index:\n",
    "        kp2 = df2.loc[idx2][kp2_col]\n",
    "        matches = computeDistacesKeypoints(kp1, kp2, threshold=2)\n",
    "        \n",
    "        # save_image_with_matches(image, kp1, kp2, matches, path, len(df))\n",
    "        \n",
    "        df.loc[len(df)] = df1.loc[idx1][cols1].tolist() + df2.loc[idx2][cols2].tolist() + [len(matches), matches]\n",
    "    return df\n",
    "\n",
    "def compare_and_save_match_points(image, df1, df2, kp1_name, kp2_name, path):\n",
    "    cols1 = list(df1.columns[:-1])\n",
    "    cols2 = list(df2.columns[:-1])\n",
    "    extra_cols = ['qtd_matches', 'match_keypoints']\n",
    "\n",
    "    df1_ = df1.copy()\n",
    "    df2_ = df2.copy()\n",
    "\n",
    "    df = pd.DataFrame(columns=cols1+cols2+extra_cols)\n",
    "    dfs = []\n",
    "    dfs = Parallel(n_jobs=-1)(delayed(comparing_keypoints_parallel)(image, df, df1_, df2_, idx1, kp1_name, kp2_name, cols1, cols2, extra_cols, path) for idx1 in df1_.index)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    path_csv = f'{path}matches_{kp1_name}_{kp2_name}.csv' \n",
    "    df.to_csv(path_csv, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando combinações de parâmetros dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_harris = {\n",
    "    # 'image': [image],\n",
    "    'threshold' : [0.005, 0.05, 0.1, 0.2],\n",
    "    'blockSize' : [2, 4, 6, 8],\n",
    "    'ksize' : [3, 5, 7, 9],\n",
    "    'k' : [0.02, 0.04, 0.08, 0.16]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    # 'image': [image],\n",
    "    # 'nfeatures': [50, 100, 500, 1000],\n",
    "    'nOctaveLayers' : [1, 3, 5, 7],\n",
    "    'contrastThreshold' : [0.02, 0.04, 0.08, 0.1],\n",
    "    'edgeThreshold' : [5, 10, 20, 40],\n",
    "    'sigma' : [0.8, 1.6, 3.2, 6.4]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    # 'image': [image],\n",
    "    'max_size': [11, 21, 41, 81],\n",
    "    'response_threshold': [5, 10, 20, 30],\n",
    "    'line_threshold_projected': [5, 10, 20, 30],\n",
    "    'line_threshold_binarized': [4, 8, 16, 32],\n",
    "    'suppress_nonmax_size': [2, 3, 5, 7]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "train_img_2 = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "\n",
    "train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "train_img_2_ = cv2.resize(train_img_2, (480,640))\n",
    "train_img_3_ = cv2.resize(train_img_3, (480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_imgs = ['IMG_20231217_075101', 'dsc07631', 'dsc02595']\n",
    "train_imgs = [train_img_1_, train_img_2_, train_img_3_]\n",
    "\n",
    "# for image, name_img in zip(train_imgs, name_imgs):\n",
    "#     df_harris = extract_and_save_features_csv(image, params_harris, 'harris', f'../results/{name_img}/harris_keypoints.csv')\n",
    "#     df_sift = extract_and_save_features_csv(image, params_sift, 'sift', f'../results/{name_img}/sift_keypoints.csv')\n",
    "#     df_star = extract_and_save_features_csv(image, params_star, 'star', f'../results/{name_img}/star_keypoints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_imgs = [\n",
    "    # 'IMG_20231217_075101',\n",
    "      'dsc07631', 'dsc02595']\n",
    "train_imgs = [\n",
    "    # train_img_1_,\n",
    "      train_img_2_, train_img_3_]\n",
    "\n",
    "for name_img, train_img in zip(name_imgs, train_imgs):\n",
    "    df_harris = pd.read_csv(f'../results/{name_img}/harris_keypoints.csv')\n",
    "    df_sift = pd.read_csv(f'../results/{name_img}/sift_keypoints.csv')\n",
    "    df_star = pd.read_csv(f'../results/{name_img}/star_keypoints.csv')\n",
    "\n",
    "    kps1 = []\n",
    "    for idx in df_harris.index.tolist():\n",
    "        kps1.append(convert_to_kp(df_harris['harris_keypoints'].loc[idx]))\n",
    "\n",
    "    kps2 = []\n",
    "    for idx in df_sift.index.tolist():\n",
    "        kps2.append(convert_to_kp(df_sift['sift_keypoints'].loc[idx]))\n",
    "\n",
    "    kps3 = []\n",
    "    for idx in df_star.index.tolist():\n",
    "        kps3.append(convert_to_kp(df_star['star_keypoints'].loc[idx]))\n",
    "\n",
    "    df_harris['harris_keypoints'] = kps1\n",
    "    df_sift['sift_keypoints'] = kps2\n",
    "    df_star['star_keypoints'] = kps3\n",
    "\n",
    "    df_hs = compare_and_save_match_points(train_img, df_harris, df_sift, 'harris', 'sift', f'../results/{name_img}/kp_harris_sift/')\n",
    "    df_hst = compare_and_save_match_points(train_img, df_harris, df_star, 'harris', 'star', f'../results/{name_img}/kp_harris_star/')\n",
    "    df_ss = compare_and_save_match_points(train_img, df_sift, df_star, 'sift', 'star', f'../results/{name_img}/kp_sift_star/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps1 = []\n",
    "for idx in df_harris.index.tolist():\n",
    "    kps1.append(convert_to_kp(df_harris['harris_keypoints'].loc[idx]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps2 = []\n",
    "for idx in df_sift.index.tolist():\n",
    "    kps2.append(convert_to_kp(df_sift['sift_keypoints'].loc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps3 = []\n",
    "for idx in df_star.index.tolist():\n",
    "    kps3.append(convert_to_kp(df_star['star_keypoints'].loc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_harris['harris_keypoints'] = kps1\n",
    "df_sift['sift_keypoints'] = kps2\n",
    "df_star['star_keypoints'] = kps3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs = compare_and_save_match_points(train_img_2, df_harris, df_sift, 'harris', 'sift', '../results/dsc07631/kp_harris_sift/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hst = compare_and_save_match_points(df_harris, df_star, 'harris_keypoints', 'star_keypoints', '../data/results/dsc07631/harris_star_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss = compare_and_save_match_points(df_sift, df_star, 'sift_keypoints', 'star_keypoints', '../data/results/dsc07631/sift_star_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harris_threshold</th>\n",
       "      <th>harris_blockSize</th>\n",
       "      <th>harris_ksize</th>\n",
       "      <th>harris_k</th>\n",
       "      <th>harris_qtd_keypoints</th>\n",
       "      <th>harris_keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10493</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9288</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5947</td>\n",
       "      <td>[(98.0, 2.0), (99.0, 2.0), (100.0, 2.0), (98.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8844</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7534</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   harris_threshold  harris_blockSize  harris_ksize  harris_k  \\\n",
       "0              0.01                 2             3      0.02   \n",
       "1              0.01                 2             3      0.04   \n",
       "2              0.01                 2             3      0.16   \n",
       "3              0.01                 2             5      0.02   \n",
       "4              0.01                 2             5      0.04   \n",
       "\n",
       "   harris_qtd_keypoints                                   harris_keypoints  \n",
       "0                 10493  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "1                  9288  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "2                  5947  [(98.0, 2.0), (99.0, 2.0), (100.0, 2.0), (98.0...  \n",
       "3                  8844  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "4                  7534  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_harris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=2)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro experimento\n",
    "- Rodando com os parâmetros default dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "h_kp, harris_image = detectHarrisKeypoints(image)\n",
    "s_kp, sift_image = detectSIFTKeypoints(image)\n",
    "o_kp, orb_image = detectStarKeypoints(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=1)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=1)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   9288\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD ORB Keypoints:   500\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   645\n",
      "Matches Keypoints Harris/ORB:   666\n",
      "Matches Keypoints SIFT/ORB:   80\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD ORB Keypoints:   {len(o_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/ORB:   {len(matches_ho)}')\n",
    "print(f'Matches Keypoints SIFT/ORB:   {len(matches_so)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_matches_hs = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_hs]\n",
    "kp_matches_ho = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_ho]\n",
    "kp_matches_so = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_so]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, kp_matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, kp_matches_ho, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, kp_matches_so, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('ORB', kp_matches_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=2)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   9288\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD ORB Keypoints:   500\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   2342\n",
      "Matches Keypoints Harris/ORB:   1430\n",
      "Matches Keypoints SIFT/ORB:   125\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD ORB Keypoints:   {len(o_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/ORB:   {len(matches_ho)}')\n",
    "print(f'Matches Keypoints SIFT/ORB:   {len(matches_so)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_matches_hs = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_hs]\n",
    "kp_matches_ho = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_ho]\n",
    "kp_matches_so = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_so]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, kp_matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, kp_matches_ho, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, kp_matches_so, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('Harris/SIFT', kp1_image)\n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Descritores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def calculate_slope(pt1, pt2):\n",
    "    slope = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0]) if (pt2[0] - pt1[0]) != 0 else -1\n",
    "    return slope\n",
    "\n",
    "\n",
    "def verify_slope(match, trainKeypoints, queryKeypoints, slope1, slope2):\n",
    "    slope = calculate_slope(trainKeypoints[match.trainIdx].pt, queryKeypoints[match.queryIdx].pt) \n",
    "    if slope <= slope2 and slope >= slope1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def verify_dist(match, trainKeypoints, queryKeypoints, dist1, dist2):\n",
    "    point1 = np.asarray(trainKeypoints[match.trainIdx].pt)\n",
    "    point2 = np.asarray(queryKeypoints[match.queryIdx].pt)\n",
    "\n",
    "    dist = np.linalg.norm(point1 - point2)\n",
    "\n",
    "    if dist <= dist2 and dist >= dist1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints):\n",
    "    slope_list = [calculate_slope(trainKeypoints[matches[i][0].trainIdx].pt, queryKeypoints[matches[i][0].queryIdx].pt) for i, m in enumerate(matchesMask)]\n",
    "    slope_list_mask = [calculate_slope(trainKeypoints[matches[i][0].trainIdx].pt, queryKeypoints[matches[i][0].queryIdx].pt) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "\n",
    "    return slope_list, slope_list_mask\n",
    "\n",
    "\n",
    "def calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints):\n",
    "    kps_train = [(trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]) for i, m in enumerate(matchesMask)]\n",
    "    kps_query = [(queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]) for i, m in enumerate(matchesMask)]\n",
    "\n",
    "    kps_train_ = [(trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "    kps_query_ = [(queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "    \n",
    "    array_pts_train = np.asarray(kps_train)\n",
    "    array_pts_query = np.asarray(kps_query)\n",
    "\n",
    "    array_pts_train_ = np.asarray(kps_train_)\n",
    "    array_pts_query_ = np.asarray(kps_query_)\n",
    "\n",
    "    dists = [np.linalg.norm(point1 - point2) for point1, point2 in zip(array_pts_train, array_pts_query)]\n",
    "    dists_mask = [np.linalg.norm(point1 - point2) for point1, point2 in zip(array_pts_train_, array_pts_query_)]\n",
    "\n",
    "    return dists, dists_mask\n",
    "\n",
    "\n",
    "def filter_matches_by_percentile(matches, matchesMask, trainKeypoints, queryKeypoints, q1, q2):\n",
    "    slope_list, slope_list_ = calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "    dists, dists_ = calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "\n",
    "    s1_, s2_ = np.percentile(slope_list_, [q1 ,q2])\n",
    "    d1_, d2_ = np.percentile(dists_, [q1 ,q2])\n",
    "    \n",
    "    matchesMask_ = [ [1,0] if m[0] > 0 and verify_slope(matches[i][0], trainKeypoints, queryKeypoints, s1_, s2_) else [0,0] for i, m in enumerate(matchesMask)]\n",
    "    matchesMask_ = [ [1,0] if m[0] > 0 and verify_dist(matches[i][0], trainKeypoints, queryKeypoints, d1_, d2_) else [0,0] for i, m in enumerate(matchesMask_)]\n",
    "\n",
    "    qtd_matches = len(matches)\n",
    "    qtd_matches_dlowe = len([m[0] for m in matchesMask if m[0] > 0 ])\n",
    "    qtd_matches_filter = len([m[0] for m in matchesMask_ if m[0] > 0 ])\n",
    "\n",
    "    qtd_fp_dlowe = qtd_matches - qtd_matches_dlowe\n",
    "    qtd_fp_filter = qtd_matches_dlowe - qtd_matches_filter\n",
    "\n",
    "    var_dist = np.var([d for m, d in zip(matchesMask, dists) if m[0] > 0 ])\n",
    "    var_slope = np.var([sl for m, sl in zip(matchesMask, slope_list) if m[0] > 0 ])\n",
    "\n",
    "    return matchesMask_, qtd_matches, qtd_matches_dlowe, qtd_matches_filter, qtd_fp_dlowe, qtd_fp_filter, var_dist, var_slope\n",
    "\n",
    "\n",
    "def filter_matches_by_variance(matches, trainKeypoints, queryKeypoints, var_dist, var_slope):\n",
    "    matchesMask_ = [[0,0] for i in range(len(matches))]\n",
    "    var_dist_ = -1\n",
    "    var_slope_ = -1\n",
    "    ratio_test_ = -1\n",
    "    \n",
    "    for ratio_test in np.arange(0.1, 1., 0.01):\n",
    "        matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "        for i,(m,n) in enumerate(matches):\n",
    "            if m.distance < ratio_test*n.distance:\n",
    "                matchesMask[i]=[1,0]\n",
    "\n",
    "        slope_list, slope_list_ = calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "        dists, dists_ = calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "\n",
    "        var_d = np.var(dists_)\n",
    "        var_s = np.var(slope_list_)\n",
    "\n",
    "        if var_d <= var_dist and var_s <= var_slope:\n",
    "            ratio_test_ = round(copy.copy(ratio_test), 2)\n",
    "            var_dist_ = var_d\n",
    "            var_slope_ = var_s\n",
    "            matchesMask_ = [m for m in matchesMask]\n",
    "        \n",
    "    qtd_matches = len(matches)\n",
    "    qtd_matches_dlowe = len([m[0] for m in matchesMask_ if m[0] > 0 ])\n",
    "\n",
    "    qtd_fp_dlowe = qtd_matches - qtd_matches_dlowe\n",
    "\n",
    "    return matchesMask_, ratio_test_, qtd_matches, qtd_matches_dlowe, qtd_fp_dlowe, var_dist_, var_slope_\n",
    "\n",
    "\n",
    "def draw_matches(train_img, query_img, trainKeypoints, queryKeypoints, matches, matchesMask):\n",
    "    kps_train = [[trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "    kps_query = [[queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "\n",
    "    # draw the tracks\n",
    "    mask = np.zeros_like(train_img, 'uint8') \n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "    frame = query_img.copy()\n",
    "    \n",
    "    for i, (m, query, train) in enumerate(zip(matchesMask, kps_query, kps_train)):\n",
    "        a, b = query[0], query[1]\n",
    "        c, d = train[0], train[1]\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "        \n",
    "        if m[0] > 0:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2) \n",
    "            frame = cv2.circle(frame, (a, b), 4, point_true, -1)\n",
    "        else:\n",
    "            frame = cv2.circle(frame, (a, b), 4, point_false, -1)\n",
    "    \n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchDetectedKeypoints(train_img, query_img, var_dist, var_slope, detector='harris', descriptor='orb', dect_kargs={}, des_kargs={}):\n",
    "    query_img_bw = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if descriptor == 'brief':\n",
    "        des = cv2.xfeatures2d.BriefDescriptorExtractor_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    elif descriptor == 'brisk':\n",
    "        des = cv2.BRISK_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    else:\n",
    "        des = cv2.SIFT.create(**des_kargs)\n",
    "        norm_type = cv2.NORM_L2\n",
    "    \n",
    "    if detector == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif detector == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "\n",
    "    queryKeypoints, _ = func_var(query_img, **dect_kargs)\n",
    "    trainKeypoints, _ = func_var(train_img, **dect_kargs)\n",
    "    \n",
    "    _,queryDescriptors = des.compute(query_img_bw, queryKeypoints) \n",
    "    _,trainDescriptors = des.compute(train_img_bw, trainKeypoints)\n",
    "\n",
    "\n",
    "    matcher = cv2.BFMatcher(normType=norm_type, crossCheck=False) \n",
    "    matches = matcher.knnMatch(queryDescriptors,trainDescriptors, k=2) \n",
    "\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    # matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "    # for i,(m,n) in enumerate(matches):\n",
    "    #     if m.distance < ratio_test*n.distance:\n",
    "    #         matchesMask[i]=[1,0]\n",
    "\n",
    "    # m = filter_matches_by_percentile(matches, matchesMask, trainKeypoints, queryKeypoints, filter_slope[0], filter_slope[1])\n",
    "    \n",
    "    m = filter_matches_by_variance(matches, trainKeypoints, queryKeypoints, var_dist, var_slope)\n",
    "    matchesMask_, ratio_test_, qtd_matches, qtd_matches_dlowe, qtd_fp_dlowe, var_dist_, var_slope_ = m \n",
    "\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                    singlePointColor = (255,0,0),\n",
    "                    matchesMask = matchesMask_,\n",
    "                    flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "    \n",
    "    # final_img = cv2.drawMatchesKnn(query_img,queryKeypoints,train_img,trainKeypoints,matches,None,**draw_params)\n",
    "    qtd_kp_train = len(trainKeypoints)\n",
    "    qtd_kp_query = len(queryKeypoints)\n",
    "\n",
    "    final_img = draw_matches(train_img, query_img, trainKeypoints, queryKeypoints, matches, matchesMask_)\n",
    "\n",
    "    final_img = cv2.resize(final_img, (480,640))\n",
    "\n",
    "    return final_img, qtd_kp_train, qtd_kp_query, ratio_test_, var_dist_, var_slope_, qtd_matches, qtd_matches_dlowe, qtd_fp_dlowe \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_save_result_matches_csv(train_img, query_img, var_dist, var_slope,\n",
    "                                       detector, descriptor, params_detector, path):\n",
    "    \n",
    "    cols_name = [param for param in list(params_detector.keys())]\n",
    "    cols_result = ['qtd_kp_train', 'qtd_kp_query', 'ratio_test', 'var_dist', 'var_slope',\n",
    "                    'qtd_matches', 'qtd_matches_dlowe', 'qtd_fp_dlowe']\n",
    "\n",
    "    df = pd.DataFrame(columns=cols_name+cols_result)\n",
    "    \n",
    "    keys = list(params_detector)\n",
    "    for i, values in enumerate(itertools.product(*map(params_detector.get, keys))):\n",
    "        try:\n",
    "            result = matchDetectedKeypoints(train_img, query_img, var_dist, var_slope,\n",
    "                                        detector, descriptor, dict(zip(keys, values)))\n",
    "        except:\n",
    "            result = [-1] + [-1 for i in range(len(cols_result))]\n",
    "\n",
    "        df.loc[len(df)] = list(values) + list(result[1:])\n",
    "        \n",
    "        path_img = path + f'matches_{detector}_{descriptor}/'+ str(i) + '.jpg'\n",
    "        cv2.imwrite(path_img, result[0])\n",
    "    \n",
    "    path_csv = path + f'matches_{detector}_{descriptor}/'+ f'matches_{detector}_{descriptor}.csv'\n",
    "    df.to_csv(path_csv)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_harris = {\n",
    "    'threshold' : [0.005, 0.05, 0.1, 0.2],\n",
    "    'blockSize' : [2, 4, 6, 8],\n",
    "    'ksize' : [3, 5, 7, 9],\n",
    "    'k' : [0.02, 0.04, 0.08, 0.16]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    # 'nfeatures': [50, 100, 500, 1000],\n",
    "    'nOctaveLayers' : [1, 3, 5, 7],\n",
    "    'contrastThreshold' : [0.02, 0.04, 0.08, 0.1],\n",
    "    'edgeThreshold' : [5, 10, 20, 40],\n",
    "    'sigma' : [0.8, 1.6, 3.2, 6.4]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'max_size': [11, 21, 41, 81],\n",
    "    'response_threshold': [5, 10, 20, 30],\n",
    "    'line_threshold_projected': [5, 10, 20, 30],\n",
    "    'line_threshold_binarized': [4, 8, 16, 32],\n",
    "    'suppress_nonmax_size': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "var_img_pacoca = (1, 0.001) # IMG_20231217_075107.jpg\n",
    "var_img1 = (4, 0.02) # dsc07632.jpg\n",
    "var_img2 = (3, 0.05) # dsc02596.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "\n",
    "query_img_2 = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img_2 = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "\n",
    "query_img_3 = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "\n",
    "query_img_1_ = cv2.resize(query_img_1, (480,640))\n",
    "train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "\n",
    "query_img_2_ = cv2.resize(query_img_2, (480,640))\n",
    "train_img_2_ = cv2.resize(train_img_2, (480,640))\n",
    "\n",
    "query_img_3_ = cv2.resize(query_img_3, (480,640))\n",
    "train_img_3_ = cv2.resize(train_img_3, (480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_imgs = ['IMG_20231217_075101', 'dsc07631', 'dsc02595']\n",
    "train_imgs = [train_img_1_, train_img_2_, train_img_3_]\n",
    "query_imgs = [query_img_1_, query_img_2_, query_img_3_]\n",
    "variances = [var_img_pacoca, var_img1, var_img2]\n",
    "params_detectors = [params_harris,  params_star, params_sift]\n",
    "detectors = ['harris', 'star', 'sift']\n",
    "descriptors = ['sift', 'brisk']\n",
    "\n",
    "for name_img, var, train_img, query_img in zip(name_imgs, variances,\n",
    "                                                        train_imgs, query_imgs):\n",
    "     path = f'../results/{name_img}/'\n",
    "     Parallel(n_jobs=-1)(delayed(detect_and_save_result_matches_csv)(train_img, query_img, var[0], var[1],detector, descriptor, params, path) for detector, params in zip(detectors, params_detectors) for descriptor in descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel(n_jobs=-1)(delayed(comparing_keypoints_parallel)(df, df1_, df2_, idx1, kp1_col, kp2_col, cols1, cols2, extra_cols) for idx1 in df1_.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sift_2 = {\n",
    "    # 'nfeatures': 100,\n",
    "    'nOctaveLayers' : 1,\n",
    "    'contrastThreshold' : 0.08,\n",
    "    'edgeThreshold' : 20,\n",
    "    'sigma' : 1.6\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de keypoints train image: 132\n",
      "Quantidade de keypoints query image: 133\n",
      "Quantidade de matches: 133\n",
      "Valor ratio test D.Lowe: 0.66\n",
      "Quantidade de matches filtro D.Lowe: 60\n",
      "Quantidade de falso D.Lowe: 73\n",
      "Variância da distância: 0.2038136775340516\n",
      "Variância da inclinação da linha: 0.0004199397953293102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = matchDetectedKeypoints(train_img_1_, query_img_1_, 3, 0.05, detector='sift', descriptor='brisk', dect_kargs=params_sift_2, des_kargs={})\n",
    "final_img, qtd_kp_train, qtd_kp_query, ratio_test, var_dist, var_slope, qtd_matches, qtd_matches_dlowe, qtd_fp_dlowe = result \n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de keypoints train image: {qtd_kp_train}')\n",
    "print(f'Quantidade de keypoints query image: {qtd_kp_query}')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Valor ratio test D.Lowe: {ratio_test}')\n",
    "print(f'Quantidade de matches filtro D.Lowe: {qtd_matches_dlowe}')\n",
    "print(f'Quantidade de falso D.Lowe: {qtd_fp_dlowe}')\n",
    "print(f'Variância da distância: {var_dist}')\n",
    "print(f'Variância da inclinação da linha: {var_slope}')\n",
    "\n",
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_img) \n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Fluxo Óptico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_points(old_points, new_points):\n",
    "    array_pts_train = np.asarray(old_points)\n",
    "    array_pts_query = np.asarray(new_points)\n",
    "    \n",
    "    dists = [ np.linalg.norm(p1 - p2) for p1, p2 in zip(array_pts_train, array_pts_query)]\n",
    "\n",
    "    return dists\n",
    "\n",
    "\n",
    "def calculate_slope(pt1, pt2):\n",
    "    slope = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0]) if (pt2[0] - pt1[0]) != 0 else -1\n",
    "    return slope\n",
    "\n",
    "\n",
    "def calculate_slope_points(old_points, new_points):\n",
    "    array_pts_train = np.asarray(old_points)\n",
    "    array_pts_query = np.asarray(new_points)\n",
    "    \n",
    "    slopes = [ calculate_slope(p1, p2) for p1, p2 in zip(array_pts_train, array_pts_query)]\n",
    "\n",
    "    return slopes\n",
    "\n",
    "\n",
    "def filter_outliers(data, old_points, new_points):\n",
    "\n",
    "    Q1 = np.percentile(data, 25) \n",
    "    Q2 = np.percentile(data, 50) \n",
    "    Q3 = np.percentile(data, 75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    low_lim = Q1 - 1.5 * IQR\n",
    "    up_lim = Q3 + 1.5 * IQR\n",
    "\n",
    "    filtered_old = [ old_points[i] for i, d in enumerate(data) if d <= up_lim and d >= low_lim]\n",
    "    filtered_new = [ new_points[i] for i, d in enumerate(data) if d <= up_lim and d >= low_lim]\n",
    "\n",
    "    return filtered_old, filtered_new\n",
    "\n",
    "\n",
    "def filter_by_variance(old_points, new_points, var_dist, var_slope):\n",
    "    dists = calculate_distance_points(old_points, new_points)\n",
    "    slopes = calculate_slope_points(old_points, new_points)\n",
    "\n",
    "    filtered_old = [p for p in old_points]\n",
    "    filtered_new = [p for p in new_points]\n",
    "\n",
    "    var_dist_ = np.var(dists)\n",
    "    var_slope_ = np.var(slopes)\n",
    "    loop_limit = 100\n",
    "    \n",
    "    while(var_dist_ > var_dist or var_slope_ > var_slope):\n",
    "        dists = calculate_distance_points(filtered_old, filtered_new)\n",
    "        var_dist_ = np.var(dists)\n",
    "\n",
    "        if var_dist_ > var_dist:\n",
    "            filtered_old, filtered_new = filter_outliers(dists, filtered_old, filtered_new)\n",
    "        \n",
    "        slopes = calculate_slope_points(filtered_old, filtered_new)\n",
    "        var_slope_ = np.var(slopes)\n",
    "\n",
    "        if var_slope_ > var_slope:\n",
    "            filtered_old, filtered_new = filter_outliers(slopes, filtered_old, filtered_new)\n",
    "        \n",
    "        if loop_limit > 0:\n",
    "            loop_limit -= 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return np.asarray(filtered_old), np.asarray(filtered_new)\n",
    "\n",
    "\n",
    "def lucas_kanade_opflow(train_img, query_img, feature_params, lk_params, var_dist, var_slope):\n",
    "    \n",
    "    # Take first frame and find corners in it \n",
    "    old_frame = train_img.copy() \n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params) \n",
    "\n",
    "    # Create a mask image for drawing purposes \n",
    "\n",
    "    mask = np.zeros_like(old_frame, 'uint8') \n",
    "    \n",
    "    frame = query_img.copy()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # calculate optical flow \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params) \n",
    "\n",
    "    # Select good points \n",
    "    good_new = p1[st == 1] \n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    good_old_, good_new_ = filter_by_variance(good_old, good_new, var_dist, var_slope)\n",
    "    dists = calculate_distance_points(good_old_, good_new_)\n",
    "    slopes = calculate_slope_points(good_old_, good_new_)\n",
    "    \n",
    "    var_dist_ = np.var(dists)\n",
    "    var_slope_ = np.var(slopes)\n",
    "    \n",
    "    qtd_matches = len(good_new)\n",
    "    qtd_matches_filtered = len(good_new_)\n",
    "    qtd_fp = qtd_matches - qtd_matches_filtered\n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new,  \n",
    "                                        good_old)):\n",
    "        a, b = new.ravel() \n",
    "        c, d = old.ravel()\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "\n",
    "        if new in good_new_:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "            frame = cv2.circle(frame, (a, b), 5, point_true, -1) \n",
    "        else:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "            frame = cv2.circle(frame, (a, b), 5, point_false, -1)\n",
    "            \n",
    "    img = cv2.add(frame, mask) \n",
    "\n",
    "    return img, var_dist_, var_slope_, qtd_matches, qtd_matches_filtered, qtd_fp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lk_and_save_result_matches_csv(train_img, query_img, features_params, lk_params, name_img):\n",
    "    cols_features = [param for param in list(features_params.keys())]\n",
    "    cols_lk = [param for param in list(lk_params.keys())]\n",
    "\n",
    "    cols_name = cols_features + cols_lk\n",
    "\n",
    "    cols_result = ['var_dist', 'var_slope', 'qtd_matches', 'qtd_matches_filtered', 'qtd_fp']\n",
    "\n",
    "    df = pd.DataFrame(columns=cols_name+cols_result)\n",
    "    \n",
    "    keys_feat = list(features_params)\n",
    "    keys_lk = list(lk_params)\n",
    "    path = f'../results/{name_img}/lk_matches/'\n",
    "    i = 0\n",
    "    for values_feat in itertools.product(*map(features_params.get, keys_feat)):\n",
    "        for values_lk in itertools.product(*map(lk_params.get, keys_lk)):\n",
    "            try:\n",
    "                result = lucas_kanade_opflow(train_img, query_img, dict(zip(keys_feat, values_feat)), \n",
    "                                            dict(zip(keys_lk, values_lk)), 0, 0) \n",
    "            except:\n",
    "                result = [-1] + [-1 for i in range(len(cols_result))]\n",
    "\n",
    "            df.loc[len(df)] = list(values_feat) + list(values_lk) + list(result[1:])\n",
    "            \n",
    "            path_img = path + str(i) + '.jpg'\n",
    "            cv2.imwrite(path_img, result[0])\n",
    "            i+=1\n",
    "    \n",
    "    path_csv = path + 'lk_matches.csv'\n",
    "    df.to_csv(path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "query_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "\n",
    "query_img_2 = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img_2 = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "\n",
    "query_img_3 = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "\n",
    "query_img_1_ = cv2.resize(query_img_1, (480,640))\n",
    "train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "\n",
    "query_img_2_ = cv2.resize(query_img_2, (480,640))\n",
    "train_img_2_ = cv2.resize(train_img_2, (480,640))\n",
    "\n",
    "query_img_3_ = cv2.resize(query_img_3, (480,640))\n",
    "train_img_3_ = cv2.resize(train_img_3, (480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_params = {\n",
    "    'maxCorners' : [25, 50, 100], \n",
    "    'qualityLevel' : [0.02, 0.05, 0.1],\n",
    "    'minDistance' : [3, 7, 9] , \n",
    "    'blockSize' : [3, 7, 9],\n",
    "    'useHarrisDetector' : [False]\n",
    "} \n",
    "  \n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = {\n",
    "    'winSize' : [(8, 8), (16, 16), (24, 24)], \n",
    "    'maxLevel': [2, 4, 8], \n",
    "    'criteria': [(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)]\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 1238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_imgs = ['IMG_20231217_075101', 'dsc07631', 'dsc02595']\n",
    "train_imgs = [train_img_1_, train_img_2_, train_img_3_]\n",
    "query_imgs = [query_img_1_, query_img_2_, query_img_3_]\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(lk_and_save_result_matches_csv)(train_img, query_img, features_params, lk_params, name_img) for name_img, train_img, query_img in zip(name_imgs, train_imgs, query_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 100\n",
      "Quantidade de matches filtro outliers: 91\n",
      "Quantidade de falso positivo: 9\n",
      "Variância da distância: 0.241999089717865\n",
      "Variância da inclinação da linha: 0.00028355419635772705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "train_img = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg') \n",
    "query_img = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg')\n",
    "# query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "# train_img = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "# params for corner detection \n",
    "feature_params = dict( maxCorners = 100, \n",
    "                       qualityLevel = 0.02, \n",
    "                       minDistance = 7, \n",
    "                       blockSize = 7,\n",
    "                       useHarrisDetector = False) \n",
    "  \n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = dict( winSize = (16, 16), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "  \n",
    "\n",
    "lk_result = lucas_kanade_opflow(train_img_, query_img_, feature_params, lk_params, 0, 0)\n",
    "\n",
    "img, var_dist, var_slope, qtd_matches, qtd_matches_filtered, qtd_fp = lk_result\n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de matches filtro outliers: {qtd_matches_filtered}')\n",
    "print(f'Quantidade de falso positivo: {qtd_fp}')\n",
    "print(f'Variância da distância: {var_dist}')\n",
    "print(f'Variância da inclinação da linha: {var_slope}')\n",
    "\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horn-Schunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow(img, flow, new_points_, step=24):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "    # cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    \n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        if np.asarray([x2, y2]) in new_points_:\n",
    "            cv2.circle(vis, (x1, y1), 2, point_true, -1)\n",
    "            cv2.line(vis, (x1, y1), (x2, y2), line, 1)\n",
    "        else:\n",
    "            cv2.circle(vis, (x1, y1), 2, point_false, -1)\n",
    "            cv2.line(vis, (x1, y1), (x2, y2), line, 1)\n",
    "    return vis\n",
    "\n",
    "\n",
    "def return_points_hs(img, flow, step=24):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    old_points = np.asarray([[x1, y1] for (x1, y1), (x2, y2) in lines if calculate_distance_points([[x1, y1]], [[x2, y2]])[0] > 0.5])\n",
    "    new_points = np.asarray([[x2, y2] for (x1, y1), (x2, y2) in lines if calculate_distance_points([[x1, y1]], [[x2, y2]])[0] > 0.5])\n",
    "\n",
    "    return old_points, new_points\n",
    "\n",
    "\n",
    "def horn_schunck_opflow(train_img, query_img, params_horn_schunck):\n",
    "    # Convert to gray scale\n",
    "    prvs = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Capture another frame and convert to gray scale\n",
    "    next = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Optical flow is now calculated\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev=prvs, next=next,flow=None, flags=0, **params_horn_schunck)\n",
    "\n",
    "    # Calculated fp points\n",
    "    old_points, new_points = return_points_hs(next, flow, step=24)\n",
    "    old_points_, new_points_ = filter_by_variance(old_points, new_points, 0.0, 0.0)\n",
    "    dists = calculate_distance_points(old_points_, new_points_)\n",
    "    slopes = calculate_slope_points(old_points_, new_points_)\n",
    "\n",
    "    var_dist_ = np.var(dists)\n",
    "    var_slope_ = np.var(slopes)\n",
    "\n",
    "    qtd_matches = len(new_points)\n",
    "    qtd_matches_filtered = len(new_points_)\n",
    "    qtd_fp = qtd_matches - qtd_matches_filtered\n",
    "\n",
    "    mapped_img = draw_flow(next, flow, new_points_, step=24)\n",
    "\n",
    "    return mapped_img, var_dist_, var_slope_, qtd_matches, qtd_matches_filtered, qtd_fp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hs_and_save_result_matches_csv(train_img, query_img, hs_params, name_img):\n",
    "    cols_name = [param for param in list(hs_params.keys())]\n",
    "\n",
    "    cols_result = ['var_dist', 'var_slope', 'qtd_matches', 'qtd_matches_filtered', 'qtd_fp']\n",
    "\n",
    "    df = pd.DataFrame(columns=cols_name+cols_result)\n",
    "    \n",
    "    keys = list(hs_params)\n",
    "    path = f'../results/{name_img}/hs_matches/'\n",
    "    \n",
    "    for i, values in enumerate(itertools.product(*map(hs_params.get, keys))):\n",
    "        try:\n",
    "            result = horn_schunck_opflow(train_img, query_img, dict(zip(keys, values)))\n",
    "        except:\n",
    "            result = [-1] + [-1 for i in range(len(cols_result))]\n",
    "\n",
    "        df.loc[len(df)] = list(values) + list(result[1:])\n",
    "        \n",
    "        path_img = path + str(i) + '.jpg'\n",
    "        cv2.imwrite(path_img, result[0])\n",
    "    \n",
    "    path_csv = path + 'hs_matches.csv'\n",
    "    df.to_csv(path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "query_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "train_img_1 = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "\n",
    "query_img_2 = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img_2 = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "\n",
    "query_img_3 = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "train_img_3 = cv2.imread('../data/imgs/dsc02595.jpg')\n",
    "\n",
    "query_img_1_ = cv2.resize(query_img_1, (480,640))\n",
    "train_img_1_ = cv2.resize(train_img_1, (480,640))\n",
    "\n",
    "query_img_2_ = cv2.resize(query_img_2, (480,640))\n",
    "train_img_2_ = cv2.resize(train_img_2, (480,640))\n",
    "\n",
    "query_img_3_ = cv2.resize(query_img_3, (480,640))\n",
    "train_img_3_ = cv2.resize(train_img_3, (480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_horn_schunck = {\n",
    "    'pyr_scale': [0.1, 0.5, 0.8],\n",
    "    'levels': [3, 6, 9], \n",
    "    'winsize': [15, 30, 45],\n",
    "    'iterations': [3, 15, 30], \n",
    "    'poly_n': [3, 6, 9], \n",
    "    'poly_sigma': [1.2, 1.6, 2.4]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 1271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_imgs = ['IMG_20231217_075101', 'dsc07631', 'dsc02595']\n",
    "train_imgs = [train_img_1_, train_img_2_, train_img_3_]\n",
    "query_imgs = [query_img_1_, query_img_2_, query_img_3_]\n",
    "\n",
    "Parallel(n_jobs=-1)(delayed(hs_and_save_result_matches_csv)(train_img, query_img, params_horn_schunck, name_img) for name_img, train_img, query_img in zip(name_imgs, train_imgs, query_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 475\n",
      "Quantidade de matches filtro outliers: 309\n",
      "Quantidade de falso positivo: 166\n",
      "Variância da distância: 3.2450807925440697\n",
      "Variância da inclinação da linha: 0.018452262684142417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "params_horn_schunck = dict(pyr_scale=0.5, levels=3, winsize=15,\n",
    "                           iterations=3, poly_n=5, poly_sigma=1.2)\n",
    "\n",
    "hs_optical = horn_schunck_opflow(train_img_, query_img_, params_horn_schunck)\n",
    "mapped_img, var_dist, var_slope, qtd_matches, qtd_matches_filtered, qtd_fp = hs_optical\n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de matches filtro outliers: {qtd_matches_filtered}')\n",
    "print(f'Quantidade de falso positivo: {qtd_fp}')\n",
    "print(f'Variância da distância: {var_dist}')\n",
    "print(f'Variância da inclinação da linha: {var_slope}')\n",
    "\n",
    "cv2.imshow('frame2', mapped_img)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
