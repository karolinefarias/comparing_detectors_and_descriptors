{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### tarefas para fazer\n",
    "## Algoritmos de detecção\n",
    "# -- harris - OK\n",
    "# -- sift - OK\n",
    "# -- star/brisk OK\n",
    "# -- entender parâmetros harris, sift, star e brisk (pendente)\n",
    "# -- criar experimento para 25, 50, 100, 500, 1000 features\n",
    "########################\n",
    "## Algoritmos de descrição\n",
    "# -- restringir área de checagem de pontos\n",
    "# -- criar algoritmo para contar falsos positivos\n",
    "## Imagem de teste\n",
    "# -- preciso escolher qual o terceiro par de imagens para testar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento com detectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Códigos detectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.04):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "\n",
    "    # Applying the function \n",
    "    dst = cv2.cornerHarris(gray_image_f32, blockSize, ksize, k) \n",
    "  \n",
    "    # dilate to mark the corners \n",
    "    dst = cv2.dilate(dst, None)\n",
    "    \n",
    "    ret, dst = cv2.threshold(dst,threshold*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # draw keypoints\n",
    "    # image[dst > threshold * dst.max()] = [0, 255, 0]\n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(255, 0, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSIFTKeypoints(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None) \n",
    "    \n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectStarKeypoints(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kp = star.detect(gray_image, None)    \n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "# kp, kp_image = detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.02)\n",
    "# print(len(kp))\n",
    "# cv2.imshow('Star', kp_image) \n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detectORBKeypoints(image, nfeatures=500, scaleFactor = 1.2, nlevels=8, edgeThreshold=31, WTA_K=2, patchSize=31):\n",
    "#     # Reading the image and converting the image to B/W \n",
    "#     gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "#     # Applying the function \n",
    "#     orb = cv2.ORB_create(\n",
    "#         nfeatures=nfeatures,\n",
    "#         scaleFactor=scaleFactor,\n",
    "#         nlevels=nlevels, \n",
    "#         edgeThreshold=edgeThreshold, \n",
    "#         WTA_K=WTA_K, \n",
    "#         patchSize=patchSize, \n",
    "#     ) \n",
    "#     kp, des = orb.detectAndCompute(gray_image, None)    \n",
    "\n",
    "#     # Applying the function \n",
    "#     kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "#     return kp, kp_image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código comparando pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def computeDistacesKeypoints(pts1, pts2, threshold=1):\n",
    "    array_pts1 = np.asarray(pts1)\n",
    "    array_pts2 = np.asarray(pts2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)  \n",
    "        matches = [pts2[pt] for pt, dist in zip(dists[0], dists[1]) if dist <= threshold]\n",
    "    else:\n",
    "        matches = []\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features_csv(params, algol, path):\n",
    "    if algol == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif algol == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "    \n",
    "    cols_name = [algol + '_' + param for param in list(params.keys())[1:]]\n",
    "    cols_result = [algol + '_' + 'qtd_keypoints', algol + '_' + 'keypoints']\n",
    "    df = pd.DataFrame(columns=cols_name+cols_result)\n",
    "    \n",
    "    keys = list(params)\n",
    "    for values in itertools.product(*map(params.get, keys)):\n",
    "        kps, kp_image = func_var(**dict(zip(keys, values)))\n",
    "        kps_ = [(kp.pt[0], kp.pt[1]) for kp in kps] #kp.angle, kp.response, kp.octave, kp.class_id) for kp in kps]\n",
    "\n",
    "        df.loc[len(df)] = list(values[1:]) + [len(kps_), kps_]\n",
    "\n",
    "    df.to_csv(path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_to_kp(string_points):\n",
    "    string_converted = list(eval(string_points))\n",
    "    # kps = [cv2.KeyPoint(x[0], x[1], 13) for x in string_converted]\n",
    "    # for p in string_converted:\n",
    "    #     kp = cv2.KeyPoint(x=float(p[0]), y=float(p[1]), size=float(p[2]), angle=float(p[3]),\n",
    "    #                 response=float(p[4]), octave=int(p[5]), class_id=int(p[6]))\n",
    "    #     kps.append(kp)\n",
    "    \n",
    "    return string_converted\n",
    "\n",
    "def comparing_keypoints_parallel(df, df1, df2, idx1, kp1_col, kp2_col, cols1, cols2, extra_cols):\n",
    "    kp1 = df1.loc[idx1][kp1_col]\n",
    "    df = pd.DataFrame(columns=cols1+cols2+extra_cols)\n",
    "    for idx2 in df2.index:\n",
    "        kp2 = df2.loc[idx2][kp2_col]\n",
    "        matches = computeDistacesKeypoints(kp1, kp2, threshold=2)\n",
    "\n",
    "        df.loc[len(df)] = df1.loc[idx1][cols1].tolist() + df2.loc[idx2][cols2].tolist() + [len(matches), matches]\n",
    "    return df\n",
    "\n",
    "def compare_and_save_match_points(df1, df2, kp1_col, kp2_col, path):\n",
    "    cols1 = list(df1.columns[:-1])\n",
    "    cols2 = list(df2.columns[:-1])\n",
    "    extra_cols = ['qtd_matches', 'match_keypoints']\n",
    "\n",
    "    df1_ = df1.copy()\n",
    "    df2_ = df2.copy()\n",
    "\n",
    "    df = pd.DataFrame(columns=cols1+cols2+extra_cols)\n",
    "    dfs = []\n",
    "    dfs = Parallel(n_jobs=-1)(delayed(comparing_keypoints_parallel)(df, df1_, df2_, idx1, kp1_col, kp2_col, cols1, cols2, extra_cols) for idx1 in df1_.index)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    # for idx1 in df1_.index:\n",
    "    #     kp1 = df1_.loc[idx1][kp1_col]\n",
    "    #     print(f'passou {idx1}')\n",
    "    #     for idx2 in df2_.index:\n",
    "    #         kp2 = df2_.loc[idx2][kp2_col]\n",
    "    #         matches = computeDistacesKeypoints(kp1, kp2, threshold=2)\n",
    "\n",
    "    #         df.loc[len(df)] = df1_.loc[idx1][cols1].tolist() + df2_.loc[idx2][cols2].tolist() + [len(matches), matches]\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando combinações de parâmetros dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "\n",
    "params_harris = {\n",
    "    'image': [image],\n",
    "    'threshold' : [0.005, 0.05, 0.1, 0.2],\n",
    "    'blockSize' : [2, 4, 6, 8],\n",
    "    'ksize' : [3, 5, 7, 9],\n",
    "    'k' : [0.02, 0.04, 0.08, 0.16]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'image': [image],\n",
    "    # 'nfeatures': [50, 100, 500, 1000],\n",
    "    'nOctaveLayers' : [3, 5, 7, 9],\n",
    "    'contrastThreshold' : [0.02, 0.04, 0.08, 0.1],\n",
    "    'edgeThreshold' : [5, 10, 20, 40],\n",
    "    'sigma' : [0.8, 1.6, 3.2, 6.4]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'image': [image],\n",
    "    'max_size': [11, 21, 41, 81],\n",
    "    'response_threshold': [5, 10, 20, 30],\n",
    "    'line_threshold_projected': [5, 10, 20, 30],\n",
    "    'line_threshold_binarized': [4, 8, 16, 32],\n",
    "    'suppress_nonmax_size': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "# df_harris = extract_and_save_features_csv(params_harris, 'harris', '../data/results/dsc07631/harris_keypoints_1.csv')\n",
    "# df_sift = extract_and_save_features_csv(params_sift, 'sift', '../data/results/dsc07631/sift_keypoints_1.csv')\n",
    "# df_orb = extract_and_save_features_csv(params_star, 'star', '../data/results/dsc07631/star_keypoints_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_harris = pd.read_csv('../data/results/dsc07631/harris_keypoints_1.csv')\n",
    "df_sift = pd.read_csv('../data/results/dsc07631/sift_keypoints_1.csv')\n",
    "df_star = pd.read_csv('../data/results/dsc07631/star_keypoints_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps1 = []\n",
    "for idx in df_harris.index.tolist():\n",
    "    kps1.append(convert_to_kp(df_harris['harris_keypoints'].loc[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps2 = []\n",
    "for idx in df_sift.index.tolist():\n",
    "    kps2.append(convert_to_kp(df_sift['sift_keypoints'].loc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps3 = []\n",
    "for idx in df_star.index.tolist():\n",
    "    kps3.append(convert_to_kp(df_star['star_keypoints'].loc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_harris['harris_keypoints'] = kps1\n",
    "df_sift['sift_keypoints'] = kps2\n",
    "df_star['star_keypoints'] = kps3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs = compare_and_save_match_points(df_harris, df_sift, 'harris_keypoints', 'sift_keypoints', '../data/results/dsc07631/harris_sift_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hst = compare_and_save_match_points(df_harris, df_star, 'harris_keypoints', 'star_keypoints', '../data/results/dsc07631/harris_star_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss = compare_and_save_match_points(df_sift, df_star, 'sift_keypoints', 'star_keypoints', '../data/results/dsc07631/sift_star_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harris_threshold</th>\n",
       "      <th>harris_blockSize</th>\n",
       "      <th>harris_ksize</th>\n",
       "      <th>harris_k</th>\n",
       "      <th>harris_qtd_keypoints</th>\n",
       "      <th>harris_keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10493</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9288</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5947</td>\n",
       "      <td>[(98.0, 2.0), (99.0, 2.0), (100.0, 2.0), (98.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8844</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7534</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   harris_threshold  harris_blockSize  harris_ksize  harris_k  \\\n",
       "0              0.01                 2             3      0.02   \n",
       "1              0.01                 2             3      0.04   \n",
       "2              0.01                 2             3      0.16   \n",
       "3              0.01                 2             5      0.02   \n",
       "4              0.01                 2             5      0.04   \n",
       "\n",
       "   harris_qtd_keypoints                                   harris_keypoints  \n",
       "0                 10493  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "1                  9288  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "2                  5947  [(98.0, 2.0), (99.0, 2.0), (100.0, 2.0), (98.0...  \n",
       "3                  8844  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "4                  7534  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_harris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=2)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro experimento\n",
    "- Rodando com os parâmetros default dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "h_kp, harris_image = detectHarrisKeypoints(image)\n",
    "s_kp, sift_image = detectSIFTKeypoints(image)\n",
    "o_kp, orb_image = detectStarKeypoints(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=1)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=1)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   9288\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD ORB Keypoints:   500\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   645\n",
      "Matches Keypoints Harris/ORB:   666\n",
      "Matches Keypoints SIFT/ORB:   80\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD ORB Keypoints:   {len(o_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/ORB:   {len(matches_ho)}')\n",
    "print(f'Matches Keypoints SIFT/ORB:   {len(matches_so)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_matches_hs = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_hs]\n",
    "kp_matches_ho = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_ho]\n",
    "kp_matches_so = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_so]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, kp_matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, kp_matches_ho, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, kp_matches_so, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('ORB', kp_matches_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=2)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   9288\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD ORB Keypoints:   500\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   2342\n",
      "Matches Keypoints Harris/ORB:   1430\n",
      "Matches Keypoints SIFT/ORB:   125\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD ORB Keypoints:   {len(o_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/ORB:   {len(matches_ho)}')\n",
    "print(f'Matches Keypoints SIFT/ORB:   {len(matches_so)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_matches_hs = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_hs]\n",
    "kp_matches_ho = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_ho]\n",
    "kp_matches_so = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_so]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, kp_matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, kp_matches_ho, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, kp_matches_so, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('Harris/SIFT', kp1_image)\n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Descritores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def calculate_slope(pt1, pt2):\n",
    "    slope = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0]) if (pt2[0] - pt1[0]) != 0 else -1\n",
    "    return slope\n",
    "\n",
    "\n",
    "def verify_slope(match, trainKeypoints, queryKeypoints, slope1, slope2):\n",
    "    slope = calculate_slope(trainKeypoints[match.trainIdx].pt, queryKeypoints[match.queryIdx].pt) \n",
    "    if slope <= slope2 and slope >= slope1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def verify_dist(match, trainKeypoints, queryKeypoints, dist1, dist2):\n",
    "    point1 = np.asarray(trainKeypoints[match.trainIdx].pt)\n",
    "    point2 = np.asarray(queryKeypoints[match.queryIdx].pt)\n",
    "\n",
    "    dist = np.linalg.norm(point1 - point2)\n",
    "\n",
    "    if dist <= dist2 and dist >= dist1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints):\n",
    "    slope_list = [calculate_slope(trainKeypoints[matches[i][0].trainIdx].pt, queryKeypoints[matches[i][0].queryIdx].pt) for i, m in enumerate(matchesMask)]\n",
    "    slope_list_mask = [calculate_slope(trainKeypoints[matches[i][0].trainIdx].pt, queryKeypoints[matches[i][0].queryIdx].pt) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "\n",
    "    return slope_list, slope_list_mask\n",
    "\n",
    "\n",
    "def calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints):\n",
    "    kps_train = [(trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]) for i, m in enumerate(matchesMask)]\n",
    "    kps_query = [(queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]) for i, m in enumerate(matchesMask)]\n",
    "\n",
    "    kps_train_ = [(trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "    kps_query_ = [(queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "    \n",
    "    array_pts_train = np.asarray(kps_train)\n",
    "    array_pts_query = np.asarray(kps_query)\n",
    "\n",
    "    array_pts_train_ = np.asarray(kps_train_)\n",
    "    array_pts_query_ = np.asarray(kps_query_)\n",
    "\n",
    "    dists = [np.linalg.norm(point1 - point2) for point1, point2 in zip(array_pts_train, array_pts_query)]\n",
    "    dists_mask = [np.linalg.norm(point1 - point2) for point1, point2 in zip(array_pts_train_, array_pts_query_)]\n",
    "\n",
    "    return dists, dists_mask\n",
    "\n",
    "\n",
    "def filter_matches_by_percentile(matches, matchesMask, trainKeypoints, queryKeypoints, q1, q2):\n",
    "    slope_list, slope_list_ = calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "    dists, dists_ = calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "\n",
    "    s1_, s2_ = np.percentile(slope_list_, [q1 ,q2])\n",
    "    d1_, d2_ = np.percentile(dists_, [q1 ,q2])\n",
    "    \n",
    "    matchesMask_ = [ [1,0] if m[0] > 0 and verify_slope(matches[i][0], trainKeypoints, queryKeypoints, s1_, s2_) else [0,0] for i, m in enumerate(matchesMask)]\n",
    "    matchesMask_ = [ [1,0] if m[0] > 0 and verify_dist(matches[i][0], trainKeypoints, queryKeypoints, d1_, d2_) else [0,0] for i, m in enumerate(matchesMask_)]\n",
    "\n",
    "    qtd_matches = len(matches)\n",
    "    qtd_matches_dlowe = len([m[0] for m in matchesMask if m[0] > 0 ])\n",
    "    qtd_matches_filter = len([m[0] for m in matchesMask_ if m[0] > 0 ])\n",
    "\n",
    "    qtd_fp_dlowe = qtd_matches - qtd_matches_dlowe\n",
    "    qtd_fp_filter = qtd_matches_dlowe - qtd_matches_filter\n",
    "    \n",
    "    # norm = np.linalg.norm(data)  # Calculate the L2 norm of the data\n",
    "    # normalized_data = data / norm\n",
    "\n",
    "    var_dist = np.var([d for m, d in zip(matchesMask, dists) if m[0] > 0 ])\n",
    "    var_slope = np.var([sl for m, sl in zip(matchesMask, slope_list) if m[0] > 0 ])\n",
    "\n",
    "    # mismatch_train_keypoints = len(trainKeypoints) - qtd_matches\n",
    "    # mismatch_query_keypoints = len(queryKeypoints) - qtd_matches\n",
    "\n",
    "    return matchesMask_, qtd_matches, qtd_matches_dlowe, qtd_matches_filter, qtd_fp_dlowe, qtd_fp_filter, var_dist, var_slope\n",
    "\n",
    "\n",
    "def filter_matches_by_variance(matches, trainKeypoints, queryKeypoints, var_dist, var_slope):\n",
    "    matchesMask_ = [[0,0] for i in range(len(matches))]\n",
    "    var_dist_ = -1\n",
    "    var_slope_ = -1\n",
    "    ratio_test_ = -1\n",
    "    \n",
    "    for ratio_test in np.arange(0.1, 1., 0.01):\n",
    "        matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "        for i,(m,n) in enumerate(matches):\n",
    "            if m.distance < ratio_test*n.distance:\n",
    "                matchesMask[i]=[1,0]\n",
    "\n",
    "        slope_list, slope_list_ = calculate_slope_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "        dists, dists_ = calculate_dist_list(matches, matchesMask, trainKeypoints, queryKeypoints)\n",
    "\n",
    "        var_d = np.var(dists_)\n",
    "        var_s = np.var(slope_list_)\n",
    "\n",
    "        if var_d <= var_dist and var_s <= var_slope:\n",
    "            ratio_test_ = round(copy.copy(ratio_test), 2)\n",
    "            var_dist_ = var_d\n",
    "            var_slope_ = var_s\n",
    "            matchesMask_ = [m for m in matchesMask]\n",
    "        \n",
    "    \n",
    "    qtd_matches = len(matches)\n",
    "    qtd_matches_dlowe = len([m[0] for m in matchesMask_ if m[0] > 0 ])\n",
    "\n",
    "    qtd_fp_dlowe = qtd_matches - qtd_matches_dlowe\n",
    "\n",
    "    return matchesMask_, ratio_test_, qtd_matches, qtd_matches_dlowe, qtd_fp_dlowe, var_dist_, var_slope_\n",
    "\n",
    "\n",
    "\n",
    "def draw_matches(train_img, query_img, trainKeypoints, queryKeypoints, matches, matchesMask):\n",
    "    kps_train = [[trainKeypoints[matches[i][0].trainIdx].pt[0], trainKeypoints[matches[i][0].trainIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "    kps_query = [[queryKeypoints[matches[i][0].queryIdx].pt[0], queryKeypoints[matches[i][0].queryIdx].pt[1]] for i, m in enumerate(matchesMask)]\n",
    "\n",
    "    # draw the tracks\n",
    "    mask = np.zeros_like(train_img, 'uint8') \n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "    frame = query_img.copy()\n",
    "    \n",
    "    for i, (m, query, train) in enumerate(zip(matchesMask, kps_query, kps_train)):\n",
    "        a, b = query[0], query[1]\n",
    "        c, d = train[0], train[1]\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "        \n",
    "        if m[0] > 0:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2) \n",
    "            frame = cv2.circle(frame, (a, b), 4, point_true, -1)\n",
    "        else:\n",
    "            frame = cv2.circle(frame, (a, b), 4, point_false, -1)\n",
    "    \n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchDetectedKeypoints(train_img, query_img, var_dist, var_slope, detector='harris', descriptor='orb', dect_kargs={}, des_kargs={}):\n",
    "    query_img_bw = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if descriptor == 'brief':\n",
    "        des = cv2.xfeatures2d.BriefDescriptorExtractor_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    elif descriptor == 'brisk':\n",
    "        des = cv2.BRISK_create(**des_kargs)\n",
    "        norm_type = cv2.NORM_HAMMING\n",
    "    else:\n",
    "        des = cv2.SIFT.create(**des_kargs)\n",
    "        norm_type = cv2.NORM_L2\n",
    "    \n",
    "    if detector == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif detector == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "\n",
    "    queryKeypoints, _ = func_var(query_img, **dect_kargs)\n",
    "    trainKeypoints, _ = func_var(train_img, **dect_kargs)\n",
    "    \n",
    "    _,queryDescriptors = des.compute(query_img_bw, queryKeypoints) \n",
    "    _,trainDescriptors = des.compute(train_img_bw, trainKeypoints)\n",
    "\n",
    "\n",
    "    matcher = cv2.BFMatcher(normType=norm_type, crossCheck=False) \n",
    "    matches = matcher.knnMatch(queryDescriptors,trainDescriptors, k=2) \n",
    "\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    # matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "    # for i,(m,n) in enumerate(matches):\n",
    "    #     if m.distance < ratio_test*n.distance:\n",
    "    #         matchesMask[i]=[1,0]\n",
    "\n",
    "    # m = filter_matches_by_percentile(matches, matchesMask, trainKeypoints, queryKeypoints, filter_slope[0], filter_slope[1])\n",
    "    \n",
    "    m = filter_matches_by_variance(matches, trainKeypoints, queryKeypoints, var_dist, var_slope)\n",
    "    matchesMask_, ratio_test_, qtd_matches, qtd_matches_dlowe, qtd_fp_dlowe, var_dist_, var_slope_ = m \n",
    "\n",
    "    print('---- Resultado ---- ')\n",
    "    print(f'Quantidade de keypoints train image: {len(trainKeypoints)}')\n",
    "    print(f'Quantidade de keypoints query image: {len(queryKeypoints)}')\n",
    "    print(f'Quantidade de matches: {qtd_matches}')\n",
    "    print(f'Valor ratio test D.Lowe: {ratio_test_}')\n",
    "    print(f'Quantidade de matches filtro D.Lowe: {qtd_matches_dlowe}')\n",
    "    print(f'Quantidade de falso D.Lowe: {qtd_fp_dlowe}')\n",
    "    print(f'Variância da distância: {var_dist_}')\n",
    "    print(f'Variância da inclinação da linha: {var_slope_}')\n",
    "\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                    singlePointColor = (255,0,0),\n",
    "                    matchesMask = matchesMask_,\n",
    "                    flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "    \n",
    "    # final_img = cv2.drawMatchesKnn(query_img,queryKeypoints,train_img,trainKeypoints,matches,None,**draw_params)\n",
    "\n",
    "    final_img = draw_matches(train_img, query_img, trainKeypoints, queryKeypoints, matches, matchesMask_)\n",
    "\n",
    "    \n",
    "    final_img = cv2.resize(final_img, (480,640))\n",
    "\n",
    "    return final_img \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sift = {\n",
    "    'nfeatures': 100,\n",
    "    'nOctaveLayers' : 1,\n",
    "    'contrastThreshold' : 0.04,\n",
    "    'edgeThreshold' : 20,\n",
    "    'sigma' : 1.6\n",
    "}\n",
    "\n",
    "params_harris = {\n",
    "    # 'image': [image],\n",
    "    'threshold' : 0.2,# [0.005, 0.01, 0.05, 0.1, 0.2],\n",
    "    'blockSize' : 6,#[2, 4, 6, 8],\n",
    "    'ksize' : 7,#[3, 5, 7, 9],\n",
    "    'k' : 0.16,#[0.02, 0.04, 0.08, 0.16]\n",
    "}\n",
    "\n",
    "params_brisk = {    \n",
    "    # 'thresh': 100,\t#AGAST detection threshold score.\n",
    "    # 'octaves':200,\t#detection octaves. Use 0 to do single scale.\n",
    "    'radiusList': [8, 9, 10],\t#defines the radii (in pixels) where the samples around a keypoint are taken (for keypoint scale 1).\n",
    "    'numberList': [12, 16, 20],\t#defines the number of sampling points on the sampling circle. Must be the same size as radiusList..\n",
    "    'dMax': 2,\t#threshold for the short pairings used for descriptor formation (in pixels for keypoint scale 1).\n",
    "    'dMin': 1,\t#threshold for the long pairings used for orientation determination (in pixels for keypoint scale 1).\n",
    "    # 'indexChange': 1,\t#index remapping of the bits.\n",
    "}\n",
    "\n",
    "var_img_pacoca = (1, 0.001) # IMG_20231217_075107.jpg\n",
    "var_img1 = (4, 0.02) # dsc07632.jpg\n",
    "var_img2 = (3, 0.05) # dsc02596.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg') \n",
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg')\n",
    "# query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "# train_img = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc02596.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc02595.jpg') \n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "train_img_ = cv2.resize(train_img, (480,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_img = matchDetectedKeypoints(train_img_, query_img_, 0.75, filter_slope=(0,100), detector='harris', descriptor='sift', dect_kargs=params_harris, des_kargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de keypoints train image: 2404\n",
      "Quantidade de keypoints query image: 2375\n",
      "Quantidade de matches: 2375\n",
      "Valor ratio test D.Lowe: 0.36\n",
      "Quantidade de matches filtro D.Lowe: 1164\n",
      "Quantidade de falso D.Lowe: 1211\n",
      "Variância da distância: 2.014497795273739\n",
      "Variância da inclinação da linha: 0.009831970594583893\n"
     ]
    }
   ],
   "source": [
    "final_img = matchDetectedKeypoints(train_img_, query_img_, 3, 0.05, detector='sift', descriptor='sift', dect_kargs={}, des_kargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_img) \n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Fluxo Óptico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_points(old_points, new_points):\n",
    "    array_pts_train = np.asarray(old_points)\n",
    "    array_pts_query = np.asarray(new_points)\n",
    "    \n",
    "    dists = [ np.linalg.norm(p1 - p2) for p1, p2 in zip(array_pts_train, array_pts_query)]\n",
    "\n",
    "    return dists\n",
    "\n",
    "\n",
    "def calculate_slope(pt1, pt2):\n",
    "    slope = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0]) if (pt2[0] - pt1[0]) != 0 else -1\n",
    "    return slope\n",
    "\n",
    "\n",
    "def calculate_slope_points(old_points, new_points):\n",
    "    array_pts_train = np.asarray(old_points)\n",
    "    array_pts_query = np.asarray(new_points)\n",
    "    \n",
    "    slopes = [ calculate_slope(p1, p2) for p1, p2 in zip(array_pts_train, array_pts_query)]\n",
    "\n",
    "    return slopes\n",
    "\n",
    "\n",
    "def filter_outliers(data, old_points, new_points):\n",
    "\n",
    "    Q1 = np.percentile(data, 25) \n",
    "    Q2 = np.percentile(data, 50) \n",
    "    Q3 = np.percentile(data, 75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    low_lim = Q1 - 1.5 * IQR\n",
    "    up_lim = Q3 + 1.5 * IQR\n",
    "\n",
    "    filtered_old = [ old_points[i] for i, d in enumerate(data) if d <= up_lim and d >= low_lim]\n",
    "    filtered_new = [ new_points[i] for i, d in enumerate(data) if d <= up_lim and d >= low_lim]\n",
    "\n",
    "    return filtered_old, filtered_new\n",
    "\n",
    "\n",
    "def filter_by_variance(old_points, new_points, var_dist, var_slope):\n",
    "    dists = calculate_distance_points(old_points, new_points)\n",
    "    slopes = calculate_slope_points(old_points, new_points)\n",
    "\n",
    "    filtered_old = [p for p in old_points]\n",
    "    filtered_new = [p for p in new_points]\n",
    "\n",
    "    var_dist_ = np.var(dists)\n",
    "    var_slope_ = np.var(slopes)\n",
    "    loop_limit = 100\n",
    "    \n",
    "    while(var_dist_ > var_dist or var_slope_ > var_slope):\n",
    "        dists = calculate_distance_points(filtered_old, filtered_new)\n",
    "        var_dist_ = np.var(dists)\n",
    "\n",
    "        if var_dist_ > var_dist:\n",
    "            filtered_old, filtered_new = filter_outliers(dists, filtered_old, filtered_new)\n",
    "        \n",
    "        slopes = calculate_slope_points(filtered_old, filtered_new)\n",
    "        var_slope_ = np.var(slopes)\n",
    "\n",
    "        if var_slope_ > var_slope:\n",
    "            filtered_old, filtered_new = filter_outliers(slopes, filtered_old, filtered_new)\n",
    "        \n",
    "        if loop_limit > 0:\n",
    "            loop_limit -= 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return np.asarray(filtered_old), np.asarray(filtered_new)\n",
    "\n",
    "\n",
    "def lucas_kanade_opflow(train_img, query_img, feature_params, lk_params, var_dist, var_slope):\n",
    "    \n",
    "    # Take first frame and find corners in it \n",
    "    old_frame = train_img \n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params) \n",
    "\n",
    "    # Create a mask image for drawing purposes \n",
    "\n",
    "    mask = np.zeros_like(old_frame, 'uint8') \n",
    "    \n",
    "    frame = query_img \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    # calculate optical flow \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params) \n",
    "\n",
    "    # Select good points \n",
    "    good_new = p1[st == 1] \n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    good_old_, good_new_ = filter_by_variance(good_old, good_new, var_dist, var_slope)\n",
    "    dists = calculate_distance_points(good_old_, good_new_)\n",
    "    slopes = calculate_slope_points(good_old_, good_new_)\n",
    "    \n",
    "    var_dist_ = np.var(dists)\n",
    "    var_slope_ = np.var(slopes)\n",
    "    \n",
    "    qtd_matches = len(good_new)\n",
    "    qtd_matches_filtered = len(good_new_)\n",
    "    qtd_fp = qtd_matches - qtd_matches_filtered\n",
    "\n",
    "    line = (0,255,0)\n",
    "    point_true = (255,0,0)\n",
    "    point_false = (0,0,255)\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new,  \n",
    "                                        good_old)):\n",
    "        a, b = new.ravel() \n",
    "        c, d = old.ravel()\n",
    "        \n",
    "        a, b = int(a), int(b)\n",
    "        c, d = int(c), int(d)\n",
    "\n",
    "        if new in good_new_:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "            frame = cv2.circle(frame, (a, b), 5, point_true, -1) \n",
    "        else:\n",
    "            mask = cv2.line(mask, (a, b), (c, d), line, 2)     \n",
    "            frame = cv2.circle(frame, (a, b), 5, point_false, -1)\n",
    "            \n",
    "    img = cv2.add(frame, mask) \n",
    "\n",
    "    return img, var_dist_, var_slope_, qtd_matches, qtd_matches_filtered, qtd_fp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 97\n",
      "Quantidade de matches filtro outliers: 79\n",
      "Quantidade de falso positivo: 18\n",
      "Variância da distância: 2.194173812866211\n",
      "Variância da inclinação da linha: 0.008462824858725071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 986,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "# params for corner detection \n",
    "feature_params = dict( maxCorners = 100, \n",
    "                       qualityLevel = 0.02, \n",
    "                       minDistance = 7, \n",
    "                       blockSize = 7,\n",
    "                       useHarrisDetector = False) \n",
    "  \n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = dict( winSize = (16, 16), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "  \n",
    "\n",
    "lk_result = lucas_kanade_opflow(train_img_, query_img_, feature_params, lk_params, 0, 0)\n",
    "\n",
    "img, var_dist, var_slope, qtd_matches, qtd_matches_filtered, qtd_fp = lk_result\n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de matches filtro outliers: {qtd_matches_filtered}')\n",
    "print(f'Quantidade de falso positivo: {qtd_fp}')\n",
    "print(f'Variância da distância: {var_dist}')\n",
    "print(f'Variância da inclinação da linha: {var_slope}')\n",
    "\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey()\n",
    "\n",
    "# # Updating Previous frame and points  \n",
    "# old_gray = frame_gray.copy() \n",
    "# p0 = good_new.reshape(-1, 1, 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horn-Schunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow(img, flow, new_points_, step=24):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    # cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        if np.asarray([x2, y2]) in new_points_:\n",
    "            cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
    "            cv2.line(vis, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "        else:\n",
    "            cv2.circle(vis, (x1, y1), 1, (0, 0, 255), -1)\n",
    "            cv2.line(vis, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "    return vis\n",
    "\n",
    "\n",
    "def return_points_hs(img, flow, step=24):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    old_points = np.asarray([[x1, y1] for (x1, y1), (x2, y2) in lines if calculate_distance_points([[x1, y1]], [[x2, y2]])[0] > 0.5])\n",
    "    new_points = np.asarray([[x2, y2] for (x1, y1), (x2, y2) in lines if calculate_distance_points([[x1, y1]], [[x2, y2]])[0] > 0.5])\n",
    "\n",
    "    return old_points, new_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 475\n",
      "Quantidade de matches filtro outliers: 309\n",
      "Quantidade de falso positivo: 166\n",
      "Variância da distância: 3.2450807925440697\n",
      "Variância da inclinação da linha: 0.018452262684142417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1039,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231217_075101.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231217_075107.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "# Convert to gray scale\n",
    "prvs = cv2.cvtColor(train_img_, cv2.COLOR_BGR2GRAY)\n",
    "# Create mask\n",
    "hsv_mask = np.zeros_like(train_img_)\n",
    "# Make image saturation to a maximum value\n",
    "hsv_mask[..., 1] = 255\n",
    " \n",
    "# Capture another frame and convert to gray scale\n",
    "next = cv2.cvtColor(query_img_, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Optical flow is now calculated\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "# Calculated fp points\n",
    "old_points, new_points = return_points_hs(next, flow, step=24)\n",
    "old_points_, new_points_ = filter_by_variance(old_points, new_points, 0.0, 0.0)\n",
    "dists = calculate_distance_points(old_points_, new_points_)\n",
    "slopes = calculate_slope_points(old_points_, new_points_)\n",
    "\n",
    "var_dist_ = np.var(dists)\n",
    "var_slope_ = np.var(slopes)\n",
    "\n",
    "qtd_matches = len(new_points)\n",
    "qtd_matches_filtered = len(new_points_)\n",
    "qtd_fp = qtd_matches - qtd_matches_filtered\n",
    "\n",
    "mapped_img = draw_flow(next, flow, new_points_, step=24)\n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de matches filtro outliers: {qtd_matches_filtered}')\n",
    "print(f'Quantidade de falso positivo: {qtd_fp}')\n",
    "print(f'Variância da distância: {var_dist_}')\n",
    "print(f'Variância da inclinação da linha: {var_slope_}')\n",
    "\n",
    "cv2.imshow('frame2', mapped_img)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
