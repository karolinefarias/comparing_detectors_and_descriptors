{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### tarefas para fazer\n",
    "## Algoritmos de detecção\n",
    "# -- harris - OK\n",
    "# -- sift - OK\n",
    "# -- star/brisk (pendente)\n",
    "# -- entender parâmetros harris, sift, star e brisk\n",
    "# -- criar experimento para 25, 50, 100, 500, 1000 features\n",
    "########################\n",
    "## Algoritmos de descrição\n",
    "# -- restringir área de checagem de pontos\n",
    "# -- criar algoritmo para contar falsos positivos\n",
    "## Imagem de teste\n",
    "# -- preciso escolher qual o terceiro par de imagens para testar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento com detectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Códigos detectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.04):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "\n",
    "    # Applying the function \n",
    "    dst = cv2.cornerHarris(gray_image_f32, blockSize, ksize, k) \n",
    "  \n",
    "    # dilate to mark the corners \n",
    "    dst = cv2.dilate(dst, None)\n",
    "    \n",
    "    ret, dst = cv2.threshold(dst,threshold*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # draw keypoints\n",
    "    # image[dst > threshold * dst.max()] = [0, 255, 0]\n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(255, 0, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSIFTKeypoints(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None) \n",
    "    \n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectStarKeypoints(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kp = star.detect(gray_image, None)    \n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "# kp, kp_image = detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.02)\n",
    "# print(len(kp))\n",
    "# cv2.imshow('Star', kp_image) \n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detectORBKeypoints(image, nfeatures=500, scaleFactor = 1.2, nlevels=8, edgeThreshold=31, WTA_K=2, patchSize=31):\n",
    "#     # Reading the image and converting the image to B/W \n",
    "#     gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "#     # Applying the function \n",
    "#     orb = cv2.ORB_create(\n",
    "#         nfeatures=nfeatures,\n",
    "#         scaleFactor=scaleFactor,\n",
    "#         nlevels=nlevels, \n",
    "#         edgeThreshold=edgeThreshold, \n",
    "#         WTA_K=WTA_K, \n",
    "#         patchSize=patchSize, \n",
    "#     ) \n",
    "#     kp, des = orb.detectAndCompute(gray_image, None)    \n",
    "\n",
    "#     # Applying the function \n",
    "#     kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "#     return kp, kp_image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código comparando pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def computeDistacesKeypoints(pts1, pts2, threshold=1):\n",
    "    array_pts1 = np.asarray(pts1)\n",
    "    array_pts2 = np.asarray(pts2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)  \n",
    "        matches = [pts2[pt] for pt, dist in zip(dists[0], dists[1]) if dist <= threshold]\n",
    "    else:\n",
    "        matches = []\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_features_csv(params, algol, path):\n",
    "    if algol == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif algol == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "    \n",
    "    cols_name = [algol + '_' + param for param in list(params.keys())[1:]]\n",
    "    cols_result = [algol + '_' + 'qtd_keypoints', algol + '_' + 'keypoints']\n",
    "    df = pd.DataFrame(columns=cols_name+cols_result)\n",
    "    \n",
    "    keys = list(params)\n",
    "    for values in itertools.product(*map(params.get, keys)):\n",
    "        kps, kp_image = func_var(**dict(zip(keys, values)))\n",
    "        kps_ = [(kp.pt[0], kp.pt[1]) for kp in kps] #kp.angle, kp.response, kp.octave, kp.class_id) for kp in kps]\n",
    "\n",
    "        df.loc[len(df)] = list(values[1:]) + [len(kps_), kps_]\n",
    "\n",
    "    df.to_csv(path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_to_kp(string_points):\n",
    "    string_converted = list(eval(string_points))\n",
    "    # kps = [cv2.KeyPoint(x[0], x[1], 13) for x in string_converted]\n",
    "    # for p in string_converted:\n",
    "    #     kp = cv2.KeyPoint(x=float(p[0]), y=float(p[1]), size=float(p[2]), angle=float(p[3]),\n",
    "    #                 response=float(p[4]), octave=int(p[5]), class_id=int(p[6]))\n",
    "    #     kps.append(kp)\n",
    "    \n",
    "    return string_converted\n",
    "\n",
    "def comparing_keypoints_parallel(df, df1, df2, idx1, kp1_col, kp2_col, cols1, cols2, extra_cols):\n",
    "    kp1 = df1.loc[idx1][kp1_col]\n",
    "    df = pd.DataFrame(columns=cols1+cols2+extra_cols)\n",
    "    for idx2 in df2.index:\n",
    "        kp2 = df2.loc[idx2][kp2_col]\n",
    "        matches = computeDistacesKeypoints(kp1, kp2, threshold=2)\n",
    "\n",
    "        df.loc[len(df)] = df1.loc[idx1][cols1].tolist() + df2.loc[idx2][cols2].tolist() + [len(matches), matches]\n",
    "    return df\n",
    "\n",
    "def compare_and_save_match_points(df1, df2, kp1_col, kp2_col, path):\n",
    "    cols1 = list(df1.columns[:-1])\n",
    "    cols2 = list(df2.columns[:-1])\n",
    "    extra_cols = ['qtd_matches', 'match_keypoints']\n",
    "\n",
    "    df1_ = df1.copy()\n",
    "    df2_ = df2.copy()\n",
    "\n",
    "    df = pd.DataFrame(columns=cols1+cols2+extra_cols)\n",
    "    dfs = []\n",
    "    dfs = Parallel(n_jobs=-1)(delayed(comparing_keypoints_parallel)(df, df1_, df2_, idx1, kp1_col, kp2_col, cols1, cols2, extra_cols) for idx1 in df1_.index)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    # for idx1 in df1_.index:\n",
    "    #     kp1 = df1_.loc[idx1][kp1_col]\n",
    "    #     print(f'passou {idx1}')\n",
    "    #     for idx2 in df2_.index:\n",
    "    #         kp2 = df2_.loc[idx2][kp2_col]\n",
    "    #         matches = computeDistacesKeypoints(kp1, kp2, threshold=2)\n",
    "\n",
    "    #         df.loc[len(df)] = df1_.loc[idx1][cols1].tolist() + df2_.loc[idx2][cols2].tolist() + [len(matches), matches]\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando combinações de parâmetros dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "\n",
    "params_harris = {\n",
    "    'image': [image],\n",
    "    'threshold' : [0.005, 0.01, 0.05, 0.08],\n",
    "    'blockSize' : [2, 4, 6, 8],\n",
    "    'ksize' : [3, 5, 7, 9],\n",
    "    'k' : [0.02, 0.04, 0.08, 0.16]\n",
    "}\n",
    "\n",
    "params_sift = {\n",
    "    'image': [image],\n",
    "    # 'nfeatures': [50, 100, 500, 1000],\n",
    "    'nOctaveLayers' : [3, 5, 7, 9],\n",
    "    'contrastThreshold' : [0.02, 0.04, 0.08, 0.1],\n",
    "    'edgeThreshold' : [5, 10, 20, 40],\n",
    "    'sigma' : [0.8, 1.6, 3.2, 6.4]\n",
    "}\n",
    "\n",
    "params_star = {\n",
    "    'image': [image],\n",
    "    'max_size': [11, 21, 41, 81],\n",
    "    'response_threshold': [5, 10, 20, 30],\n",
    "    'line_threshold_projected': [5, 10, 20, 30],\n",
    "    'line_threshold_binarized': [4, 8, 16, 32],\n",
    "    'suppress_nonmax_size': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "# df_harris = extract_and_save_features_csv(params_harris, 'harris', '../data/results/dsc07631/harris_keypoints_1.csv')\n",
    "# df_sift = extract_and_save_features_csv(params_sift, 'sift', '../data/results/dsc07631/sift_keypoints_1.csv')\n",
    "# df_orb = extract_and_save_features_csv(params_star, 'star', '../data/results/dsc07631/star_keypoints_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_harris = pd.read_csv('../data/results/dsc07631/harris_keypoints_1.csv')\n",
    "df_sift = pd.read_csv('../data/results/dsc07631/sift_keypoints_1.csv')\n",
    "df_star = pd.read_csv('../data/results/dsc07631/star_keypoints_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps1 = []\n",
    "for idx in df_harris.index.tolist():\n",
    "    kps1.append(convert_to_kp(df_harris['harris_keypoints'].loc[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps2 = []\n",
    "for idx in df_sift.index.tolist():\n",
    "    kps2.append(convert_to_kp(df_sift['sift_keypoints'].loc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps3 = []\n",
    "for idx in df_star.index.tolist():\n",
    "    kps3.append(convert_to_kp(df_star['star_keypoints'].loc[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_harris['harris_keypoints'] = kps1\n",
    "df_sift['sift_keypoints'] = kps2\n",
    "df_star['star_keypoints'] = kps3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs = compare_and_save_match_points(df_harris, df_sift, 'harris_keypoints', 'sift_keypoints', '../data/results/dsc07631/harris_sift_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hst = compare_and_save_match_points(df_harris, df_star, 'harris_keypoints', 'star_keypoints', '../data/results/dsc07631/harris_star_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss = compare_and_save_match_points(df_sift, df_star, 'sift_keypoints', 'star_keypoints', '../data/results/dsc07631/sift_star_matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>harris_threshold</th>\n",
       "      <th>harris_blockSize</th>\n",
       "      <th>harris_ksize</th>\n",
       "      <th>harris_k</th>\n",
       "      <th>harris_qtd_keypoints</th>\n",
       "      <th>harris_keypoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10493</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.04</td>\n",
       "      <td>9288</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>5947</td>\n",
       "      <td>[(98.0, 2.0), (99.0, 2.0), (100.0, 2.0), (98.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8844</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7534</td>\n",
       "      <td>[(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   harris_threshold  harris_blockSize  harris_ksize  harris_k  \\\n",
       "0              0.01                 2             3      0.02   \n",
       "1              0.01                 2             3      0.04   \n",
       "2              0.01                 2             3      0.16   \n",
       "3              0.01                 2             5      0.02   \n",
       "4              0.01                 2             5      0.04   \n",
       "\n",
       "   harris_qtd_keypoints                                   harris_keypoints  \n",
       "0                 10493  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "1                  9288  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "2                  5947  [(98.0, 2.0), (99.0, 2.0), (100.0, 2.0), (98.0...  \n",
       "3                  8844  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  \n",
       "4                  7534  [(71.0, 0.0), (72.0, 0.0), (73.0, 0.0), (74.0,...  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_harris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=2)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro experimento\n",
    "- Rodando com os parâmetros default dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "h_kp, harris_image = detectHarrisKeypoints(image)\n",
    "s_kp, sift_image = detectSIFTKeypoints(image)\n",
    "o_kp, orb_image = detectStarKeypoints(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=1)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=1)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   9288\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD ORB Keypoints:   500\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   645\n",
      "Matches Keypoints Harris/ORB:   666\n",
      "Matches Keypoints SIFT/ORB:   80\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD ORB Keypoints:   {len(o_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/ORB:   {len(matches_ho)}')\n",
    "print(f'Matches Keypoints SIFT/ORB:   {len(matches_so)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_matches_hs = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_hs]\n",
    "kp_matches_ho = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_ho]\n",
    "kp_matches_so = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_so]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, kp_matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, kp_matches_ho, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, kp_matches_so, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('ORB', kp_matches_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_ho = computeDistacesKeypoints(h_kp, o_kp, threshold=2)\n",
    "matches_so = computeDistacesKeypoints(s_kp, o_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   9288\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD ORB Keypoints:   500\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   2342\n",
      "Matches Keypoints Harris/ORB:   1430\n",
      "Matches Keypoints SIFT/ORB:   125\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD ORB Keypoints:   {len(o_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/ORB:   {len(matches_ho)}')\n",
    "print(f'Matches Keypoints SIFT/ORB:   {len(matches_so)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_matches_hs = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_hs]\n",
    "kp_matches_ho = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_ho]\n",
    "kp_matches_so = [cv2.KeyPoint(x[0], x[1], 13) for x in matches_so]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, kp_matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, kp_matches_ho, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, kp_matches_so, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('Harris/SIFT', kp1_image)\n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Descritores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slope(pt1, pt2):\n",
    "    slope = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0])\n",
    "    return abs(slope)\n",
    "\n",
    "\n",
    "def verify_slope(match, trainKeypoints, queryKeypoints, q1, q2):\n",
    "    slope = calculate_slope(trainKeypoints[match.trainIdx].pt, queryKeypoints[match.queryIdx].pt) \n",
    "    if slope <= q2 and slope > q1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def filter_matches_by_slope(matches, matchesMask, trainKeypoints, queryKeypoints, q1, q2):\n",
    "    slope_list = [calculate_slope(trainKeypoints[matches[i][0].trainIdx].pt, queryKeypoints[matches[i][0].queryIdx].pt) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "    q1_, q2_ = np.percentile(slope_list, [q1 ,q2])\n",
    "    matchesMask_ = [ [1,0] if m[0] > 0 and verify_slope(matches[i][0], trainKeypoints, queryKeypoints, q1_, q2_) else [0,0] for i, m in enumerate(matchesMask)]\n",
    "    \n",
    "    qtd_fp = len([m[0] for m, m_ in zip(matchesMask, matchesMask_) if m[0] != m_[0]])\n",
    "    qtd_matches = len([m[0] for m in matchesMask_ if m[0] > 0 ])\n",
    "    \n",
    "    mismatch_train_keypoints = len(trainKeypoints) - qtd_matches\n",
    "    mismatch_query_keypoints = len(queryKeypoints) - qtd_matches\n",
    "\n",
    "    return matchesMask_, qtd_fp, qtd_matches, mismatch_train_keypoints, mismatch_query_keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchDetectedKeypoints(train_img, query_img, ratio_test=0.7, filter_slope=(2,98), detector='harris', descriptor='orb', dect_kargs={}, des_kargs={}):\n",
    "    query_img_bw = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if descriptor == 'brief':\n",
    "        des = cv2.xfeatures2d.BriefDescriptorExtractor_create(**des_kargs)\n",
    "    elif descriptor == 'brisk':\n",
    "        des = cv2.BRISK_create(**des_kargs)\n",
    "    else:\n",
    "        des = cv2.SIFT.create(**des_kargs)\n",
    "    \n",
    "    if detector == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif detector == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "\n",
    "    queryKeypoints, _ = func_var(query_img, **dect_kargs)\n",
    "    trainKeypoints, _ = func_var(train_img, **dect_kargs)\n",
    "    \n",
    "    _,queryDescriptors = des.compute(query_img_bw, queryKeypoints) \n",
    "    _,trainDescriptors = des.compute(train_img_bw, trainKeypoints)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=100)   # or pass empty dictionary\n",
    "\n",
    "    # flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    # matches = flann.knnMatch(queryDescriptors, trainDescriptors, k=2)\n",
    "\n",
    "    matcher = cv2.BFMatcher() \n",
    "    matches = matcher.knnMatch(queryDescriptors,trainDescriptors, k=2) \n",
    "\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < ratio_test*n.distance:\n",
    "            matchesMask[i]=[1,0]\n",
    "\n",
    "    m = filter_matches_by_slope(matches, matchesMask, trainKeypoints, queryKeypoints, filter_slope[0], filter_slope[1])\n",
    "    matchesMask_, qtd_fp, qtd_matches, mismatch_train_keypoints, mismatch_query_keypoints = m \n",
    "\n",
    "    print('---- Resultado ---- ')\n",
    "    print(f'Quantidade de matches: {qtd_matches}')\n",
    "    print(f'Quantidade de falso positivos: {qtd_fp}')\n",
    "    print(f'Quantidade de pontos sem match (train_image): {mismatch_train_keypoints}')\n",
    "    print(f'Quantidade de pontos sem match (query_image): {mismatch_query_keypoints}')\n",
    "\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                    singlePointColor = (255,0,0),\n",
    "                    matchesMask = matchesMask_,\n",
    "                    flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "    final_img = cv2.drawMatchesKnn(query_img,queryKeypoints,train_img,trainKeypoints,matches,None,**draw_params)\n",
    "\n",
    "    \n",
    "    final_img = cv2.resize(final_img, (1280,960))\n",
    "\n",
    "    return final_img \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg') \n",
    "train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg') \n",
    "query_img_ = cv2.resize(query_img, (640,480))\n",
    "train_img_ = cv2.resize(train_img, (640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 189\n",
      "Quantidade de falso positivos: 65\n",
      "Quantidade de pontos sem match (train_image): 162\n",
      "Quantidade de pontos sem match (query_image): 112\n"
     ]
    }
   ],
   "source": [
    "final_img = matchDetectedKeypoints(train_img_, query_img_, 1, filter_slope=(0,75), detector='sift', descriptor='brisk', dect_kargs={}, des_kargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_img) \n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Fluxo Óptico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg') \n",
    "query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg')\n",
    "# query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "# train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[431.3327  564.85614]\n",
      "[451. 552.]\n",
      "1\n",
      "[430.23105 352.35507]\n",
      "[449. 338.]\n",
      "2\n",
      "[270.37616 399.77667]\n",
      "[288. 388.]\n",
      "3\n",
      "[200.3223  419.82062]\n",
      "[218. 409.]\n",
      "4\n",
      "[326.21582 384.61417]\n",
      "[344. 372.]\n",
      "5\n",
      "[288.3712 393.879 ]\n",
      "[306. 382.]\n",
      "6\n",
      "[406.51358 360.05463]\n",
      "[425. 346.]\n",
      "7\n",
      "[282.97272 254.16939]\n",
      "[300. 242.]\n",
      "8\n",
      "[416.07144 198.3425 ]\n",
      "[434. 183.]\n",
      "9\n",
      "[317.96292 240.05962]\n",
      "[335. 227.]\n",
      "10\n",
      "[213.14963 283.64902]\n",
      "[230. 273.]\n",
      "11\n",
      "[214.29677 415.88315]\n",
      "[232. 405.]\n",
      "12\n",
      "[346.09125 377.79666]\n",
      "[364. 365.]\n",
      "13\n",
      "[216.69705 541.1982 ]\n",
      "[235. 530.]\n",
      "14\n",
      "[274.76843 534.8154 ]\n",
      "[293. 523.]\n",
      "15\n",
      "[336.736   231.32799]\n",
      "[354. 218.]\n",
      "16\n",
      "[198.95457 290.6671 ]\n",
      "[216. 280.]\n",
      "17\n",
      "[ 32.220825 537.1152  ]\n",
      "[ 52. 527.]\n",
      "18\n",
      "[267.10538 261.96283]\n",
      "[284. 250.]\n",
      "19\n",
      "[164.75938 168.86162]\n",
      "[181. 159.]\n",
      "20\n",
      "[329.46777 113.86752]\n",
      "[346. 100.]\n",
      "21\n",
      "[200.69786 544.146  ]\n",
      "[219. 533.]\n",
      "22\n",
      "[292.66507 532.9082 ]\n",
      "[311. 521.]\n",
      "23\n",
      "[127.90655  106.011856]\n",
      "[144.  97.]\n",
      "24\n",
      "[278.70374 140.35786]\n",
      "[295. 128.]\n",
      "25\n",
      "[263.77777 150.19882]\n",
      "[280. 138.]\n",
      "26\n",
      "[302.99326  60.51038]\n",
      "[303.  55.]\n",
      "27\n",
      "[312.71228 124.55594]\n",
      "[329. 111.]\n",
      "28\n",
      "[332.52744 526.34515]\n",
      "[351. 514.]\n",
      "29\n",
      "[353.38043 522.45416]\n",
      "[372. 510.]\n",
      "30\n",
      "[199.58096 184.67647]\n",
      "[216. 174.]\n",
      "31\n",
      "[112.903854 259.09027 ]\n",
      "[130. 250.]\n",
      "32\n",
      "[ 84.933525 554.4177  ]\n",
      "[104. 544.]\n",
      "33\n",
      "[373.4705   39.81045]\n",
      "[390.  24.]\n",
      "34\n",
      "[395.48264 208.96678]\n",
      "[413. 194.]\n",
      "35\n",
      "[217.08372  110.024414]\n",
      "[233.  99.]\n",
      "36\n",
      "[211.52635 175.76959]\n",
      "[228. 165.]\n",
      "37\n",
      "[384.1605   86.82445]\n",
      "[401.  71.]\n",
      "38\n",
      "[130.12976 622.948  ]\n",
      "[149. 619.]\n",
      "39\n",
      "[293.005    82.13387]\n",
      "[309.  69.]\n",
      "40\n",
      "[ 74.6221 586.7767]\n",
      "[ 94. 576.]\n",
      "41\n",
      "[336.40424 569.2936 ]\n",
      "[355. 557.]\n",
      "42\n",
      "[222.10048  123.132805]\n",
      "[238. 112.]\n",
      "43\n",
      "[ 36.20565 552.19763]\n",
      "[ 56. 542.]\n",
      "44\n",
      "[153.10944 627.31506]\n",
      "[172. 616.]\n",
      "45\n",
      "[ 80.89537 545.4002 ]\n",
      "[100. 535.]\n",
      "46\n",
      "[86.95092  46.746265]\n",
      "[103.  39.]\n",
      "47\n",
      "[136.84436 115.1687 ]\n",
      "[153. 106.]\n",
      "48\n",
      "[213.08315 116.00441]\n",
      "[229. 105.]\n",
      "49\n",
      "[159.48299 559.8415 ]\n",
      "[178. 549.]\n",
      "50\n",
      "[403.76514  75.33708]\n",
      "[421.  59.]\n",
      "51\n",
      "[92.97561  58.916733]\n",
      "[109.  51.]\n",
      "52\n",
      "[142.82286  126.272835]\n",
      "[159. 117.]\n",
      "53\n",
      "[ 51.525295 540.215   ]\n",
      "[ 71. 530.]\n",
      "54\n",
      "[134.39285 550.6562 ]\n",
      "[153. 540.]\n",
      "55\n",
      "[441.02914 601.6371 ]\n",
      "[461. 589.]\n",
      "56\n",
      "[107.04648 378.39545]\n",
      "[125. 369.]\n",
      "57\n",
      "[188.21762 624.28143]\n",
      "[204. 613.]\n",
      "58\n",
      "[115.09104 587.85895]\n",
      "[134. 577.]\n",
      "59\n",
      "[ 74.40679 628.2293 ]\n",
      "[ 94. 617.]\n",
      "60\n",
      "[409.48285   18.516983]\n",
      "[408.  12.]\n",
      "61\n",
      "[212.49129 192.77597]\n",
      "[229. 182.]\n",
      "62\n",
      "[ 97.045425 546.4402  ]\n",
      "[116. 536.]\n",
      "63\n",
      "[142.97762  91.20838]\n",
      "[159.  82.]\n",
      "64\n",
      "[297.5295    65.767876]\n",
      "[297.  62.]\n",
      "65\n",
      "[ 29.924177 577.4891  ]\n",
      "[ 50. 567.]\n",
      "66\n",
      "[281.13855 450.76865]\n",
      "[299. 439.]\n",
      "67\n",
      "[278.00052  90.69138]\n",
      "[294.  78.]\n",
      "68\n",
      "[451.6325  602.61444]\n",
      "[472. 590.]\n",
      "69\n",
      "[154.48708 554.8315 ]\n",
      "[173. 544.]\n",
      "70\n",
      "[416.83603 508.2542 ]\n",
      "[436. 495.]\n",
      "71\n",
      "[148.3456 588.9626]\n",
      "[167. 578.]\n",
      "72\n",
      "[355.24738 569.36816]\n",
      "[374. 557.]\n",
      "73\n",
      "[216.58888 583.39606]\n",
      "[235. 572.]\n",
      "74\n",
      "[418.43784 358.18973]\n",
      "[437. 344.]\n",
      "75\n",
      "[ 82.83987 383.0146 ]\n",
      "[101. 374.]\n",
      "76\n",
      "[122.31068 549.6285 ]\n",
      "[141. 539.]\n",
      "77\n",
      "[275.0096 260.073 ]\n",
      "[292. 248.]\n",
      "78\n",
      "[142.43753 621.41095]\n",
      "[161. 621.]\n",
      "79\n",
      "[113.84627 615.4088 ]\n",
      "[133. 613.]\n",
      "80\n",
      "[ 37.47715 356.2881 ]\n",
      "[ 56. 348.]\n",
      "81\n",
      "[344.39566 571.31195]\n",
      "[363. 559.]\n",
      "82\n",
      "[346.04932 400.71426]\n",
      "[364. 388.]\n",
      "83\n",
      "[356.1236  589.27563]\n",
      "[375. 577.]\n",
      "84\n",
      "[200.51112 199.69557]\n",
      "[217. 189.]\n",
      "85\n",
      "[432.1023 376.2083]\n",
      "[451. 362.]\n",
      "86\n",
      "[444.22034 503.47345]\n",
      "[464. 490.]\n",
      "87\n",
      "[154.7855 139.5194]\n",
      "[171. 130.]\n",
      "88\n",
      "[152.16907 421.15784]\n",
      "[170. 411.]\n",
      "89\n",
      "[435.94095 417.8089 ]\n",
      "[455. 404.]\n",
      "90\n",
      "[ 63.75271 350.60397]\n",
      "[ 82. 342.]\n",
      "91\n",
      "[142.82837 110.22759]\n",
      "[159. 101.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "\n",
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "# params for corner detection \n",
    "feature_params = dict( maxCorners = 100, \n",
    "                       qualityLevel = 0.2, \n",
    "                       minDistance = 7, \n",
    "                       blockSize = 7,\n",
    "                       useHarrisDetector = False) \n",
    "  \n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = dict( winSize = (25, 25), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "  \n",
    "# Create some random colors \n",
    "color = np.random.randint(0, 255, (100, 3)) \n",
    "  \n",
    "# Take first frame and find corners in it \n",
    "old_frame = train_img_ \n",
    "old_gray = cv2.cvtColor(old_frame, \n",
    "                        cv2.COLOR_BGR2GRAY) \n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, \n",
    "                             **feature_params) \n",
    "\n",
    "# Create a mask image for drawing purposes \n",
    "mask = np.zeros_like(old_frame, 'uint8') \n",
    "  \n",
    "\n",
    "frame = query_img_ \n",
    "frame_gray = cv2.cvtColor(frame, \n",
    "                            cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# calculate optical flow \n",
    "p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, \n",
    "                                        frame_gray, \n",
    "                                        p0, None, \n",
    "                                        **lk_params) \n",
    "\n",
    "# Select good points \n",
    "good_new = p1[st == 1] \n",
    "good_old = p0[st == 1] \n",
    "\n",
    "# draw the tracks \n",
    "for i, (new, old) in enumerate(zip(good_new,  \n",
    "                                    good_old)):\n",
    "    print(i)\n",
    "    print(new)\n",
    "    print(old)\n",
    "    a, b = new.ravel() \n",
    "    c, d = old.ravel()\n",
    "    \n",
    "    a, b = int(a), int(b)\n",
    "    c, d = int(c), int(d)\n",
    "\n",
    "    mask = cv2.line(mask, (a, b), (c, d), \n",
    "                    color[i].tolist(), 2) \n",
    "        \n",
    "    frame = cv2.circle(frame, (a, b), 5, \n",
    "                        color[i].tolist(), -1) \n",
    "        \n",
    "img = cv2.add(frame, mask) \n",
    "\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey()\n",
    "\n",
    "# # Updating Previous frame and points  \n",
    "# old_gray = frame_gray.copy() \n",
    "# p0 = good_new.reshape(-1, 1, 2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\flann\\src\\miniflann.cpp:336: error: (-210:Unsupported format or combination of formats) in function 'cv::flann::buildIndex_'\n> type=0\n> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kdemo\\Documents\\Doutorado\\disciplinas\\Visão Computacional\\projetos\\comparing_detectors_and_descriptors\\notebooks\\testando_algoritmos.ipynb Cell 51\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kdemo/Documents/Doutorado/disciplinas/Vis%C3%A3o%20Computacional/projetos/comparing_detectors_and_descriptors/notebooks/testando_algoritmos.ipynb#Y104sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m search_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(checks\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)   \u001b[39m# or pass empty dictionary\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kdemo/Documents/Doutorado/disciplinas/Vis%C3%A3o%20Computacional/projetos/comparing_detectors_and_descriptors/notebooks/testando_algoritmos.ipynb#Y104sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m flann \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mFlannBasedMatcher(index_params,search_params)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kdemo/Documents/Doutorado/disciplinas/Vis%C3%A3o%20Computacional/projetos/comparing_detectors_and_descriptors/notebooks/testando_algoritmos.ipynb#Y104sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m matches \u001b[39m=\u001b[39m flann\u001b[39m.\u001b[39;49mknnMatch(queryDescriptors, trainDescriptors,k\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kdemo/Documents/Doutorado/disciplinas/Vis%C3%A3o%20Computacional/projetos/comparing_detectors_and_descriptors/notebooks/testando_algoritmos.ipynb#Y104sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Need to draw only good matches, so create a mask\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kdemo/Documents/Doutorado/disciplinas/Vis%C3%A3o%20Computacional/projetos/comparing_detectors_and_descriptors/notebooks/testando_algoritmos.ipynb#Y104sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m matchesMask \u001b[39m=\u001b[39m [[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(matches))]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\flann\\src\\miniflann.cpp:336: error: (-210:Unsupported format or combination of formats) in function 'cv::flann::buildIndex_'\n> type=0\n> "
     ]
    }
   ],
   "source": [
    "# Read the query image as query_img \n",
    "# and train image This query image \n",
    "# is what you need to find in train image \n",
    "# Save it in the same directory \n",
    "# with the name image.jpg\n",
    "   \n",
    "query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg') \n",
    "train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg') \n",
    "query_img = cv2.resize(query_img, (640,480))\n",
    "train_img = cv2.resize(train_img, (640,480))\n",
    "# Convert it to grayscale \n",
    "query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY) \n",
    "train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY) \n",
    "   \n",
    "# Initialize the ORB detector algorithm \n",
    "orb = cv2.ORB_create(nfeatures=100)\n",
    "sift = cv2.SIFT_create(nfeatures=100)\n",
    "brisk = cv2.BRISK_create()\n",
    "\n",
    "star = cv2.xfeatures2d.StarDetector_create()\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "\n",
    "# Now detect the keypoints and compute \n",
    "# the descriptors for the query image \n",
    "# and train image \n",
    "\n",
    "queryKeypoints = sift.detect(query_img_bw,None) \n",
    "trainKeypoints, trainDescriptors = brisk.compute(train_img_bw,queryKeypoints)\n",
    "  \n",
    "# Initialize the Matcher for matching \n",
    "# the keypoints and then match the \n",
    "# keypoints \n",
    "\n",
    "# matcher = cv2.BFMatcher() \n",
    "# matches = matcher.knnMatch(queryDescriptors,trainDescriptors, k=2) \n",
    "\n",
    "# good_matches = []\n",
    "# for m, n in matches:\n",
    "#     if m.distance < 0.6 * n.distance:\n",
    "#         good_matches.append(m)\n",
    "   \n",
    "# draw the matches to the final image \n",
    "# containing both the images the drawMatches() \n",
    "# function takes both images and keypoints \n",
    "# and outputs the matched query image with \n",
    "# its train image \n",
    "\n",
    "# final_img = cv2.drawMatches(query_img, queryKeypoints, train_img, trainKeypoints, good_matches, None, flags=2) \n",
    "\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=100)   # or pass empty dictionary\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "matches = flann.knnMatch(queryDescriptors, trainDescriptors,k=2)\n",
    "# Need to draw only good matches, so create a mask\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "\n",
    "m = filter_matches_by_slope(matches, matchesMask, trainKeypoints, queryKeypoints, 2, 98)\n",
    "matchesMask_, qtd_fp, qtd_matches, mismatch_train_keypoints, mismatch_query_keypoints = m \n",
    "\n",
    "print('---- Resultado ---- ')\n",
    "print(f'Quantidade de matches: {qtd_matches}')\n",
    "print(f'Quantidade de falso positivos: {qtd_fp}')\n",
    "print(f'Quantidade de pontos sem match (train_image): {mismatch_train_keypoints}')\n",
    "print(f'Quantidade de pontos sem match (query_image): {mismatch_query_keypoints}')\n",
    "\n",
    "draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask_,\n",
    "                   flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "final_img = cv2.drawMatchesKnn(query_img,queryKeypoints,train_img,trainKeypoints,matches,None,**draw_params)\n",
    "\n",
    "   \n",
    "final_img = cv2.resize(final_img, (1280,960)) \n",
    "  \n",
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_img) \n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB Descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.SIFT 0000028B6AF50FB0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
