{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Códigos detectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.04):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "    gray_image_f32 = np.float32(gray_image)\n",
    "\n",
    "    # Applying the function \n",
    "    dst = cv2.cornerHarris(gray_image_f32, blockSize, ksize, k) \n",
    "  \n",
    "    # dilate to mark the corners \n",
    "    dst = cv2.dilate(dst, None)\n",
    "    \n",
    "    ret, dst = cv2.threshold(dst,threshold*dst.max(),255,0)\n",
    "    dst = np.uint8(dst)\n",
    "\n",
    "    # find centroids\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "    # define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(gray_image_f32,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "    # # extract keypoints\n",
    "    # points = np.argwhere(dst > threshold * dst.max())\n",
    "    \n",
    "    keypoints = [cv2.KeyPoint(float(x[0]), float(x[1]), 13) for x in corners]\n",
    "\n",
    "    # draw keypoints\n",
    "    # image[dst > threshold * dst.max()] = [0, 255, 0]\n",
    "    kp_image = cv2.drawKeypoints(image, keypoints, None, color=(255, 0, 0), flags=0)\n",
    "\n",
    "    return keypoints, kp_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSIFTKeypoints(image, nfeatures=0, nOctaveLayers=3, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6, enable_precise_upscale=False):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    sift = cv2.SIFT_create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, enable_precise_upscale) \n",
    "    kp, des = sift.detectAndCompute(gray_image, None) \n",
    "    \n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectStarKeypoints(image, max_size = 41, response_threshold = 30, line_threshold_projected = 10,\n",
    "                        line_threshold_binarized = 8, suppress_nonmax_size = 5):\n",
    "    # Reading the image and converting the image to B/W \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Applying the function \n",
    "    star = cv2.xfeatures2d.StarDetector_create(maxSize= max_size, \n",
    "                                        responseThreshold = response_threshold,\n",
    "                                        lineThresholdProjected = line_threshold_projected,\n",
    "                                        lineThresholdBinarized = line_threshold_binarized,\n",
    "                                        suppressNonmaxSize = suppress_nonmax_size)\n",
    "    kp = star.detect(gray_image, None)    \n",
    "\n",
    "    # Applying the function \n",
    "    kp_image = cv2.drawKeypoints(image, kp, None, color=(0, 0, 255), flags=0) \n",
    "\n",
    "    return kp, kp_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "# kp, kp_image = detectHarrisKeypoints(image, threshold=0.01, blockSize=2, ksize=3, k=0.02)\n",
    "# print(len(kp))\n",
    "# cv2.imshow('Star', kp_image) \n",
    "# cv2.waitKey() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código comparando pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "def computeDistacesKeypoints(pts1, pts2, threshold=1):\n",
    "    kps1 = [(kp.pt[0], kp.pt[1]) for kp in pts1]\n",
    "    kps2 = [(kp.pt[0], kp.pt[1]) for kp in pts2]\n",
    "\n",
    "    array_pts1 = np.asarray(kps1)\n",
    "    array_pts2 = np.asarray(kps2)\n",
    "\n",
    "    if array_pts1.shape[0] > 0 and array_pts2.shape[0] > 0:\n",
    "        dists = pairwise_distances_argmin_min(array_pts1, array_pts2)  \n",
    "        matches = [pts2[pt] for pt, dist in zip(dists[0], dists[1]) if dist <= threshold]\n",
    "    else:\n",
    "        matches = []\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeiro experimento\n",
    "- Rodando com os parâmetros default dos algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/imgs/dsc07631.jpg')\n",
    "h_kp, harris_image = detectHarrisKeypoints(image)\n",
    "s_kp, sift_image = detectSIFTKeypoints(image)\n",
    "st_kp, star_image = detectStarKeypoints(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold para matches de detectores 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_hs = computeDistacesKeypoints(h_kp, s_kp, threshold=2)\n",
    "matches_hst = computeDistacesKeypoints(h_kp, st_kp, threshold=2)\n",
    "matches_sst = computeDistacesKeypoints(s_kp, st_kp, threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Resultados -----\n",
      "QTD Harris Keypoints:   417\n",
      "QTD SIFT Keypoints:   1518\n",
      "QTD Star Keypoints:   291\n",
      "----- Matches -----\n",
      "Matches Keypoints Harris/SIFT:   80\n",
      "Matches Keypoints Harris/Star:   14\n",
      "Matches Keypoints SIFT/Star:   232\n"
     ]
    }
   ],
   "source": [
    "print('----- Resultados -----')\n",
    "print(f'QTD Harris Keypoints:   {len(h_kp)}')\n",
    "print(f'QTD SIFT Keypoints:   {len(s_kp)}')\n",
    "print(f'QTD Star Keypoints:   {len(st_kp)}')\n",
    "print('----- Matches -----')\n",
    "print(f'Matches Keypoints Harris/SIFT:   {len(matches_hs)}')\n",
    "print(f'Matches Keypoints Harris/Star:   {len(matches_hst)}')\n",
    "print(f'Matches Keypoints SIFT/Star:   {len(matches_sst)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp1_image = cv2.drawKeypoints(image, matches_hs, None, color=(0, 0, 255), flags=0)\n",
    "kp2_image = cv2.drawKeypoints(image, matches_hst, None, color=(0, 255, 0), flags=0)\n",
    "kp3_image = cv2.drawKeypoints(image, matches_sst, None, color=(255, 0, 0), flags=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Matches Harris vs SIFT Keypoints', kp1_image)\n",
    "cv2.imshow('Matches Harris vs STAR Keypoints', kp2_image)\n",
    "cv2.imshow('Matches SIFT vs STAR Keypoints', kp3_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Descritores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slope(pt1, pt2):\n",
    "    slope = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0])\n",
    "    return abs(slope)\n",
    "\n",
    "\n",
    "def verify_slope(match, trainKeypoints, queryKeypoints, q1, q2):\n",
    "    slope = calculate_slope(trainKeypoints[match.trainIdx].pt, queryKeypoints[match.queryIdx].pt) \n",
    "    if slope <= q2 and slope > q1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def filter_matches_by_slope(matches, matchesMask, trainKeypoints, queryKeypoints, q1, q2):\n",
    "    slope_list = [calculate_slope(trainKeypoints[matches[i][0].trainIdx].pt, queryKeypoints[matches[i][0].queryIdx].pt) for i, m in enumerate(matchesMask) if m[0] > 0]\n",
    "    q1_, q2_ = np.percentile(slope_list, [q1 ,q2])\n",
    "    matchesMask_ = [ [1,0] if m[0] > 0 and verify_slope(matches[i][0], trainKeypoints, queryKeypoints, q1_, q2_) else [0,0] for i, m in enumerate(matchesMask)]\n",
    "    \n",
    "    qtd_fp = len([m[0] for m, m_ in zip(matchesMask, matchesMask_) if m[0] != m_[0]])\n",
    "    qtd_matches = len([m[0] for m in matchesMask_ if m[0] > 0 ])\n",
    "    \n",
    "    mismatch_train_keypoints = len(trainKeypoints) - qtd_matches\n",
    "    mismatch_query_keypoints = len(queryKeypoints) - qtd_matches\n",
    "\n",
    "    return matchesMask_, qtd_fp, qtd_matches, mismatch_train_keypoints, mismatch_query_keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchDetectedKeypoints(train_img, query_img, ratio_test=0.7, filter_slope=(2,98), detector='harris', descriptor='orb', dect_kargs={}, des_kargs={}):\n",
    "    query_img_bw = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY) \n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if descriptor == 'brief':\n",
    "        des = cv2.xfeatures2d.BriefDescriptorExtractor_create(**des_kargs)\n",
    "    else:\n",
    "        des = cv2.SIFT.create(**des_kargs)\n",
    "    \n",
    "    if detector == 'star':\n",
    "        func_var = detectStarKeypoints\n",
    "    elif detector == 'harris':\n",
    "        func_var = detectHarrisKeypoints\n",
    "    else:\n",
    "        func_var = detectSIFTKeypoints\n",
    "\n",
    "    queryKeypoints, _ = func_var(query_img, **dect_kargs)\n",
    "    trainKeypoints, _ = func_var(train_img, **dect_kargs)\n",
    "    \n",
    "    _,queryDescriptors = des.compute(query_img_bw, queryKeypoints, **des_kargs) \n",
    "    _,trainDescriptors = des.compute(train_img_bw, trainKeypoints, **des_kargs)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=100)   # or pass empty dictionary\n",
    "\n",
    "    # flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    # matches = flann.knnMatch(queryDescriptors, trainDescriptors, k=2)\n",
    "\n",
    "    matcher = cv2.BFMatcher() \n",
    "    matches = matcher.knnMatch(queryDescriptors,trainDescriptors, k=2) \n",
    "\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < ratio_test*n.distance:\n",
    "            matchesMask[i]=[1,0]\n",
    "\n",
    "    m = filter_matches_by_slope(matches, matchesMask, trainKeypoints, queryKeypoints, filter_slope[0], filter_slope[1])\n",
    "    matchesMask_, qtd_fp, qtd_matches, mismatch_train_keypoints, mismatch_query_keypoints = m \n",
    "\n",
    "    print('---- Resultado ---- ')\n",
    "    print(f'Quantidade de matches: {qtd_matches}')\n",
    "    print(f'Quantidade de falso positivos: {qtd_fp}')\n",
    "    print(f'Quantidade de pontos sem match (train_image): {mismatch_train_keypoints}')\n",
    "    print(f'Quantidade de pontos sem match (query_image): {mismatch_query_keypoints}')\n",
    "\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                    singlePointColor = (255,0,0),\n",
    "                    matchesMask = matchesMask_,\n",
    "                    flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "    final_img = cv2.drawMatchesKnn(query_img,queryKeypoints,train_img,trainKeypoints,matches,None,**draw_params)\n",
    "\n",
    "    \n",
    "    final_img = cv2.resize(final_img, (1280,960))\n",
    "\n",
    "    return final_img \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg') \n",
    "query_img_ = cv2.resize(query_img, (640,480))\n",
    "train_img_ = cv2.resize(train_img, (640,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sift = {\n",
    "    'nfeatures': 100,\n",
    "    'nOctaveLayers' : 3,\n",
    "    'contrastThreshold' : 0.04,\n",
    "    'edgeThreshold' : 20,\n",
    "    'sigma' : 1.6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Resultado ---- \n",
      "Quantidade de matches: 234\n",
      "Quantidade de falso positivos: 79\n",
      "Quantidade de pontos sem match (train_image): 183\n",
      "Quantidade de pontos sem match (query_image): 176\n"
     ]
    }
   ],
   "source": [
    "final_img = matchDetectedKeypoints(train_img_, query_img_, 0.7, filter_slope=(0,75), detector='harris', descriptor='sift', dect_kargs={}, des_kargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the final image \n",
    "cv2.imshow(\"Matches\", final_img) \n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando Fluxo Óptico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "\n",
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "# params for corner detection \n",
    "feature_params = dict( maxCorners = 100, \n",
    "                       qualityLevel = 0.2, \n",
    "                       minDistance = 7, \n",
    "                       blockSize = 7,\n",
    "                       useHarrisDetector = False) \n",
    "  \n",
    "# Parameters for lucas kanade optical flow \n",
    "lk_params = dict( winSize = (25, 25), \n",
    "                  maxLevel = 2, \n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                              10, 0.03)) \n",
    "  \n",
    "# Create some random colors \n",
    "color = np.random.randint(0, 255, (100, 3)) \n",
    "  \n",
    "# Take first frame and find corners in it \n",
    "old_frame = train_img_ \n",
    "old_gray = cv2.cvtColor(old_frame, \n",
    "                        cv2.COLOR_BGR2GRAY) \n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, \n",
    "                             **feature_params) \n",
    "\n",
    "# Create a mask image for drawing purposes \n",
    "mask = np.zeros_like(old_frame, 'uint8') \n",
    "  \n",
    "\n",
    "frame = query_img_ \n",
    "frame_gray = cv2.cvtColor(frame, \n",
    "                            cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# calculate optical flow \n",
    "p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, \n",
    "                                        frame_gray, \n",
    "                                        p0, None, \n",
    "                                        **lk_params) \n",
    "\n",
    "# Select good points \n",
    "good_new = p1[st == 1] \n",
    "good_old = p0[st == 1] \n",
    "\n",
    "# draw the tracks \n",
    "for i, (new, old) in enumerate(zip(good_new,  \n",
    "                                    good_old)):\n",
    "    a, b = new.ravel() \n",
    "    c, d = old.ravel()\n",
    "    \n",
    "    a, b = int(a), int(b)\n",
    "    c, d = int(c), int(d)\n",
    "\n",
    "    mask = cv2.line(mask, (a, b), (c, d), \n",
    "                    color[i].tolist(), 2) \n",
    "        \n",
    "    frame = cv2.circle(frame, (a, b), 5, \n",
    "                        color[i].tolist(), -1) \n",
    "        \n",
    "img = cv2.add(frame, mask) \n",
    "\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey()\n",
    "\n",
    "# # Updating Previous frame and points  \n",
    "# old_gray = frame_gray.copy() \n",
    "# p0 = good_new.reshape(-1, 1, 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horn-Schunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_flow(img, flow, step=16):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step / 2:h:step, step / 2:w:step].reshape(2, -1).astype(int)\n",
    "    fx, fy = flow[y, x].T\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.polylines(vis, lines, 0, (0, 255, 0))\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.circle(vis, (x1, y1), 1, (0, 255, 0), -1)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# train_img = cv2.imread('../data/imgs_teste/IMG_20231129_083404.jpg') \n",
    "# query_img = cv2.imread('../data/imgs_teste/IMG_20231129_083413.jpg')\n",
    "query_img = cv2.imread('../data/imgs/dsc07632.jpg') \n",
    "train_img = cv2.imread('../data/imgs/dsc07631.jpg')  \n",
    "train_img_ = cv2.resize(train_img, (480,640))\n",
    "query_img_ = cv2.resize(query_img, (480,640))\n",
    "\n",
    "# Convert to gray scale\n",
    "prvs = cv2.cvtColor(train_img_, cv2.COLOR_BGR2GRAY)\n",
    "# Create mask\n",
    "hsv_mask = np.zeros_like(train_img_)\n",
    "# Make image saturation to a maximum value\n",
    "hsv_mask[..., 1] = 255\n",
    " \n",
    "# Capture another frame and convert to gray scale\n",
    "next = cv2.cvtColor(query_img_, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Optical flow is now calculated\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "mapped_img = draw_flow(next, flow, step=16)\n",
    "\n",
    "cv2.imshow('frame2', mapped_img)\n",
    "cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
